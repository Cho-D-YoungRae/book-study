{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-18T12:44:02.208226Z",
     "start_time": "2026-02-18T12:43:53.569078Z"
    }
   },
   "source": [
    "from typing import Callable, Literal, Any\n",
    "\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T12:44:14.233720Z",
     "start_time": "2026-02-18T12:44:02.210100Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = load_dataset(\"daekeun-ml/naver-news-summarization-ko\")",
   "id": "7b01635e2c1c4130",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/787 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ca5f86ddd9140819e8ebed8d17f68fa"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "train.csv:   0%|          | 0.00/66.3M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "230e79b75cd54597afd35a8302932087"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "validation.csv: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77eb74e1d428465b813f9fb976f5ae82"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "test.csv: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06e08904d46a4ebca156af19842f622a"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/22194 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f4e319b1bc9f408bbd5c98dca7b641d3"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Generating validation split:   0%|          | 0/2466 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61a295da651846e495e658608376a5ae"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/2740 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "baced8d418b043c588011e8c591ca65e"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T12:44:14.274739Z",
     "start_time": "2026-02-18T12:44:14.243154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = dataset\n",
    "data"
   ],
   "id": "5bd8ebe3d9eedaac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
       "        num_rows: 22194\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
       "        num_rows: 2466\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
       "        num_rows: 2740\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T12:44:14.291563Z",
     "start_time": "2026-02-18T12:44:14.280556Z"
    }
   },
   "cell_type": "code",
   "source": "data[\"train\"][\"document\"][0]",
   "id": "25e3f26155c61727",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'앵커 정부가 올해 하반기 우리 경제의 버팀목인 수출 확대를 위해 총력을 기울이기로 했습니다. 특히 수출 중소기업의 물류난 해소를 위해 무역금융 규모를 40조 원 이상 확대하고 물류비 지원과 임시선박 투입 등을 추진하기로 했습니다. 류환홍 기자가 보도합니다. 기자 수출은 최고의 실적을 보였지만 수입액이 급증하면서 올해 상반기 우리나라 무역수지는 역대 최악인 103억 달러 적자를 기록했습니다. 정부가 수출확대에 총력을 기울이기로 한 것은 원자재 가격 상승 등 대외 리스크가 가중되는 상황에서 수출 증가세 지속이야말로 한국경제의 회복을 위한 열쇠라고 본 것입니다. 추경호 경제부총리 겸 기획재정부 장관 정부는 우리 경제의 성장엔진인 수출이 높은 증가세를 지속할 수 있도록 총력을 다하겠습니다. 우선 물류 부담 증가 원자재 가격 상승 등 가중되고 있는 대외 리스크에 대해 적극 대응하겠습니다. 특히 중소기업과 중견기업 수출 지원을 위해 무역금융 규모를 연초 목표보다 40조 원 늘린 301조 원까지 확대하고 물류비 부담을 줄이기 위한 대책도 마련했습니다. 이창양 산업통상자원부 장관 국제 해상운임이 안정될 때까지 월 4척 이상의 임시선박을 지속 투입하는 한편 중소기업 전용 선복 적재 용량 도 현재보다 주당 50TEU 늘려 공급하겠습니다. 하반기에 우리 기업들의 수출 기회를 늘리기 위해 2 500여 개 수출기업을 대상으로 해외 전시회 참가를 지원하는 등 마케팅 지원도 벌이기로 했습니다. 정부는 또 이달 중으로 반도체를 비롯한 첨단 산업 육성 전략을 마련해 수출 증가세를 뒷받침하고 에너지 소비를 줄이기 위한 효율화 방안을 마련해 무역수지 개선에 나서기로 했습니다. YTN 류환홍입니다.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T12:44:14.308412Z",
     "start_time": "2026-02-18T12:44:14.293735Z"
    }
   },
   "cell_type": "code",
   "source": "print(sorted(list(set(data[\"train\"][\"document\"][0]))))",
   "id": "3f12d5eb4906260d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '.', '0', '1', '2', '3', '4', '5', 'E', 'N', 'T', 'U', 'Y', '가', '개', '것', '겠', '격', '견', '겸', '경', '고', '공', '과', '관', '국', '규', '극', '금', '급', '기', '까', '나', '난', '너', '높', '는', '늘', '니', '다', '단', '달', '담', '당', '대', '도', '되', '될', '뒷', '들', '등', '때', '또', '라', '략', '량', '러', '려', '력', '련', '로', '록', '롯', '류', '를', '리', '린', '마', '만', '말', '면', '모', '목', '무', '물', '박', '반', '받', '방', '버', '벌', '보', '복', '본', '부', '비', '산', '상', '서', '선', '성', '세', '소', '속', '쇠', '수', '스', '습', '승', '시', '실', '악', '안', '액', '앵', '야', '양', '억', '업', '에', '엔', '여', '역', '연', '열', '였', '올', '외', '용', '우', '운', '울', '원', '월', '위', '육', '율', '융', '으', '은', '을', '응', '의', '이', '인', '임', '입', '있', '자', '장', '재', '적', '전', '정', '제', '조', '주', '줄', '중', '증', '지', '진', '참', '창', '책', '척', '첨', '체', '초', '총', '최', '추', '출', '침', '커', '케', '크', '통', '투', '특', '팀', '팅', '편', '표', '하', '한', '할', '합', '해', '했', '현', '호', '홍', '화', '확', '환', '황', '회', '획', '효', '히']\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T12:44:14.792709Z",
     "start_time": "2026-02-18T12:44:14.309853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ko_text = \"\".join(data[\"train\"][\"document\"])\n",
    "ko_chars = sorted(list(set(ko_text)))\n",
    "ko_vocab_size = len(ko_chars)\n",
    "print(f\"총 글자 수: {ko_vocab_size}\")"
   ],
   "id": "d9d601de19a8232d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 글자 수: 2701\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T12:44:14.807290Z",
     "start_time": "2026-02-18T12:44:14.793515Z"
    }
   },
   "cell_type": "code",
   "source": "print(ko_chars[2000:2100])",
   "id": "8ba0914b9e2c9a5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['왓', '왔', '왕', '왜', '왠', '외', '왹', '왼', '요', '욕', '욘', '욜', '욤', '욥', '용', '우', '욱', '운', '욷', '울', '움', '웁', '웃', '웅', '워', '웍', '원', '월', '웜', '웠', '웡', '웨', '웬', '웰', '웸', '웹', '웻', '위', '윅', '윈', '윌', '윔', '윕', '윗', '윙', '유', '육', '윤', '율', '윱', '윳', '융', '으', '윽', '은', '을', '음', '읍', '읏', '응', '의', '읠', '이', '익', '인', '일', '읽', '잃', '임', '입', '잇', '있', '잉', '잊', '잎', '자', '작', '잔', '잖', '잘', '잠', '잡', '잣', '잤', '장', '잦', '재', '잭', '잰', '잼', '잽', '잿', '쟁', '쟈', '쟝', '쟤', '저', '적', '전', '절']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T12:44:14.820843Z",
     "start_time": "2026-02-18T12:44:14.809144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "character_to_ids = {char:i for i, char in enumerate(ko_chars)}\n",
    "ids_to_character = {i:char for i, char in enumerate(ko_chars)}\n",
    "\n",
    "token_encode: Callable[[str], list[int]] = lambda s:[character_to_ids[c] for c in s]\n",
    "token_decode: Callable[[list[int]], str] = lambda l: \"\".join([ids_to_character[i] for i in l])\n",
    "\n",
    "print(token_encode(\"안녕하세요 함께 인공지능을 공부하게 되어 반가워요.\"))\n",
    "print(token_decode(token_encode(\"안녕하세요 함께 인공지능을 공부하게 되어 반가워요.\")))"
   ],
   "id": "5aa20580c200c786",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1909, 1169, 2546, 1770, 2008, 0, 2551, 1061, 0, 2064, 977, 2157, 1209, 2055, 0, 977, 1658, 2546, 949, 0, 1283, 1942, 0, 1593, 908, 2024, 2008, 2]\n",
      "안녕하세요 함께 인공지능을 공부하게 되어 반가워요.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T12:44:16.102863Z",
     "start_time": "2026-02-18T12:44:14.822437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_data = torch.tensor(token_encode(ko_text), dtype=torch.long)\n",
    "print(tokenized_data.shape, tokenized_data.dtype)\n",
    "print(tokenized_data[:100])"
   ],
   "id": "6c6ebeee921fae04",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22162967]) torch.int64\n",
      "tensor([1928, 2315,    0, 2105, 1658,  908,    0, 1987, 2555,    0, 2546, 1593,\n",
      "        1028,    0, 2015, 1485,    0,  965, 2107, 2060,    0, 1617, 2465, 1542,\n",
      "        2064,    0, 1808, 2273,    0, 2603, 1236, 1477,    0, 2037, 2555,    0,\n",
      "        2263, 1430, 2055,    0, 1028, 2019, 2062, 1028, 1441,    0, 2562, 1841,\n",
      "        1213, 1221,    2,    0, 2451, 2650,    0, 1808, 2273,    0, 2142, 1787,\n",
      "        1028, 1950, 2060,    0, 1558, 1468, 1119,    0, 2555, 1787, 1477,    0,\n",
      "        2037, 2555,    0, 1553, 1967, 1024, 2051,    0, 1015, 1541, 1477,    0,\n",
      "           7,    3, 2117,    0, 2026,    0, 2062, 1740,    0, 2603, 1236, 2546,\n",
      "         968,    0, 1558, 1468])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T12:44:16.114064Z",
     "start_time": "2026-02-18T12:44:16.108921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n = int(0.9 * len(tokenized_data))\n",
    "train_dataset = tokenized_data[:n]\n",
    "test_dataset = tokenized_data[n:]"
   ],
   "id": "e90c3963e881abf5",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T12:44:16.123670Z",
     "start_time": "2026-02-18T12:44:16.114590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "block_size = 8\n",
    "train_dataset[:block_size]"
   ],
   "id": "c97f595a9ae8d91c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1928, 2315,    0, 2105, 1658,  908,    0, 1987])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T12:44:16.134647Z",
     "start_time": "2026-02-18T12:44:16.124744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = train_dataset[:block_size]\n",
    "y = train_dataset[1:block_size+1]\n",
    "\n",
    "for time in range(block_size):\n",
    "    context = x[:time+1]\n",
    "    target = y[time]\n",
    "\n",
    "    print(f\"입력 텐서: {context}\")\n",
    "    print(f\"타깃 글자: {target}\")"
   ],
   "id": "346d41f0eb97febb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 텐서: tensor([1928])\n",
      "타깃 글자: 2315\n",
      "입력 텐서: tensor([1928, 2315])\n",
      "타깃 글자: 0\n",
      "입력 텐서: tensor([1928, 2315,    0])\n",
      "타깃 글자: 2105\n",
      "입력 텐서: tensor([1928, 2315,    0, 2105])\n",
      "타깃 글자: 1658\n",
      "입력 텐서: tensor([1928, 2315,    0, 2105, 1658])\n",
      "타깃 글자: 908\n",
      "입력 텐서: tensor([1928, 2315,    0, 2105, 1658,  908])\n",
      "타깃 글자: 0\n",
      "입력 텐서: tensor([1928, 2315,    0, 2105, 1658,  908,    0])\n",
      "타깃 글자: 1987\n",
      "입력 텐서: tensor([1928, 2315,    0, 2105, 1658,  908,    0, 1987])\n",
      "타깃 글자: 2555\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T12:44:16.151018Z",
     "start_time": "2026-02-18T12:44:16.135781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(1234)\n",
    "\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def batch_function(mode: Literal[\"train\", \"test\"]) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    dataset = train_dataset if mode == \"train\" else test_dataset\n",
    "    idx = torch.randint(len(dataset) - block_size, (batch_size,))\n",
    "    x = torch.stack([dataset[index:index+block_size] for index in idx])\n",
    "    y = torch.stack([dataset[index+1:index+block_size+1] for index in idx])\n",
    "    return x, y\n",
    "\n",
    "example_x, example_y = batch_function(\"train\")\n",
    "print(f\"inputs: {example_x.shape}\")\n",
    "print(\"\")\n",
    "print(\"example_x의 실제 값\")\n",
    "print(example_x)\n",
    "print(\"-----------------------\")\n",
    "print(\"targets : \", example_y.shape)\n",
    "print(\"\")\n",
    "print(\"example_y의 실제 값\")\n",
    "print(example_y)\n",
    "print(\"-----------------------\")\n",
    "\n",
    "for size in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = example_x[size, :t+1]\n",
    "        target = example_y[size, t]\n",
    "        print(f\"input: {context}, target: {target}\")\n",
    "    print(\"-----------------------\")\n",
    "    print(\"-----------------------\")"
   ],
   "id": "f30551c0cbfdccae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: torch.Size([4, 8])\n",
      "\n",
      "example_x의 실제 값\n",
      "tensor([[1764, 2555,    0, 1236, 2248,    0, 2017, 1976],\n",
      "        [   0, 1966, 2157,    0, 1951, 2062,    0, 2548],\n",
      "        [   0, 1304, 1485, 1586,    0, 1907, 2450,    0],\n",
      "        [   3,    2,    6,    5,    1,    0,    5,    3]])\n",
      "-----------------------\n",
      "targets :  torch.Size([4, 8])\n",
      "\n",
      "example_y의 실제 값\n",
      "tensor([[2555,    0, 1236, 2248,    0, 2017, 1976, 2546],\n",
      "        [1966, 2157,    0, 1951, 2062,    0, 2548, 2289],\n",
      "        [1304, 1485, 1586,    0, 1907, 2450,    0, 2480],\n",
      "        [   2,    6,    5,    1,    0,    5,    3,    5]])\n",
      "-----------------------\n",
      "input: tensor([1764]), target: 2555\n",
      "input: tensor([1764, 2555]), target: 0\n",
      "input: tensor([1764, 2555,    0]), target: 1236\n",
      "input: tensor([1764, 2555,    0, 1236]), target: 2248\n",
      "input: tensor([1764, 2555,    0, 1236, 2248]), target: 0\n",
      "input: tensor([1764, 2555,    0, 1236, 2248,    0]), target: 2017\n",
      "input: tensor([1764, 2555,    0, 1236, 2248,    0, 2017]), target: 1976\n",
      "input: tensor([1764, 2555,    0, 1236, 2248,    0, 2017, 1976]), target: 2546\n",
      "-----------------------\n",
      "-----------------------\n",
      "input: tensor([0]), target: 1966\n",
      "input: tensor([   0, 1966]), target: 2157\n",
      "input: tensor([   0, 1966, 2157]), target: 0\n",
      "input: tensor([   0, 1966, 2157,    0]), target: 1951\n",
      "input: tensor([   0, 1966, 2157,    0, 1951]), target: 2062\n",
      "input: tensor([   0, 1966, 2157,    0, 1951, 2062]), target: 0\n",
      "input: tensor([   0, 1966, 2157,    0, 1951, 2062,    0]), target: 2548\n",
      "input: tensor([   0, 1966, 2157,    0, 1951, 2062,    0, 2548]), target: 2289\n",
      "-----------------------\n",
      "-----------------------\n",
      "input: tensor([0]), target: 1304\n",
      "input: tensor([   0, 1304]), target: 1485\n",
      "input: tensor([   0, 1304, 1485]), target: 1586\n",
      "input: tensor([   0, 1304, 1485, 1586]), target: 0\n",
      "input: tensor([   0, 1304, 1485, 1586,    0]), target: 1907\n",
      "input: tensor([   0, 1304, 1485, 1586,    0, 1907]), target: 2450\n",
      "input: tensor([   0, 1304, 1485, 1586,    0, 1907, 2450]), target: 0\n",
      "input: tensor([   0, 1304, 1485, 1586,    0, 1907, 2450,    0]), target: 2480\n",
      "-----------------------\n",
      "-----------------------\n",
      "input: tensor([3]), target: 2\n",
      "input: tensor([3, 2]), target: 6\n",
      "input: tensor([3, 2, 6]), target: 5\n",
      "input: tensor([3, 2, 6, 5]), target: 1\n",
      "input: tensor([3, 2, 6, 5, 1]), target: 0\n",
      "input: tensor([3, 2, 6, 5, 1, 0]), target: 5\n",
      "input: tensor([3, 2, 6, 5, 1, 0, 5]), target: 3\n",
      "input: tensor([3, 2, 6, 5, 1, 0, 5, 3]), target: 5\n",
      "-----------------------\n",
      "-----------------------\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T12:45:05.843006Z",
     "start_time": "2026-02-18T12:45:05.775897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SemiGPT(nn.Module):\n",
    "    def __init__(self, vocab_length: int):\n",
    "        super().__init__()\n",
    "        self.embedding_token_table = nn.Embedding(vocab_length, vocab_length)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        logits = self.embedding_token_table(inputs)\n",
    "        return logits\n",
    "\n",
    "model = SemiGPT(ko_vocab_size)\n",
    "output = model(example_x, example_y)\n",
    "print(output.shape)"
   ],
   "id": "32e0ae64bd7c7900",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 2701])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T12:55:07.178407Z",
     "start_time": "2026-02-18T12:55:07.100673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SemiGPT(nn.Module):\n",
    "    def __init__(self, vocab_length: int):\n",
    "        super().__init__()\n",
    "        self.embedding_token_table = nn.Embedding(vocab_length, vocab_length)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        logits = self.embedding_token_table(inputs)\n",
    "        batch, seq_length, vocab_length = logits.shape\n",
    "        logits = logits.view(batch * seq_length, vocab_length)\n",
    "        targets = targets.view(batch * seq_length)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        print(f\"logits: {logits.shape}, targets: {targets.shape}\")\n",
    "        return logits, loss\n",
    "\n",
    "model = SemiGPT(ko_vocab_size)\n",
    "logits, loss = model(example_x, example_y)\n",
    "print(loss)"
   ],
   "id": "be2e87be8ff799c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: torch.Size([32, 2701]), targets: torch.Size([32])\n",
      "tensor(8.5332, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:08:25.453505Z",
     "start_time": "2026-02-18T13:08:25.382382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SemiGPT(nn.Module):\n",
    "    def __init__(self, vocab_length: int):\n",
    "        super().__init__()\n",
    "        self.embedding_token_table = nn.Embedding(vocab_length, vocab_length)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor, targets: torch.Tensor=None) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        logits = self.embedding_token_table(inputs)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            batch, seq_length, vocab_length = logits.shape\n",
    "            logits = logits.view(batch * seq_length, vocab_length)\n",
    "            targets = targets.view(batch*seq_length)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, inputs: torch.Tensor, max_new_tokens: int) -> torch.Tensor:\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self.forward(inputs)\n",
    "            logits = logits[:, -1, :]\n",
    "            print(f\"logits: {logits.shape}\")\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_inputs = torch.multinomial(probs, num_samples=1)\n",
    "            inputs = torch.cat([inputs, next_inputs], dim=-1)\n",
    "        return inputs\n",
    "\n",
    "model = SemiGPT(ko_vocab_size)\n",
    "logits, loss = model(example_x, example_y)\n",
    "print(loss)\n",
    "\n",
    "token_decode(model.generate(torch.zeros((1,1),\n",
    "                                        dtype=torch.long),\n",
    "                            max_new_tokens=10)[0].tolist())"
   ],
   "id": "a01e1c7f1d378eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.3806, grad_fn=<NllLossBackward0>)\n",
      "logits: torch.Size([1, 2701])\n",
      "logits: torch.Size([1, 2701])\n",
      "logits: torch.Size([1, 2701])\n",
      "logits: torch.Size([1, 2701])\n",
      "logits: torch.Size([1, 2701])\n",
      "logits: torch.Size([1, 2701])\n",
      "logits: torch.Size([1, 2701])\n",
      "logits: torch.Size([1, 2701])\n",
      "logits: torch.Size([1, 2701])\n",
      "logits: torch.Size([1, 2701])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 됨엷랲씌써엣퉈率湖깅'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dca5e8a1f29ea78d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
