{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:34:29.869147Z",
     "start_time": "2026-02-10T22:34:29.855415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from typing import TypedDict\n",
    "import tiktoken"
   ],
   "id": "5982b59c04fbf870",
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-10T22:01:21.376017Z",
     "start_time": "2026-02-10T22:01:21.365788Z"
    }
   },
   "source": [
    "class GPTConfig(TypedDict):\n",
    "    vocab_size: int\n",
    "    context_length: int\n",
    "    emb_dim: int\n",
    "    n_heads: int\n",
    "    n_layers: int\n",
    "    drop_rate: float\n",
    "    qkv_bias: bool\n",
    "\n",
    "GPT_CONFIG_124M: GPTConfig = {\n",
    "    \"vocab_size\": 50257,    # 어휘사전 크기\n",
    "    \"context_length\": 1024, # 문맥 길이\n",
    "    \"emb_dim\": 768,         # 임베딩 차원\n",
    "    \"n_heads\": 12,          # 어텐션 헤드 개수\n",
    "    \"n_layers\": 12,         # 층 개수\n",
    "    \"drop_rate\": 0.1,       # 드롭아웃 비율\n",
    "    \"qkv_bias\": False       # 쿼리, 키, 값을 만들 때 편향 포함 여부\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:01:21.385667Z",
     "start_time": "2026-02-10T22:01:21.376605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg: GPTConfig):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape: int, eps: float = 1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x"
   ],
   "id": "9d8c3d76d79cc8ff",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:01:21.526335Z",
     "start_time": "2026-02-10T22:01:21.386322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "batch = []\n",
    "\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ],
   "id": "843e25026f5cc666",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:01:21.863741Z",
     "start_time": "2026-02-10T22:01:21.527309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "logits = model(batch)\n",
    "print(f\"출력 크기: {logits.shape}\")\n",
    "print(logits.shape)"
   ],
   "id": "a14eee248a783563",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력 크기: torch.Size([2, 4, 50257])\n",
      "torch.Size([2, 4, 50257])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:01:21.886031Z",
     "start_time": "2026-02-10T22:01:21.864578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "batch_example = torch.randn(2, 5)\n",
    "\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ],
   "id": "3d52c62634feb721",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:01:21.901113Z",
     "start_time": "2026-02-10T22:01:21.886918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "\n",
    "print(f\"평균: {mean}\")\n",
    "print(f\"분산: {var}\")"
   ],
   "id": "45ef785bb8496bb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균: tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "분산: tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:01:21.913127Z",
     "start_time": "2026-02-10T22:01:21.903249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "print(\"정규화된 층 출력:\\n\", out_norm)\n",
    "\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"평균:\\n\", mean)\n",
    "print(\"분산:\\n\", var)"
   ],
   "id": "3ad40771d8d4ebed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화된 층 출력:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "평균:\n",
      " tensor([[-5.9605e-08],\n",
      "        [ 1.9868e-08]], grad_fn=<MeanBackward1>)\n",
      "분산:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:01:21.927082Z",
     "start_time": "2026-02-10T22:01:21.914616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"평균:\\n\", mean)\n",
    "print(\"분산:\\n\", var)"
   ],
   "id": "b9e9630112a5d66a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균:\n",
      " tensor([[-0.0000],\n",
      "        [ 0.0000]], grad_fn=<MeanBackward1>)\n",
      "분산:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:12:58.162263Z",
     "start_time": "2026-02-10T22:12:58.154168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim: int):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False) # correction=0\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ],
   "id": "73df1616408921d3",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:01:21.936518Z",
     "start_time": "2026-02-10T22:01:21.932642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)"
   ],
   "id": "e48cb032ef61ba38",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:01:21.945541Z",
     "start_time": "2026-02-10T22:01:21.936833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "\n",
    "print(\"평균:\\n\", mean)\n",
    "print(\"분산:\\n\", var)"
   ],
   "id": "13650cf4dab0950b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균:\n",
      " tensor([[-0.0000],\n",
      "        [ 0.0000]], grad_fn=<MeanBackward1>)\n",
      "분산:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:01:21.950526Z",
     "start_time": "2026-02-10T22:01:21.946877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n"
   ],
   "id": "514e8ef092949e17",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:01:21.954045Z",
     "start_time": "2026-02-10T22:01:21.950866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ],
   "id": "c1cccb58c4662702",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:01:21.962078Z",
     "start_time": "2026-02-10T22:01:21.954385Z"
    }
   },
   "cell_type": "code",
   "source": "print(GPT_CONFIG_124M[\"emb_dim\"])\n",
   "id": "55e09aaada6bb699",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:01:21.984396Z",
     "start_time": "2026-02-10T22:01:21.963211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "\n",
    "# 입력 크기: [batch_size, num_token, emb_size]\n",
    "x = torch.rand(2, 3, 768)\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ],
   "id": "7caf80297ccc92db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:01:21.993315Z",
     "start_time": "2026-02-10T22:01:21.989080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes: list[int], use_shortcut: bool):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU()),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(x)\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x\n",
    "\n",
    "def print_gradients(model, x):\n",
    "    # 정방향 계산\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    # 타깃과 출력의 가까운 정도를 기반으로 손실을 계산합니다.\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "\n",
    "    # 그레이디언트를 계산하기 위한 역전파\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # 가중치의 그레이디언트의 평균 절댓값을 출력합니다.\n",
    "            print(f\"{name}의 평균 그레이디언트는 {param.grad.abs().mean().item()}입니다.\")"
   ],
   "id": "262682a1d33d3ed9",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:01:22.022688Z",
     "start_time": "2026-02-10T22:01:21.993606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=False)\n",
    "print_gradients(model_without_shortcut, sample_input)"
   ],
   "id": "30e231bd7e7d14e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight의 평균 그레이디언트는 0.00020173587836325169입니다.\n",
      "layers.1.0.weight의 평균 그레이디언트는 0.0001201116101583466입니다.\n",
      "layers.2.0.weight의 평균 그레이디언트는 0.0007152041071094573입니다.\n",
      "layers.3.0.weight의 평균 그레이디언트는 0.0013988735154271126입니다.\n",
      "layers.4.0.weight의 평균 그레이디언트는 0.005049645435065031입니다.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:01:22.044266Z",
     "start_time": "2026-02-10T22:01:22.023738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ],
   "id": "4f0c3b15de816d29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight의 평균 그레이디언트는 0.22169791162014008입니다.\n",
      "layers.1.0.weight의 평균 그레이디언트는 0.20694106817245483입니다.\n",
      "layers.2.0.weight의 평균 그레이디언트는 0.32896995544433594입니다.\n",
      "layers.3.0.weight의 평균 그레이디언트는 0.2665732204914093입니다.\n",
      "layers.4.0.weight의 평균 그레이디언트는 1.3258540630340576입니다.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:01:22.051761Z",
     "start_time": "2026-02-10T22:01:22.047426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from previous_chapter import MultiHeadAttention\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.attn(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x"
   ],
   "id": "ffcd8085ef06d9a0",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:03:36.088713Z",
     "start_time": "2026-02-10T22:03:36.052631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "x = torch.rand(2, 4, 768)  # 크기: [batch_size, num_tokens, emb_dim]\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "\n",
    "print(\"입력 크기:\", x.shape)\n",
    "print(\"출력 크기:\", output.shape)"
   ],
   "id": "6683814210d7e904",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 크기: torch.Size([2, 4, 768])\n",
      "출력 크기: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:13:02.578447Z",
     "start_time": "2026-02-10T22:13:02.565440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ],
   "id": "e4ed0e0219d80bae",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:17:22.873082Z",
     "start_time": "2026-02-10T22:17:22.322489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"입력 배치:\\n\", batch)\n",
    "print(\"\\n출력 크기:\", out.shape)\n",
    "print(out)"
   ],
   "id": "aee58d471540df79",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 배치:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "출력 크기: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.3613,  0.4222, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
      "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
      "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
      "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
      "\n",
      "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
      "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
      "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
      "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:18:41.880611Z",
     "start_time": "2026-02-10T22:18:41.849494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"총 파라미터 개수: {total_params:,}\")"
   ],
   "id": "159a3120deda0b48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 파라미터 개수: 163,009,536\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:19:15.263732Z",
     "start_time": "2026-02-10T22:19:15.236232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"토큰 임베딩 층의 가중치 크기:\", model.tok_emb.weight.shape)\n",
    "print(\"출력 층의 가중치 크기:\", model.out_head.weight.shape)"
   ],
   "id": "6eba587bf9670663",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰 임베딩 층의 가중치 크기: torch.Size([50257, 768])\n",
      "출력 층의 가중치 크기: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:19:37.227092Z",
     "start_time": "2026-02-10T22:19:37.199275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_params_gpt2 =  total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"가중치 묶기를 고려한 훈련 가능한 파라미터 개수: {total_params_gpt2:,}\")"
   ],
   "id": "1940f251f1d5d0cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가중치 묶기를 고려한 훈련 가능한 파라미터 개수: 124,412,160\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:21:52.641453Z",
     "start_time": "2026-02-10T22:21:52.565097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 총 크기를 바이트 단위로 계산합니다(float32라 가정하면 파라미터당 4바이트입니다).\n",
    "total_size_bytes = total_params * 4\n",
    "\n",
    "# 메가바이트로 변환합니다.\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"모델에 필요한 메모리 공간: {total_size_mb:.2f} MB\")"
   ],
   "id": "787fcfe921581521",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델에 필요한 메모리 공간: 621.83 MB\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:41:48.453558Z",
     "start_time": "2026-02-10T22:41:48.444393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_text_simple(model: GPTModel, idx: torch.Tensor, max_new_tokens: int, context_size: int) -> torch.Tensor:\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx"
   ],
   "id": "2bc45dd91c881e8b",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:34:37.882339Z",
     "start_time": "2026-02-10T22:34:37.858341Z"
    }
   },
   "cell_type": "code",
   "source": "type(np.array([123]))",
   "id": "c61f90ea8149235d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:41:21.583847Z",
     "start_time": "2026-02-10T22:41:21.559377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_context = \"Hello, I am\"\n",
    "\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"인코딩된 ID:\", encoded)\n",
    "\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ],
   "id": "7c58e35c30bda353",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩된 ID: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:41:58.387902Z",
     "start_time": "2026-02-10T22:41:58.255002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval() # 드롭아웃 끄기\n",
    "\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=encoded_tensor,\n",
    "    max_new_tokens=6,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"출력:\", out)\n",
    "print(\"출력 길이:\", len(out[0]))"
   ],
   "id": "28bbc34104bae394",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "출력: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "출력 길이: 10\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:42:14.678752Z",
     "start_time": "2026-02-10T22:42:14.644630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(decoded_text)"
   ],
   "id": "d79e214f1e816124",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ad05258508fc7d5b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
