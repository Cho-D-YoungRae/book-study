{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6DMn4nBwcTe"
      },
      "source": [
        "# Chapter 17. 딥러닝을 이용한 자연어 처리\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvIePS7lwkpj",
        "outputId": "6c09c931-d4ee-4b24-872e-8ff2a6486416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "numpy: 1.25.2\n",
            "pandas: 1.5.3\n",
            "sklearn: 1.2.2\n",
            "matplotlib: 3.7.1\n",
            "seaborn: 0.13.1\n",
            "tensorflow: 2.15.0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "print(f\"python: {sys.version}\")\n",
        "print(f\"numpy: {np.__version__}\")\n",
        "print(f\"pandas: {pd.__version__}\")\n",
        "print(f\"sklearn: {sklearn.__version__}\")\n",
        "print(f\"matplotlib: {matplotlib.__version__}\")\n",
        "print(f\"seaborn: {sns.__version__}\")\n",
        "print(f\"tensorflow: {tf.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIZiCvZ1wl4m",
        "outputId": "f963d8a7-e896-42b0-b2cc-b7281e748c13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "원문:\n",
            " 해보지 않으면 해낼 수 없다\n",
            "\n",
            "토큰화:\n",
            " ['해보지', '않으면', '해낼', '수', '없다']\n"
          ]
        }
      ],
      "source": [
        "text = '해보지 않으면 해낼 수 없다'\n",
        "\n",
        "result = text_to_word_sequence(text)\n",
        "print(\"\\n원문:\\n\", text)\n",
        "print(\"\\n토큰화:\\n\", result)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = ['먼저 텍스트의 각 단어를 나누어 토큰화합니다.',\n",
        "       '텍스트의 단어로 토큰화해야 딥러닝에서 인식됩니다.',\n",
        "       '토큰화한 결과는 딥러닝에서 사용할 수 있습니다.',\n",
        "       ]\n",
        "\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(docs)\n",
        "\n",
        "print(\"\\n단어 카운트:\\n\", token.word_counts)\n",
        "\n",
        "print(\"\\n문장 카운트: \", token.document_count)\n",
        "print(\"\\n각 단어가 몇 개의 문장에 포함되어 있는가:\\n\", token.word_docs)\n",
        "print(\"\\n각 단어에 매겨진 인덱스 값:\\n\",  token.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxFKx2R_MakF",
        "outputId": "4ba24f23-2174-4615-ac9d-c3ad04d02781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "단어 카운트:\n",
            " OrderedDict([('먼저', 1), ('텍스트의', 2), ('각', 1), ('단어를', 1), ('나누어', 1), ('토큰화합니다', 1), ('단어로', 1), ('토큰화해야', 1), ('딥러닝에서', 2), ('인식됩니다', 1), ('토큰화한', 1), ('결과는', 1), ('사용할', 1), ('수', 1), ('있습니다', 1)])\n",
            "\n",
            "문장 카운트:  3\n",
            "\n",
            "각 단어가 몇 개의 문장에 포함되어 있는가:\n",
            " defaultdict(<class 'int'>, {'각': 1, '먼저': 1, '나누어': 1, '단어를': 1, '토큰화합니다': 1, '텍스트의': 2, '토큰화해야': 1, '딥러닝에서': 2, '인식됩니다': 1, '단어로': 1, '수': 1, '결과는': 1, '사용할': 1, '있습니다': 1, '토큰화한': 1})\n",
            "\n",
            "각 단어에 매겨진 인덱스 값:\n",
            " {'텍스트의': 1, '딥러닝에서': 2, '먼저': 3, '각': 4, '단어를': 5, '나누어': 6, '토큰화합니다': 7, '단어로': 8, '토큰화해야': 9, '인식됩니다': 10, '토큰화한': 11, '결과는': 12, '사용할': 13, '수': 14, '있습니다': 15}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"오랫동안 꿈꾸는 이는 그 꿈을 닮아간다\"\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts([text])\n",
        "print(token.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZgUUkpHZPDi",
        "outputId": "6399b291-2e51-4d0f-86b2-3d95d0033dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'오랫동안': 1, '꿈꾸는': 2, '이는': 3, '그': 4, '꿈을': 5, '닮아간다': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=token.texts_to_sequences([text])\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6lhK98gZnbZ",
        "outputId": "8c361269-20c6-4d5c-d9c9-8e5786d0d8a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2, 3, 4, 5, 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_size = len(token.word_index) + 1\n",
        "x = to_categorical(x, num_classes=word_size)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYpjY8h1Zuzw",
        "outputId": "e89f61a6-7730-4414-d138-83f88336b789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 1. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 1.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "원-핫 인코딩을 그대로 사용하면 벡터의 길이가 너무 길어진다는 단점\n",
        "\n",
        "이러한 공간적 낭비를 해결하기 위해 등장한 것이 단어 임베딩(word embedding)\n",
        "\n",
        "단어 임베딩으로 얻은 결과가 밀집된 정보를 가지고 있고 공간의 낭비가 적음 -> 이러한 결과가 가능한 이유는 각 단어 간의 유사도를 계산 했기 때문\n",
        "\n",
        "이 단어 간 유사도는 어떻게 계산?\n",
        "\n",
        "> 적절한 크기로 배열을 바꾸어 주기 위해 최적의 유사도를 계산 하는 학습 과정을 거치는 것 -> 오차 역전파 사용"
      ],
      "metadata": {
        "id": "RKyz1tetZ1cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\n",
        "    \"너무 재밌네요\",\n",
        "    \"최고예요\",\n",
        "    \"참 잘 만든 영화예요\",\n",
        "    \"추천하고 싶은 영화입니다\",\n",
        "    \"한번 더 보고싶네요\",\n",
        "    \"글쎄요\",\n",
        "    \"별로예요\",\n",
        "    \"생각보다 지루하네요\",\n",
        "    \"연기가 어색해요\",\n",
        "    \"재미없어요\"\n",
        "]\n",
        "\n",
        "classes = np.array([1,1,1,1,1,0,0,0,0,0])\n",
        "\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(docs)\n",
        "print(token.word_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PuJIE01a6DK",
        "outputId": "42d00588-643f-4f5c-ac29-c2d52903e928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'너무': 1, '재밌네요': 2, '최고예요': 3, '참': 4, '잘': 5, '만든': 6, '영화예요': 7, '추천하고': 8, '싶은': 9, '영화입니다': 10, '한번': 11, '더': 12, '보고싶네요': 13, '글쎄요': 14, '별로예요': 15, '생각보다': 16, '지루하네요': 17, '연기가': 18, '어색해요': 19, '재미없어요': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = token.texts_to_sequences(docs)\n",
        "print(\"\\n리뷰 텍스트, 토큰화 결과:\\n\",  x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qccy1I-9a-mg",
        "outputId": "1b387679-0459-494f-aac2-c734cb9b4c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "리뷰 텍스트, 토큰화 결과:\n",
            " [[1, 2], [3], [4, 5, 6, 7], [8, 9, 10], [11, 12, 13], [14], [15], [16, 17], [18, 19], [20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "딥러닝 모델에 입력하려면 학습 데이터의 길이가 동일해야 함 -> 이처럼 길이를 똑같이 맞추어 주는 작업을 패딩(padding) 이라고 함"
      ],
      "metadata": {
        "id": "zozlByIubDRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "padded_x = pad_sequences(x, 4)\n",
        "print(\"\\n패딩 결과:\\n\", padded_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTNutHFoxaDP",
        "outputId": "5192e275-a526-45ab-f5fc-ee612b6a2b01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "패딩 결과:\n",
            " [[ 0  0  1  2]\n",
            " [ 0  0  0  3]\n",
            " [ 4  5  6  7]\n",
            " [ 0  8  9 10]\n",
            " [ 0 11 12 13]\n",
            " [ 0  0  0 14]\n",
            " [ 0  0  0 15]\n",
            " [ 0  0 16 17]\n",
            " [ 0  0 18 19]\n",
            " [ 0  0  0 20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_size = len(token.word_index) + 1\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(word_size, 8, input_length=4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WC-N9mLyPGE",
        "outputId": "d907de4c-66eb-4743-8cac-b9d9d72629ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 4, 8)              168       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 201 (804.00 Byte)\n",
            "Trainable params: 201 (804.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(padded_x, classes, epochs=20)\n",
        "print(\"\\n Accuracy: %.4f\" % (model.evaluate(padded_x, classes)[1]))"
      ],
      "metadata": {
        "id": "6PivS5g1y2Ik",
        "outputId": "adcb3ba1-0391-4cdf-82ba-dbbb55cb319b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6957 - accuracy: 0.6000\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6938 - accuracy: 0.6000\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6918 - accuracy: 0.6000\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6898 - accuracy: 0.6000\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6879 - accuracy: 0.7000\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6859 - accuracy: 0.7000\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6840 - accuracy: 0.7000\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6820 - accuracy: 0.7000\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6801 - accuracy: 0.8000\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6781 - accuracy: 0.8000\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6762 - accuracy: 0.9000\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6742 - accuracy: 0.9000\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6723 - accuracy: 0.9000\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6703 - accuracy: 0.9000\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6683 - accuracy: 0.9000\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6663 - accuracy: 0.9000\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6643 - accuracy: 0.9000\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6623 - accuracy: 0.9000\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6603 - accuracy: 0.9000\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6583 - accuracy: 0.9000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.6563 - accuracy: 0.9000\n",
            "\n",
            " Accuracy: 0.9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4rmeKMN_y5lP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}