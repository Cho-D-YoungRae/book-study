# 내용 정리

[docker](https://hub.docker.com/r/apache/kafka)문서에 따라 docker-compose 멀티노드로 구성

## Chapter 01. 들어가며

카프카는 각각의 애플리케이션끼리 연결하여 데이터를 처리하는 것이 아니라 한 곳에 모아 처리할 수 있도록 중앙 집중화

카프카를 중앙에 배치함으로써 소스 애플리케이션과 타깃 애플리케이션 사이의 의존도를 최소화하여 커플링을 완화

데이터 포맷 사실상 제한 없음

- 직렬화, 역직렬화를 통해 ByteArray 로 통신
- 기본적으로 제공하는 직렬화, 역직렬화 클래스와 커스텀 가능

아파치 카프카가 왜 데이터 파이프라인으로 적합한지

- 높은 처리량
  - 배치처리
    - 프로듀서가 브로커로 데이터를 보낼 때와 컨슈머가 브로커로부터 데이터를 받을 때 모두 묶어서 전송
    - 네트워크 통신 횟수 감소
  - 파티션
    - 병렬처리
- 확장성
  - 스케일 아웃과 스케일 인 가능
- 영속성
  - 데이터를 메모리에 저장하지 않고 파일 시스템에 저장
  - 페이지 캐시를 사용하므로 파일 시스템에 저장하고 데이터를 저장, 전송하더라도 처리량 높음
  - 디스크 기반의 파일 시스템을 활용한 덕분에 브로커 애플리케이션이 장애 발생으로 인해 급작스럽게 종료되더라고 프로세스를 재시작하여 안전하게 데이터를 다시 처리할 수 있음
- 고가용성
  - 3개 이상의 서버들로 운영되는 카프카 클러스터는 일부 서버에 장애가 발생하더라도 무중단으로 안전하고 지속적으로 데이터를 처리할 수 있음

카프카 클러스터를 1대, 2대가 아닌 3대 이상의 브로커들로 구성해야 하는 이유

> 1대로 운영할 경우 브로커의 장애는 서비스의 장애로 이어짐.  
> 2대로 운영할 경우 브로커 간 데이터가 복제되는 시간차이로 인해 일부 데이터가 유실될 가능성 있음.  
> 유실을 막기 위해서 `min.insync.replicas` 옵션을 사용 할 수 있음. 이 옵션을 사용하려면 브로커를 3대 이상으로 운영해야 함. 그래야 3대 중 1개의 브로커에 장애가 나더라도 지속적으로 데이터를 처리할 수 있음.  
> `min.insync.replicas` 옵션값보다 작은 수의 브로커가 존재할 때는 토픽에 더는 데이터를 넣을 수 없음.

## Chapter 02. 카프카 빠르게 시작해보기

토픽의 파티션을 늘릴 수 있지만 줄일 수는 없다.

메시지 키가 null인 경우에는 프로듀서가 파티션으로 전송할 때 레코드 배치 단위로 라운드 로빈으로 전송한다.

메시지 키가 존재하는 경우에는 키의 해시값을 작성하여 존재하는 파티션 중 한 개에 할당된다. 이로 인해 메시지 키가 동일한 경우에는 동일한 파티션으로 전송된다.

메시지 키와 파티션 할당은 프로듀서에서 설정된 파티셔너에 의해 결정된다. -> 그러므로 달라진 수도 있긴 함.

파티션 개수가 늘어나면 새로 프로듀신 되는 레코드들은 어느 파티션으로 갈까?

> 일관성이 보장되지 않는다. 만약 파티션을 추가하더라도 이전에 사용하던 메시지 키의 일관성을 보장하고 싶다면 커스텀 파티셔너를 만들어서 운영해야 한다.

컨슈머 그룹을 통해 가져간 토픽의 메시지는 가져간 메시지에 대해 커밋을 한다.

커밋이란 컨슈머가 특정 레코드까지 처리를 완료했다고 레코드의 오프셋 번호를 카프카 브로커에 저장하는 것이다.

토픽의 모든 파티션으로부터 동일한 중요도로 데이터를 가져간다. 이로 인해 프로듀서가 토픽에 넣은 데이터의 순서와 컨슈머가 토픽에서 가져간 데이터의 순서가 달라지게 되는 것이다.

토픽에 넣은 데이터의 순서를 보장하고 싶다면 가장 좋은 방법은 파티션 1개로 구성된 토픽을 만드는 것이다.

컨슈머의 랙이 증가하고 있다는 의미는 프로듀서가 데이터를 토픽으로 전달하는 속도에 비해 컨슈머의 처리량이 느리다는 증거이기 때문이다.

적재된 토픽의 데이터를 삭제하면, 특정 레코드 하나만 삭제되는 것이 아니라 파티션에 존재하는 가장 오래된 오프셋부터 지정한 오프셋까지 삭제된다. 토픽의 파티션에 저장된 특정 데이터만 삭제할 수 없다.