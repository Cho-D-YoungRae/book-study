# 내용 정리

[docker](https://hub.docker.com/r/apache/kafka)문서에 따라 docker-compose 멀티노드로 구성

> 스트림즈, 커넥트, 미러메이커와 운영 관련된 것들은 자세히 보지 않음. 애플리케이션 구현과 관련된 부분만 집중적으로 학습.

## Chapter 01. 들어가며

카프카는 각각의 애플리케이션끼리 연결하여 데이터를 처리하는 것이 아니라 한 곳에 모아 처리할 수 있도록 중앙 집중화

카프카를 중앙에 배치함으로써 소스 애플리케이션과 타깃 애플리케이션 사이의 의존도를 최소화하여 커플링을 완화

데이터 포맷 사실상 제한 없음

- 직렬화, 역직렬화를 통해 ByteArray 로 통신
- 기본적으로 제공하는 직렬화, 역직렬화 클래스와 커스텀 가능

아파치 카프카가 왜 데이터 파이프라인으로 적합한지

- 높은 처리량
    - 배치처리
        - 프로듀서가 브로커로 데이터를 보낼 때와 컨슈머가 브로커로부터 데이터를 받을 때 모두 묶어서 전송
        - 네트워크 통신 횟수 감소
    - 파티션
        - 병렬처리
- 확장성
    - 스케일 아웃과 스케일 인 가능
- 영속성
    - 데이터를 메모리에 저장하지 않고 파일 시스템에 저장
    - 페이지 캐시를 사용하므로 파일 시스템에 저장하고 데이터를 저장, 전송하더라도 처리량 높음
    - 디스크 기반의 파일 시스템을 활용한 덕분에 브로커 애플리케이션이 장애 발생으로 인해 급작스럽게 종료되더라고 프로세스를 재시작하여 안전하게 데이터를 다시 처리할 수 있음
- 고가용성
    - 3개 이상의 서버들로 운영되는 카프카 클러스터는 일부 서버에 장애가 발생하더라도 무중단으로 안전하고 지속적으로 데이터를 처리할 수 있음

카프카 클러스터를 1대, 2대가 아닌 3대 이상의 브로커들로 구성해야 하는 이유

> 1대로 운영할 경우 브로커의 장애는 서비스의 장애로 이어짐.  
> 2대로 운영할 경우 브로커 간 데이터가 복제되는 시간차이로 인해 일부 데이터가 유실될 가능성 있음.  
> 유실을 막기 위해서 `min.insync.replicas` 옵션을 사용 할 수 있음. 이 옵션을 사용하려면 브로커를 3대 이상으로 운영해야 함. 그래야 3대 중 1개의 브로커에 장애가 나더라도 지속적으로 데이터를
> 처리할 수 있음.  
> `min.insync.replicas` 옵션값보다 작은 수의 브로커가 존재할 때는 토픽에 더는 데이터를 넣을 수 없음.

## Chapter 02. 카프카 빠르게 시작해보기

토픽의 파티션을 늘릴 수 있지만 줄일 수는 없다.

메시지 키가 null인 경우에는 프로듀서가 파티션으로 전송할 때 레코드 배치 단위로 라운드 로빈으로 전송한다.

메시지 키가 존재하는 경우에는 키의 해시값을 작성하여 존재하는 파티션 중 한 개에 할당된다. 이로 인해 메시지 키가 동일한 경우에는 동일한 파티션으로 전송된다.

메시지 키와 파티션 할당은 프로듀서에서 설정된 파티셔너에 의해 결정된다. -> 그러므로 달라진 수도 있긴 함.

파티션 개수가 늘어나면 새로 프로듀신 되는 레코드들은 어느 파티션으로 갈까?

> 일관성이 보장되지 않는다. 만약 파티션을 추가하더라도 이전에 사용하던 메시지 키의 일관성을 보장하고 싶다면 커스텀 파티셔너를 만들어서 운영해야 한다.

컨슈머 그룹을 통해 가져간 토픽의 메시지는 가져간 메시지에 대해 커밋을 한다.

커밋이란 컨슈머가 특정 레코드까지 처리를 완료했다고 레코드의 오프셋 번호를 카프카 브로커에 저장하는 것이다.

토픽의 모든 파티션으로부터 동일한 중요도로 데이터를 가져간다. 이로 인해 프로듀서가 토픽에 넣은 데이터의 순서와 컨슈머가 토픽에서 가져간 데이터의 순서가 달라지게 되는 것이다.

토픽에 넣은 데이터의 순서를 보장하고 싶다면 가장 좋은 방법은 파티션 1개로 구성된 토픽을 만드는 것이다.

컨슈머의 랙이 증가하고 있다는 의미는 프로듀서가 데이터를 토픽으로 전달하는 속도에 비해 컨슈머의 처리량이 느리다는 증거이기 때문이다.

적재된 토픽의 데이터를 삭제하면, 특정 레코드 하나만 삭제되는 것이 아니라 파티션에 존재하는 가장 오래된 오프셋부터 지정한 오프셋까지 삭제된다. 토픽의 파티션에 저장된 특정 데이터만 삭제할 수 없다.

## Chapter 03. 카프카 기본 개념 설명

파일 시스템에 저장하기 때문에 파일 입출력으로 인해 속도 이슈가 발생하지 않을까 의문을 가질 수 있다. 그러나 카프카는 페이지 캐시를 사용하여 디스크 입출력 속도를 높여서 이 문제를 해결했다.
페이지 캐시란 OS에서 파일 입출력의 성능 향상을 위해 만들어 놓은 메모리 영역을 뜻한다.

- 한번 읽은 파일의 내용은 메모리의 캐시 영역에 저장시킨다.
- 추후 동일한 파일의 접근이 일어나면 디스크에서 읽지 않고 메모리에서 직접 읽는 방식이다.
- 이러한 특징 때문에 카프카 브로커를 실행하는데 힙 메모리 사이즈를 크게 설정할 필요가 없다.

데이터 복제는 카프카를 장애 허용 시스템으로 동작하도록 하는 원동력이다.

데이터 복제는 파티션 단위로 이루어진다. 토픽을 생성할 때 파티션의 복제 개수도 같이 설정되는데 직접 옵션을 선택하지 않으면 브로커에 설정된 옵션 값을 따라간다.
복제 개수의 최솟값은 1, 최댓값은 브로커 개수이다.

복제된 파티션은 리더와 팔로워로 구성된다. 프로듀서 또는 컨슈머와 직접 통신하는 파티션을 리더, 나머지 복제 데이터를 가지고 있는 파티션을 팔로워라고 부른다.

팔로워 파티션들은 리더 파티션의 오프셋을 확인하여 현재 자신이 가지고 있는 오프셋과 차이가 나는 경우 리더 파티션으로부터 데이터를 가져와서 자신의 파티션에 저장하는데, 이 과정을 `복제`라고 부른다.

리더 파티션을 가진 브로커에 장애가 발생하면 팔로워 파티션 중 하나가 리더 파티션 지위를 넘겨받는다.

클러스터의 다수 브로커 중 한 대가 `컨트롤러`의 역할을 한다. 컨트롤러는 다른 브로커들의 상태를 체크하고 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배한다.
컨트롤러 역할을 하는 브로커에 장애가 생기면 다른 브로커가 컨트롤러 역할을 한다.

오직 브로커만이 데이터를 삭제할 수 있다. 데이터 삭제는 파일 단위로 이루어지는데 이단위를 '로그 세그먼트'라고 부른다.
이 세그먼트에는 다수의 데이터가 들어 있기 때문에 일반적인 데이터베이스처럼 특정 데이터를 선별해서 삭제할 수 없다.
세그먼트는 데이터가 쌓이는 동안 파일 시스템으로 열려있으며 카프카 브로커에 log.segment.bytes 또는 log.segment.ms 옵션에 값이 설정되면 세그먼트 파일이 닫힌다.
기본값은 1GB 이고, 작은 용량으로 설정할 수 있으나 너무 작은 용량으로 설정하면 데이터들을 저장하는 동안 세그먼트 파일을 자주 여닫음으로써 부하가 발생할 수 있으므로 주의해야 한다.  
닫힌 세그먼트 파일은 log.retention.bytes 또는 log.retention.ms 옵션에 설정값이 넘으면 삭제된다. 닫힌 세그먼트 파일을 체크하는 간격은
log.retention.check.interval.ms 로 설정할 수 있다.

커핏한 오프셋은 __consumer_offsets 토픽에 저장한다.

클러스터의 다수 브로커 중 한 대는 `코디네이터`의 역할을 수행한다. 코디네이터는 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할을 한다.
파티션을 컨슈머로 재할당하는 리밸런스 과정을 맡는다.

주키퍼는 카프카의 메타데이터를 관리하는 데에 사용된다.

파티션은 카프카의 병령처리의 핵심으로써 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭된다.  
컨슈머 개수를 늘림과 동시에 파티션 개수도 늘리면 처리량이 증가하는 효과를 볼 수 있다.

파티션은 자료구조에서 접하는 큐와 비슷한 구조라고 생각하면 쉽다. 일반적인 자료구조로 사용되는 큐는 데이터를 가져가면 레코드를 삭제하지만 카프케아세넌 삭제하지 않는다.  
이러한 특징 때문에 토픽의 레코드는 다양한 목적을 가진 여러 컨슈머 그룹들이 토픽의 데이터를 여러 번 가져갈 수 있다.

레코드는 타임스탬프, 메시지 키, 메시지 값, 오프셋, 헤더로 구성되어 있다. 브로커에 한번 적재된 레코드는 수정할 수 없고 로그 리텐션 기간 또는 용량에 따라서만 삭제된다.

- 타임스탬프
    - 프로듀서에서 해당 레코드가 생성된 시점의 유닉스 타임이 설정
    - 프로듀서가 레코드를 생성할 때 임의의 타임 스탬프 값을 설정할 수 있음
    - 토픽 설정에 따라 브로커에 적재된 시간으로 설정될 수 있음
- 메시지 키
    - 메시지 값을 순서대로 처리하거나 메시지 값의 종료를 나타내기 위해 사용
    - 파티션 개수가 변경되면 메시지 키와 파티션 매칭이 달리질 수 있음
    - 메시지 키를 선언하지 않으면(null) 프로듀서 기본 설정 파티셔너에 따라서 파티션에 분배되어 적재
- 메시지 값
    - 실질적으로 처리할 데이터
    - 메시지 키와 값은 직렬화되어 브로커로 전송되므로 컨슈머가 이용할 때는 동일한 형태로 역직렬화
- 오프셋
    - 0 이상의 숫자
    - 직접 지정할 수 없고 브로커에 저장될 때 이전에 전송된 레코드의 오프셋 + 1 값으로 생성
- 헤더
    - 레코드의 추가적인 정보를 담는 메타데이터 저장소 용도
    - 키 값 형탤로 데이터를 추가
    - 레코드의 속성(스키마 버전 등)을 저장하여 컨슈머에서 참조할 수 있음

프로듀서는 압축 옵션을 통해 브로커로 전송 시 압축 방식을 정할 수 있다.
압축을 하면 데이터 전송 시 네트워크 처리량에 이득을 볼 수 있지만 압출을 하는 데에 CPU 또는 메모리 리소스를 사용하므로 사용환경에 따라 적절한 압축 옵션을 사용하는 것이 중요하다.
컨슈머 애플리케이션에서 압축한 메시지를 풀 때도 컨슈머 애플리케이션의 리소스가 사용된다.

프로듀서 옵션

- 필수
    - bootstrap.servers
    - key.serializer
    - value.serializer
- 선택
    - acks
        - 프로듀서가 전송한 데이터가 브로커들에 정상적으로 저장되었는지 전송 성공 여부를 확인하는 데에 사용하는 옵션이다. 설정 값에 따라 데이터의 유실 가능성이 달라진다.
        - 값
            - 1
                - 기본값
                - 리더 파티션에 데이터가 저장되면 전송 성공으로 판단
            - 0
                - 프로듀서가 전송한 즉시 브로커에 데이터 저장 여부와 상관없이 성공으로 판단
            - -1(all)
                - 토픽의 min.insync.replicas 개수에 해당하는 리더 파티션과 팔로워 파티션에 데이터가 저장되면 성공하는 것으로 판단
    - buffer.memory
    - retries
        - 프로듀서가 브로커로부터 에러를 받고 난 뒤 재전송을 시도하는 횟수.
    - batch.size
        - 배치로 전송할 레코드 최대 용량
    - linger.ms
        - 배치를 전송하기 전까지 기다리는 최소 시간
        - 기본값 0
    - partitioner.class
    - enable.idempotence
    - transactional.id

컨슈머를 운영하는 방법은 크게 2가지 있다.

1. 1개 이상의 컨슈머로 이루어진 컨슈머 그룹을 운영하는 것
    - 1개의 파티션은 최대 1개의 컨슈머에 할당 가능, 1개의 컨슈머는 여러 개의 파티션에 할당 가능
    - 이러한 특징으로 컨슈머 그룹의 컨슈머 개수는 가져가고자 하는 토픽의 파티션 개수보다 같거나 작아야 함
2. 토픽의 특정 파티션만 구독하는 컨슈머를 운영하는 것

컨슈머 그룹은 다른 컨슈머 그룹과 격리되는 특징을 가지고 있다. 따라서 각기 다른 역할을 하는 컨슈머 그룹끼리 영향을 받지 않게 처리할 수 있다는 장점이 있다.

컨슈머 그룹의 컨슈머에 장애가 발생하면? 장애가 발생한 컨슈머에 할당된 파티션은 장애가 발생하지 않은 컨슈머에 소유권이 넘어가는데, 이러한 과정을 리밸런싱이라고 부른다.

리밸런싱은 크게 두 가지 상황에 일어난다.

1. 컨슈머가 추가되는 상황
2. 컨슈머가 제외되는 상황

리밸런싱은 컨슈머가 데이터를 처리하는 도중에 언제든지 발생할 수 있으므로 데이터 처리 중 발생한 리밸런싱에 대응하는 코드를 작성해야 한다.

가용성을 높이면서도 안정적인 운영을 도와주는 리밸런싱은 유용하지만 자주 일어나서는 안 된다.
리밸런싱이 발생할 때 파티션의 소유권을 컨슈머로 재할당하는 과정에서 해당 컨슈머 그룹의 컨슈머들이 토픽의 데이터를 읽을 수 없기 때문이다.
코디네이터는 리밸런싱을 발동시키는 역할을 하는데 컨슈머 그룹의 컨슈머가 추가되고 삭제될 때를 감지한다.

데이터 처리의 중복이 발생하지 않게 하기 위해서는 컨슈머 애플리케이션이 오프셋 커밋을 정상적으로 처리했는지 검증해야만 한다.

오프셋 커밋은 컨슈머 애플리케이션에서 명시적, 비명시적으로 수행할 수 있다.

- 기본 옵션은 `poll()` 수행될 때 일정 간격마다 오프셋을 커밋하도록 enable.auto.commit=true로 설정되어 있다.
    - 이렇게 일정 간격마다 자동으로 커밋되는 것은 비명시 '오프셋 커밋'이라고 부른다.
    - 이 옵션은 auto.commit.interval.ms 에 설정된 값과 함께 사용되는데 해당 값 이상 지났을 때 그 시점까지 읽은 레코드의 오프셋을 커밋한다.
    - 비명시 오프셋 커밋은 편리하지만 `poll()` 이후 리밸런싱 또는 컨슈머 강제 종료 발생 시 컨슈머가 처리하는 데이터가 중복 또는 유실될 수 있는 가능성이 있는 취약한 구조를 가지고 있다.
- 명시적으로 오프셋을 커밋하려면 `poll()` 호출 이후에 반환받은 데이터의 처리가 완료되고 `commitSync()` 를 호출하면 된다.
    - `commitSync()` 은 `poll()` 통해 반환된 레코드의 가장 마지막 오프셋을 기준으로 커밋을 수행한다.
    - `commitSync()`은 브로커에 커밋 요청을 하고 커밋이 정상적으로 처리되었는지 응답하기까지 기다리는데 이는 컨슈머의 처리량에 영향을 끼친다.
    - 이를 해결하기 위해 `commitAsync()` 를 사용할 수 있다.
    - 하지만 비동기 커밋은 커밋 요청이 실패했을 경우 현재 처리 중인 데이터의 순서를 보장하지 않으며 데이터의 중복 처리가 발생할 수 있다.

컨슈머는 `poll()` 을 호출하는 시점에 클러스터에서 데이터를 가져오는 것은 아니다.
컨슈머 애플리케이션을 실행하게 되면 컨슈머 내부에서 Fetcher 인스턴스가 생성되어 `poll()`을 호출하기 전에 미리 레코드들을 내부 큐로 가져온다.
`poll()` 를 호출하면 컨슈머는 내부 큐에 있는 레코드들을 반환받아 처리를 수행한다.

컨슈머 주요 옵션

- 필수
    - bootstrap.servers
    - key.deserializer
    - value.deserializer
- 선택
    - group.id
    - auto.offset.reset
        - 컨슈머 그룹이 특정 파티션을 읽을 때 저장된 컨슈머 오프셋이 없는 경우 어느 오프셋부터 읽을지 선택하는 옵션이다.
        - 이미 컨슈머 오프셋이 있다면 이 옵션값은 무시된다.
        - 값
            - latest(기본값): 가장 최근 오프셋부터
            - earliest: 가장 오래전 오프셋부터
            - none: 컨슈머 그룹이 커밋한 기록이 있는지 찾아봄. 없으면 오류 반환. 있다면 기존 커밋 기록 이후 오프셋부터 읽기 시작.
    - enable.auto.commit
    - auto.commit.interval.ms
    - max.poll.records
        - `poll()` 메서드로 가져올 레코드의 최대 개수
        - 기본값 500
    - session.timeout.ms
        - 컨슈머가 브로커와 연결이 끊기는 최대 시간
        - 이 시간 내에 하트비트를 전송하지 않으면 브로커는 컨슈머에 이슈가 발생했다고 가정하고 리밸런싱
        - 보통 하트비트 시간 간격의 3배로 설정
        - 기본값 10000(10초)
    - heartbeat.interval.ms
        - 하트비트를 전송하는 시간 간격
        - 기본값 3000(3초)
    - max.poll.interval.ms
        - `poll()` 을 호출하는 간격의 최대 시간
        - `poll()` 을 호출한 이후에 데이터를 처리하는 데에 시간이 너무 많이 걸리는 경우 비정상으로 판단하고 리밸런싱을 시작
        - 기본값 300000(5분)
    - isolation.level

`commitSync()` 는 파라미터 없이 호출하면 `poll()` 로 반환된 가장 마지막 레코드의 오프셋을 기준으로 커밋되고, 개별 레코드 단위로 커밋할 수도 있다.

`commitAsync()` 도 마찬가지로 파라미터 없이 호출하면 `poll()` 로 반환된 가장 마지막 레코드의 오프셋을 기준으로 커밋된다.
비동기로 커밋 응답을 받기 때문에 callback 함수를 파라미터로 받아서 결과를 얻을 수 있다.

`poll()` 을 통해 반환받은 데이터를 모두 처리하기 전에 리밸런스가 발생하면 데이터를 중복 처리할 수 있다.
`poll()` 을 통해 받은 데이터 중 일부를 처리했으나 커밋하지 않았기 때문이다.

리밸런스 발생 시 데이터를 중복 처리하지 않게 하기 위해서는 리밸런스 발생 시 처리한 데이터를 기준으로 커밋을 시도해야 한다.

리밸런스 발생을 감지하기 위해 카프카 라이브러리는 `ConsumerRebalanceListener` 인터페이스를 제공한다.

- `onPartitionsAssigned()` : 리밸런스가 끝난 뒤에 파티션이 할당 완료되면 호출되는 메서드
- `onPartitionsRevoked()` : 리밸런스가 시작되기 직전에 호출. 여기에 커밋을 구현하여 처리할 수 있음.

파티션을 컨슈머에 명시적으로 할당하여 운영할 수도 있다(`assign()` 메서드 사용).
직접 컨슈머가 특정 토픽, 특정 파티션에 할당되므로 리밸런싱하는 과정이 없다.

정상적으로 종료되지 않은 컨슈머는 세션 타임아웃이 발생할 때까지 컨슈머 그룹에 남게 된다. 이로 인해 파티션 데이터는 소모되지 못하고 컨슈머 랙이 늘어나게 된다.

컨슈머를 안전하게 종료하기 위해 `KafkaConsumer.wakeup()` 메서드를 지원한다. `wakeup()` 가 실행된 후 `poll()` 가 호출되면 `WakeupException` 이 발생한다.
`WakeupException` 이 발샌한 뒤에는 데이터 처리를 위해 사용한 자원들을 해제하면 된다. 그리고 마지막에는 `close()` 메서드를 호출하여 컨슈머를 안전하게 종료한다.
`close()` 를 호출하면 해당 컨슈머는 더는 동작하지 않는다는 것을 명시적으로 알려주므로 컨슈머 그룹에서 이탈되고 나머지 컨슈머들이 파티션을 할당받게 된다.
`wakeup()` 은 셧다운 훅에서 실행하면 된다.

`AdminClient` 를 활용하는 예시

- 카프카 컨슈머를 멀티 스레드로 생성할 때, 구독하는 토픽의 파티션 개수만큼 스레드를 생성
- 웹 대시보드 구현
- 특정 토픽의 데이터양이 늘어남을 감지하고 해당 토픽의 파티션을 늘림

`카프카 스트림즈`는 토픽에 적재된 데이터를 Stateful 또는 Stateless 로 실시간 변환하여 다른 토픽에 적재하는 라이브러리이다.

`카프카 커넥트`는 카프카 오픈소스에 포함된 툴 중 하나로 데이터 파이프라인생성 시 반복 작업을 줄이고 효율적인 전송을 이루기 위한 애플리케이션이다.

`카프카 미러메이커2`는 서로 다른 두 개의 카프카 클러스터 간에 토픽을 복제하는 애플리케이션이다.
프로듀서와 컨슈머를 사용해서 직접 미러링하는 애플리케이션을 만들 수 있지만 미러메이커2를 사용하는 이유는 토픽의 모든 것을 복제할 필요성이 있기 때문이다.

## Chapter 04. 카프카 상세 개념 설명

토픽 생성 시 파티션 개수 고려 사항

- 데이터 처리량
- 메시지 키 사용 여부(데이터 처리 순서를 지켜야 하는 경우)
- 브로커, 컨슈머 영향도

데이터 처리 속도를 올리는 방법

- 컨슈머의 처리량을 늘리는 것
    - 서버 스케일업, GC 튜닝 등...
    - 컨슈머 특성상 다른 시스템들과 연동되기 때문에 일정 수준 이상 처리량을 올리는 것은 매우 어려움
- 컨슈머(스레드)를 추가해서 병렬처리량을 늘리는 것
    - 파티션 개수를 늘리고 파티션 개수만큼 컨슈머를 추가
    - 가장 확실한 방법

프로듀서 전송 데이터량 < 컨슈머 데이터 처리량 * 파티션 개수

> 컨슈머의 데이터 처리량이 프로듀서가 보내는 데이터보다 작다면 컨슈머 랙이 생기고, 데이터 처리 지연이 발생

메시지 키를 사용하고 컨슈머에서 메시지 처리 순서가 보장되어야 한다면 최대한 파티션의 변화가 발생하지 않는 방향으로 운영해야 한다.
만약에 파티션 개수가 변해야 하는 경우에는 기존에 사용하던 메시지 키의 매칭을 그대로 가져가기 위해 커스텀 파티셔너를 개발하고 적용해야 한다.
이러한 어려움 때문에 메시지 키별로 처리 순서를 보장하기 위해서는 파티션 개수를 프로듀서가 전송하는 데이터양보다 더 넉넉하게 잡고 생성하는 것이 좋다.

카프카에서 파티션은 각 브로커의 파일 시스템을 사용하기 때문에 파티션이 늘어나는 만큼 브로커에서 접근하는 파일 개수가 많아진다.
그런데 운영체제에서는 프로세스당 열 수 있는 파일 최대 개수를 제한하고 있다.
그러므로 카프카 브로커가 접근하는 파일 개수를 안정적으로 유지하기 위해서는 각 브로커당 파티션 개수를 모니터링해야 한다.
만약 브로커가 관리하는 파티션 개수가 너무 많다면 파티션 개수를 분산하기 위해서 카프카 브로커 개수를 늘리는 방안도 같이 고려해야 한다.

토픽의 데이터는 시간 또는 용량에 따라 삭제 규칙을 적용할 수 있다. 또는 삭제를 하지 않도록 설정할 수도 있다.

cleanup.policy(삭제 정책)에는 delete 로 데이터의 완전 삭제와 compact(압축)로 동일 메시지 키의 가장 오래된 데이터를 삭제하는 것이 있다.
일반적으로 대부분의 토픽은 delete 정책을 사용한다.

ISR(In-Sync-Replicas)은 리더 파티션과 팔로워 파티션이 모두 싱크가 된 상태를 뜻한다.
이 용어가 나온 이유는 팔로워 파티션이 리더 파티션으로부터 데이터를 복제하는 데에 시간이 걸리기 때문이다.

팔로워 파티션이 `replica.lag.time.max.ms`값보다 더 긴 시간동안 데이터를 가져가지 않는다면 해당 팔로워 파티션에 문제가 생긴 것으로 판단하고 ISR 그룹에서 제외한다.

ISR 로 묶인 리더 파티션과 팔로워 파티션은 파티션에 존재하는 데이터가 모두 동일하기 때문에 팔로워 파티션은 리더 파티션으로 새로 선출될 자격을 가진다.]

일부 데이터 유실이 발생하더라도 서비스를 중단하지 않고 지속적으로 토픽을 사용하고 싶다면 ISR 이 아닌 팔로워 파티션을 리더로 선출하도록 설정할 수 있다.
`unclean.leader.election.enable` 옵션을 true 로 설정하면 되는데 false 로 설정할 경우에는 ISR 이 아닌 팔로워 파티션을 리더 파티션으로 선출하지 않고 리더 파티션이 존재하는
브로커가 다시 시작되기까지 기다린다.
리다 파티션이 존재하는 브로커가 다시 시작될 때까지 기다리는 것은 토픽을 사용하는 서비스가 중단됨을 뜻한다. 대신 동기화 되지 않은 팔로워 파티션이 리더로 선출되지 않기 때문에 데이터 유실은 발생하지 않는다.

`acks` 옵션

- 0, 1, -1(all)
- 프로듀서가 전송한 데이터가 카프카 클러스터에 얼마나 신뢰성 높게 저장할지 지정할 수 있다.
- 옵션에 따라 성능이 달라진 수 있다.
- 복제 개수가 1인 경우는 옵션에 따른 성능 변화가 크지 않지만 안정적으로 데이터를 운영하기 위해서는 복제 개수가 2 이상으로 운영하는 경우가 대부분이다.

`acks` = 0

- 프로듀서가 리더 파티션으로 데이터를 전송했을 때 리더 파티션으로 데이터가 저장되었는지 확인하지 않는다는 뜻이다.
- 리더 파티션은 데이터가 저장된 이후에 데이터가 몇 번째 오프셋에 저장되었는지 리턴하는데, `acks` = 0 인 경우에는 응답 값을 받지 않는다.
- 프로듀서에는 데이터의 전송이 실패했을 때 재시도를 할 수 있도록 `retries`을 설정할 수 있는데, `acks` = 0 인 경우에는 전송 실패를 알 수 없으므로 `retries` 옵션이 무의미하다.
- 데이터가 유실되더라도 프로듀서는 리더 파티션으로부터 응답값을 받지 않기 때문에 전송 속도는 `acks` 가 1 또는 -1인 경우보다 훨씬 빠르다.
    - 데이터가 일부 유실이 발생하더라도 전송 속도가 중요한 경우에는 이 옵션을 사용할 수 있다.

`acks` = 1

- 프로듀서가 보낸 데이터가 리더 파티션에만 정상적으로 적재되었는지 확인한다.
- 만약 리더 파티션에 정상적으로 적재되지 않았다면 재시도할 수 있다.
- 리더 파티션에 적재되었음을 보장하더라도 데이터는 유실될 수 있다.
    - 복제 개수를 2 이상으로 운영할 경우 리더 파티션에 적재가 완료되어 있어도 팔로워 파티션에는 아직 데이터가 동기화되지 않을 수 있는데, 팔로워 파티션이 데이터를 복제하기 직전에 리더 파티션이 있는 브로커에
      장애가 발생하면 동기화되지 못한 일부 데이터가 유실될 수 있기 때문이다.

`acks` = -1 (all)

- 프로듀서가 보낸 데이터가 리더 파티션과 팔로워 파티션에 모두 정상적으로 적재되었는지 확인한다.
- 리더 파티션뿐만 아니라 팔로워 파티션까지 데이터가 적재되었는지 확인하기 때문에 0 또는 1 옵션보다도 속도가 느리다.
- 일부 브로커에 장애가 발생하더라도 프로듀서는 안전하게 데이터를 전송하고 저장할 수 있음을 보장할 수 있다.
- 토픽 단위로 설정 가능한 `min.insync.replicas` 옵션값에 따라 데이터의 안정성이 달라진다.
    - 모든 리더 파티션과 팔로워 파티션의 적재를 뜻하는 것이 아니고 ISR 에 포함된 파티션을 뜻하는 것이기 때문이다.
- `min.insync.replicas` 옵션은 프로듀서가 리더 파티션과 팔로워 파티션에 데이터가 적재되었는지 확인하기 위한 최소 ISR 그룹 파티션 개수이다.
- `min.insync.replicas` = 1 이라면 `acks` = 1 과 동일하기 때문에 2 이상으로 설정했을 떄부터 의미가 있다.

`min.insync.replicas` 를 설정할 때는 복제 개수도 함께 고려해야 한다.
왜냐하면 운영하는 카프카 브로커 개수가 `min.insync.replicas`의 옵션값보다 작은 경우에는 프로듀서가 더는 데이터를 전송할 수 없기 때문이다.
예를 들어 복제 개수를 3으로 설정하고 `min.insync.replicas`를 3으로 설정하면 브로커 3대중 1대에 이슈가 발생하여 동작하지 못하는 상황이 생기면 프로듀서는 데이터를 해당 토픽에 더는 전송할 수
없다.

`min.insync.replicas` 설정할 때는 절대로 브로커 개수와 동일한 숫자로 설정하면 안 된다는 것이다.
예를 들어 브로커 3대로 클러스터를 운영하면서 `min.insync.replicas` 옵션을 3으로 설정하는 경우, 카프카 클러스터의 버전 업글레이드와 같은 상황에 브로커가 롤링 다운 타임이 생기면, 브로커가
1대라도 중단되면 프로듀서가 데이터를 추가할 수 없다.
그러므로 `min.insync.replicas` 옵션값은 브로커 개수 미만으로 설정해서 운영해야 한다.

상용환경에서는 일반적으로 브로커를 3대 이상으로 묶어 클러스터를 운영하는데, 이 점을 고려하여 프로듀서가 가장 안정적으로 보내려면 토픽의 복제 개수는 3, `min.insync.replicas` = 2 로 설정하고
프로듀서는 `acks` = -1 로 설정하는 것을 추천한다.
실제 카프카 클러스터를 운영하면서 브로커가 동시에 2개가 중단되는 일은 극히 드물다.

멱등성 프로듀서 `enable.idempotence`

- 동일한 데이터를 여러 번 전송하더라도 카프카 클러스터에 단 한번만 저장됨을 의미한다.
- 기본 프로듀서의 동작 방식은 적어도 한번 전달을 지원한다.
    - 프로듀서와 브로커 사이의 네트워크 장애로 acks 응답을 받지 못해 재시도하여 데이터가 한 번 이상 전달될 수 있다.
- `enable.idempotence` = true 를 통해 멱등성 프로듀서로 동작하게 할 수 있다.(기본값 false)
- 기본 프로듀서와 달리 데이터를 브로커로 전달할 때 프로듀서 PID(Producer unique ID)와 시퀀스 넘버를 함께 전달한다.
    - 브로커는 이를 확인하여 동일한 메시지의 적재 요청이 오더라도 단 한 번만 데이터를 적재함으로써 프로듀서의 데이터는 정확히 한번 브로커에 적재되도록 동작한다.
- 단, 멱등성 프로듀서는 동일한 세션에서만 정확히 한번 전달을 보장한다.
    - 여기서 말하는 동일한 세션이란 PID의 생명주기를 뜻한다.
    - 멱등성 프로듀서로 동작하는 애플리케이션이 종료되고 재시작하면 PID가 달라진다.
- `enable.idempotence` = true 로 하면 정확히 한번 적재하는 로직이 성립되기 위해 프로듀서의 일부 옵션들이 강제로 설정된다.
    - `retries` = Integer.MAX_VALUE, `acks` = all

`트랜잭션 프로듀서`

- 다수의 파티션에 데이터를 저장할 경우 모든 데이터에 대해 동일한 원자성을 만족시키기 위해 사용된다.
- 컨슈머는 기본적으로 프로듀서가 보내는 데이터가 파티션에 쌓이는 대로 모두 가져가서 처리한다.
    - 그러나 트랜잭션으로 묶인 데이터를 브로커에서 가져갈 때는 트랜잭션으로 처리 완료된 데이터만 쓰고 읽게 된다.
- 트랜잭션 프로듀서는 사용자가 보낸 데이터를 레코드로 파티션에 저장할 뿐만 아니라 트랜잭션의 시작과 끝을 표현하기 위해 트랜잭션 레코드를 한 개 더 보낸다.
    - 트랜잭션 컨슈머는 파티션에 저장된 트랜잭션 레코드를 보고 트랜잭션이 완료되었음을 확인하고 데이터를 가져간다.
    - 트랜잭션 레코드도 레코드의 특성은 그대로 가지고 있기 떄문에 파팃녀에 저장되어 오프셋을 한 개 차지한다.

카프카는 처리량을 늘리기 위해 파티션과 컨슈머 개수를 늘려서 운영할 수 있다.
파티션을 여러 개로 운영하는 경우 데이터를 병렬처리하기 위해서 파티션 개수와 컨슈머 개수를 동일하게 맞추는 것이 가장 좋은 방법이다.
n개의 스레드를 가진 1개의 프로세스를 운영하거나 1개의 스레드를 가진 프로세스 n개를 운영하는 방법도 있다.

멀티스레드로 컨슈머를 안전하게 운영하려면 하나의 컨슈머 스레드에서 예외적 상황(ex. OutOfMemoryException)이 발생할 경우 프로세스 자체가 종료될 수 있고,
이로 인해 데이터 처리에서 중복 또는 유실이 발생할 수 있으므로 컨슈머 스레드 가ㅏㄴ에 영향이 미치지 않도록 스레드 세이프 로직, 변수를 적용해야 한다.

컨슈머를 멀티 스레드로 활용하는 방식

1. 컨슈머 스레드는 1개, 데이터 처리를 담당하는 워커 스레드 여러개
    - 데이터 처리가 끝나지 않았음에도 불구하고 커밋을 해서 리밸런싱, 컨슈머 장애시에 데이터 유실이 발생할 수 있다.
    - 스레드 처리의 시간이 다를 수 있으므로, 레코드의 순서가 뒤바뀌는 현상이 발생할 수 있다.
    - 레코드 처리에 있어 중복이 발생하거나 데이터의 역전현상이 발생해도 되며 매우 빠른 처리 속도가 필요한 데이터 처리에 적합하다.
        - 서버 리소스(CPU, 메모리 등) 모니터링 파이프라인, IoT 서비스 센터 데이터 수집 파이프라인 등
2. 컨슈머 인스턴스에서 `poll()` 메서드를 호출하는 스레드를 여러개
    - 파티션 개수만큼 컨슈머 스레드 개수를 늘려서 운영할 수 있다.

`컨슈머 랙(LAG)`은 토픽의 최신 오프셋(LOG-END_OFFSET)과 컨슈머 오프셋(CURRENT-OFFSET) 간의 차이다.
컨슈머 랙은 컨슈머 그룹과 토픽, 파티션별로 생성된다. 1개의 토픽에 3개의 파티션이 있고 1개의 컨슈머 그룹이 토픽을 구독하여 데이터를 가져가면 컨슈머 랙은 총 3개가 된다.

프로듀서가 보내는 데이터 양이 컨슈머의 데이터 처리량보다 크다면 컨슈머 랙은 늘어난다.
반대로 프로듀서가 보내는 데이터양이 컨슈머의 데이터 처리량보다 적으면 컨슈머 랙은 줄어들고 최솟값은 0으로 지연이 없음을 뜻한다.

컨슈머 랙을 모니터링하는 것은 카프카를 통한 데이터 파이프라인을 운영하는 데에 핵심적인 역할을 한다.
컨슈머 랙을 모니터링함으로써 컨슈머의 장애를 확인할 수 있고, 파티션 개수를 정하는 데에 참고할 수 있기 때문이다.

컨슈머 배포

- 중단 배포
    - 컨슈머 애플리케이션을 완전히 종료한 이후에 신규 버전 애플리케이션을 배포하는 방식
    - 한정된 서버 자원을 운영하는 기업에 적합
    - 기존 컨슈머 애플리케이션이 종료되면 더는 토픽의 데이터를 가져갈 수 없기 때문에 컨슈머 랙 증가
    - 신규 컨슈머 애플리케이션의 배포에 이슈가 생겨 배포와 실행이 늦어지면 해당 파이프라인을 운영하는 서비스는 계속 중단될 수 있음
    - 신규 애플리케이션의 실행 전후를 명확하게 특정 오프셋 지점으로 나눌 수 있음
        - 신규 배포한 애플리케이션에 이슈가 발생해서 롤백할 때 유용
- 무중단 배포
    - 블루/그린 배포
        - 이전 버전 애플리케이션과 신규 버전 애플리케이션을 동시에 띄워놓고 트래픽을 전환하는 방법
        - 파티션 개수와 컨슈머 개수를 동일하게 실행하는 애플리케이션을 운영할 때 유용
            - 신규 버전 애플리케이션을 배포하고 동일 컨슈머 그룹 파티션을 구독하도록 실행하면 신규 버전 애플리케이션의 컨슈머들은 파티션을 할당 받지 못하고 유휴 상태(idle)로 기다릴 수 있기 떄문
            - 파티션 개수와 컨슈머 개수가 동일하게 운영하고 있지 않다면 일부 파티션은 기존 애플리케이션에 하당되고 일부 파티션은 신규 애플리케이션에 할당되어 섞일 수 있음
        - 신규 버전 애플리케이션이 준비되고 기존 애플리케이션을 모두 중단하면 리밸런싱으로 파티션은 모두 신규 컨슈머와 연동
        - 리밸런싱이 한번만 발생하기 때문에 많은 수의 파티션을 운영하는 경우에도 짧은 리밸런스 시간으로 배포를 수행
    - 롤링 배포
        - 리소스 낭비를 줄이면서 무중단 배포를 할 수 있음
        - 파티션 개수가 인스턴스 개수와 같거나, 그보다 많아야 함
        - 인스턴스 1개씩 신규버전으로 실행
        - 인스턴스 개수만큼 리밸런스 발생
        - 파티션 개수가 많을 수록 리밸런스 시간도 길어지므로 파티션 개수가 많지 않은 경우에 효과적인 방법
    - 카나리 배포
        - 일부 인스턴스 먼저 신규 버전 애플리케이션으로 배포, 이후 나머지는 롤링 또는 블루/그린 수행 가능

스프링 카프카 라이브러리는 카프카 클라이언트에서 사용하는 여러가지 패턴을 미리 제공한다.
예를 들어, 컨슈머를 멀티 스레드로 운영하기 위한 스레드 풀 로직은 스프링 카프카를 사용하면 concurrency 옵션 하나만 추가하면 어렵지 않게 구현할 수 있다.

스프링 카프카 프로듀서는 `KafkaTemplate`을 사용하여 데이터를 전송할 수 있다.
프로듀서 팩토리 클래스를 통해서 이를 생성할 수 있다.
카프카 템플릿은 스프링 카프카에서 제공하는 기본 카프카 템플릿을 사용할 수도 있고, 직접 사용자가 카프카 템플릿을 프로듀서 팩토리로 생성할 수 있다.

스프링 카프카의 컨슈머는 기존 컨슈머를 2개 타입으로 나누고 커밋을 7가지로 나누어 세분화했다.

타입

- 레코드 리스너(MessageListener)
    - 단 1개의 레코드를 처리
- 배치 리스너(BatchMessageListener)
    - 한 번에 여러 개 레코드들을 처리
- 기본 리스너 타입은 레코드 리스너
- 이외의 파생된 형태의 리스너들이 있음
    - 매뉴얼 커밋을 사용할 경우 Acknowledging 이 붙고, KafkaConsumer 인스턴스에 직접 접근하여 컨트롤하고 싶다면 ConsumerAware 이 붙음

| 타입     | 리스너 이름                                           | 설명                                                           |
|--------|--------------------------------------------------|--------------------------------------------------------------|
| RECORD | `MessageListener`                                | Record 인스턴스 단위로 프로세싱, 오토 커밋 또는 컨슈머 컨테이너의 `AckMode`를 사용하는 경우  |
| RECORD | `AcknowledgingMessageListener`                   | Record 인스턴스 단위로 프로세싱, 매뉴얼 커밋을 사용하는 경우                        |
| RECORD | `ConsumerAwareMessageListener`                   | Record 인스턴스 단위로 프로세싱, 컨슈머 객체를 활용하고 싶은 경우                     |
| RECORD | `AcknowledgingConsumerAwareMessageListener`      | Record 인스턴스 단위로 프로세싱, 매뉴얼 커밋을 사용하고 컨슈머 객체를 활용하고 싶은 경우        |
| BATCH  | `BatchMessageListener`                           | Records 인스턴스 단위로 프로세싱, 오토 커밋 또는 컨슈머 컨테이너의 `AckMode`를 사용하는 경우 |
| BATCH  | `BatchAcknowledgingMessageListener`              | Records 인스턴스 단위로 프로세싱, 매뉴얼 커밋을 사용하는 경우                       |
| BATCH  | `BatchConsumerAwareMessageListener`              | Records 인스턴스 단위로 프로세싱, 컨슈머 객체를 활용하고 싶은 경우                    |
| BATCH  | `BatchAcknowledgingConsumerAwareMessageListener` | Records 인스턴스 단위로 프로세싱, 매뉴얼 커밋을 사용하고 컨슈머 객체를 활용하고 싶은 경우       |

기존 카프카 클라이언트 라이브러리에서 컨슈머를 구현할 때 가장 어려운 부분이 커밋을 구현하는 것이다.
카프카 컨슈머에서 커밋을 직접 구현할 때는 오토 커밋, 동기 커밋, 비동기 커밋 크게 세 가지로 나뉘지만 실제 운영환경에서는 다양한 종류의 커밋을 구현해서 사용하기 때문이다.

스프링 카프카에서는 커밋아록 부르지 않고 `AckMode`라고 부른다. 프로듀서에서 사용하는 acks 옵션과 동일한 어원인 Acknowledgment 를 사용하므로 AckMode 와 acks 를 혼동하지 않도록
주의해야 한다.
기본값은 BATCH 이고 컨슈머의 enable.auto.commit 옵션은 false 로 설정된다.

| `AckMode`          | 설명                                                                                                                                                                                                                     |
|--------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `RECORD`           | 레코드 단위로 프로세싱 이후 커밋                                                                                                                                                                                                     |
| `BATCH`            | `poll()`메서드로 호출된 레코드가 모두 처리된 이후 커밋. 스프링 카프카 컨슈머의 `AckMode` 기본값.                                                                                                                                                        |
| `TIME`             | 특정 시간 이후에 커밋. 이 옵션을 사용할 경우에는 시간 간격을 선언하는 `AckTime` 옵션을 설정해야 한다.                                                                                                                                                        |
| `COUNT`            | 특정 개수만큼 레코드가 처리된 이후에 커밋. 이 옵션을 사용할 경우에는 레코드 개수를 선언하는 `AckCount` 옵션을 설정해야 한다.                                                                                                                                           |
| `COUNT_TIME`       | `TIME`, `COUNT` 옵션 중 맞는 조건이 하나라도 나올 경우 커밋                                                                                                                                                                              |
| `MANUAL`           | `Acknowledgement.acknowledge()` 가 호출되면 다음번 `poll()` 때 커밋을 한다. 매번 `acknowledge()` 메서드를 호출하면 `BATCH` 옵션과 동일하게 동작한다. 이 옵션을 사용할 경우에는 `AcknowledgingMessageListener` 또는 `BatchAcknowledgingMessageListener` 를 리스너로 사용해야 한다. |
| `MANUAL_IMMEDIATE` | `Acknowledgement.acknowledge()` 메서드를 호출한 즉시 커밋한다. 이 옵션을 사용할 경우에는 `AcknowledgingMessageListener` 또는 `BatchAcknowledgingMessageListener` 를 리스너로 사용해야 한다.                                                                 |

리스너는 기본 리스너 컨테이너를 사용하거나 컨테이너 팩토리를 사용하여 직접 리스너를 만들어 사용할 수 있다.

`Acknowledgement` 는 커밋을 수행하기 위한 한정적인 메서드만 제공한다.
반면에 컨슈머 인스턴스를 사용하면 동기 커밋과 비동기 커밋을 사용할 수 있다.

서로 다른 설정을 가진 2개 이상의 리스너를 구현하거나 리밸런스 리스너를 구현하기 위해서는 커스텀 리스너 컨테이너를사용해야 한다.
