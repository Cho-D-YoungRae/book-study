# 내용 정리

[docker](https://hub.docker.com/r/apache/kafka)문서에 따라 docker-compose 멀티노드로 구성

> 스트림즈, 커넥트, 미러메이커와 운영 관련된 것들은 자세히 보지 않음. 애플리케이션 구현과 관련된 부분만 집중적으로 학습.

## Chapter 01. 들어가며

카프카는 각각의 애플리케이션끼리 연결하여 데이터를 처리하는 것이 아니라 한 곳에 모아 처리할 수 있도록 중앙 집중화

카프카를 중앙에 배치함으로써 소스 애플리케이션과 타깃 애플리케이션 사이의 의존도를 최소화하여 커플링을 완화

데이터 포맷 사실상 제한 없음

- 직렬화, 역직렬화를 통해 ByteArray 로 통신
- 기본적으로 제공하는 직렬화, 역직렬화 클래스와 커스텀 가능

아파치 카프카가 왜 데이터 파이프라인으로 적합한지

- 높은 처리량
    - 배치처리
        - 프로듀서가 브로커로 데이터를 보낼 때와 컨슈머가 브로커로부터 데이터를 받을 때 모두 묶어서 전송
        - 네트워크 통신 횟수 감소
    - 파티션
        - 병렬처리
- 확장성
    - 스케일 아웃과 스케일 인 가능
- 영속성
    - 데이터를 메모리에 저장하지 않고 파일 시스템에 저장
    - 페이지 캐시를 사용하므로 파일 시스템에 저장하고 데이터를 저장, 전송하더라도 처리량 높음
    - 디스크 기반의 파일 시스템을 활용한 덕분에 브로커 애플리케이션이 장애 발생으로 인해 급작스럽게 종료되더라고 프로세스를 재시작하여 안전하게 데이터를 다시 처리할 수 있음
- 고가용성
    - 3개 이상의 서버들로 운영되는 카프카 클러스터는 일부 서버에 장애가 발생하더라도 무중단으로 안전하고 지속적으로 데이터를 처리할 수 있음

카프카 클러스터를 1대, 2대가 아닌 3대 이상의 브로커들로 구성해야 하는 이유

> 1대로 운영할 경우 브로커의 장애는 서비스의 장애로 이어짐.  
> 2대로 운영할 경우 브로커 간 데이터가 복제되는 시간차이로 인해 일부 데이터가 유실될 가능성 있음.  
> 유실을 막기 위해서 `min.insync.replicas` 옵션을 사용 할 수 있음. 이 옵션을 사용하려면 브로커를 3대 이상으로 운영해야 함. 그래야 3대 중 1개의 브로커에 장애가 나더라도 지속적으로 데이터를
> 처리할 수 있음.  
> `min.insync.replicas` 옵션값보다 작은 수의 브로커가 존재할 때는 토픽에 더는 데이터를 넣을 수 없음.

## Chapter 02. 카프카 빠르게 시작해보기

토픽의 파티션을 늘릴 수 있지만 줄일 수는 없다.

메시지 키가 null인 경우에는 프로듀서가 파티션으로 전송할 때 레코드 배치 단위로 라운드 로빈으로 전송한다.

메시지 키가 존재하는 경우에는 키의 해시값을 작성하여 존재하는 파티션 중 한 개에 할당된다. 이로 인해 메시지 키가 동일한 경우에는 동일한 파티션으로 전송된다.

메시지 키와 파티션 할당은 프로듀서에서 설정된 파티셔너에 의해 결정된다. -> 그러므로 달라진 수도 있긴 함.

파티션 개수가 늘어나면 새로 프로듀신 되는 레코드들은 어느 파티션으로 갈까?

> 일관성이 보장되지 않는다. 만약 파티션을 추가하더라도 이전에 사용하던 메시지 키의 일관성을 보장하고 싶다면 커스텀 파티셔너를 만들어서 운영해야 한다.

컨슈머 그룹을 통해 가져간 토픽의 메시지는 가져간 메시지에 대해 커밋을 한다.

커밋이란 컨슈머가 특정 레코드까지 처리를 완료했다고 레코드의 오프셋 번호를 카프카 브로커에 저장하는 것이다.

토픽의 모든 파티션으로부터 동일한 중요도로 데이터를 가져간다. 이로 인해 프로듀서가 토픽에 넣은 데이터의 순서와 컨슈머가 토픽에서 가져간 데이터의 순서가 달라지게 되는 것이다.

토픽에 넣은 데이터의 순서를 보장하고 싶다면 가장 좋은 방법은 파티션 1개로 구성된 토픽을 만드는 것이다.

컨슈머의 랙이 증가하고 있다는 의미는 프로듀서가 데이터를 토픽으로 전달하는 속도에 비해 컨슈머의 처리량이 느리다는 증거이기 때문이다.

적재된 토픽의 데이터를 삭제하면, 특정 레코드 하나만 삭제되는 것이 아니라 파티션에 존재하는 가장 오래된 오프셋부터 지정한 오프셋까지 삭제된다. 토픽의 파티션에 저장된 특정 데이터만 삭제할 수 없다.

## Chapter 03. 카프카 기본 개념 설명

파일 시스템에 저장하기 때문에 파일 입출력으로 인해 속도 이슈가 발생하지 않을까 의문을 가질 수 있다. 그러나 카프카는 페이지 캐시를 사용하여 디스크 입출력 속도를 높여서 이 문제를 해결했다. 
페이지 캐시란 OS에서 파일 입출력의 성능 향상을 위해 만들어 놓은 메모리 영역을 뜻한다.

- 한번 읽은 파일의 내용은 메모리의 캐시 영역에 저장시킨다.
- 추후 동일한 파일의 접근이 일어나면 디스크에서 읽지 않고 메모리에서 직접 읽는 방식이다.
- 이러한 특징 때문에 카프카 브로커를 실행하는데 힙 메모리 사이즈를 크게 설정할 필요가 없다.

데이터 복제는 카프카를 장애 허용 시스템으로 동작하도록 하는 원동력이다.

데이터 복제는 파티션 단위로 이루어진다. 토픽을 생성할 때 파티션의 복제 개수도 같이 설정되는데 직접 옵션을 선택하지 않으면 브로커에 설정된 옵션 값을 따라간다. 
복제 개수의 최솟값은 1, 최댓값은 브로커 개수이다.

복제된 파티션은 리더와 팔로워로 구성된다. 프로듀서 또는 컨슈머와 직접 통신하는 파티션을 리더, 나머지 복제 데이터를 가지고 있는 파티션을 팔로워라고 부른다.

팔로워 파티션들은 리더 파티션의 오프셋을 확인하여 현재 자신이 가지고 있는 오프셋과 차이가 나는 경우 리더 파티션으로부터 데이터를 가져와서 자신의 파티션에 저장하는데, 이 과정을 `복제`라고 부른다.

리더 파티션을 가진 브로커에 장애가 발생하면 팔로워 파티션 중 하나가 리더 파티션 지위를 넘겨받는다.

클러스터의 다수 브로커 중 한 대가 `컨트롤러`의 역할을 한다. 컨트롤러는 다른 브로커들의 상태를 체크하고 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배한다. 
컨트롤러 역할을 하는 브로커에 장애가 생기면 다른 브로커가 컨트롤러 역할을 한다.

오직 브로커만이 데이터를 삭제할 수 있다. 데이터 삭제는 파일 단위로 이루어지는데 이단위를 '로그 세그먼트'라고 부른다. 
이 세그먼트에는 다수의 데이터가 들어 있기 때문에 일반적인 데이터베이스처럼 특정 데이터를 선별해서 삭제할 수 없다. 
세그먼트는 데이터가 쌓이는 동안 파일 시스템으로 열려있으며 카프카 브로커에 log.segment.bytes 또는 log.segment.ms 옵션에 값이 설정되면 세그먼트 파일이 닫힌다. 
기본값은 1GB 이고, 작은 용량으로 설정할 수 있으나 너무 작은 용량으로 설정하면 데이터들을 저장하는 동안 세그먼트 파일을 자주 여닫음으로써 부하가 발생할 수 있으므로 주의해야 한다.  
닫힌 세그먼트 파일은 log.retention.bytes 또는 log.retention.ms 옵션에 설정값이 넘으면 삭제된다. 닫힌 세그먼트 파일을 체크하는 간격은 log.retention.check.interval.ms 로 설정할 수 있다.

커핏한 오프셋은 __consumer_offsets 토픽에 저장한다.

클러스터의 다수 브로커 중 한 대는 `코디네이터`의 역할을 수행한다. 코디네이터는 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할을 한다. 
파티션을 컨슈머로 재할당하는 리밸런스 과정을 맡는다.

주키퍼는 카프카의 메타데이터를 관리하는 데에 사용된다.

파티션은 카프카의 병령처리의 핵심으로써 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭된다.  
컨슈머 개수를 늘림과 동시에 파티션 개수도 늘리면 처리량이 증가하는 효과를 볼 수 있다.

파티션은 자료구조에서 접하는 큐와 비슷한 구조라고 생각하면 쉽다. 일반적인 자료구조로 사용되는 큐는 데이터를 가져가면 레코드를 삭제하지만 카프케아세넌 삭제하지 않는다.  
이러한 특징 때문에 토픽의 레코드는 다양한 목적을 가진 여러 컨슈머 그룹들이 토픽의 데이터를 여러 번 가져갈 수 있다.

레코드는 타임스탬프, 메시지 키, 메시지 값, 오프셋, 헤더로 구성되어 있다. 브로커에 한번 적재된 레코드는 수정할 수 없고 로그 리텐션 기간 또는 용량에 따라서만 삭제된다.

- 타임스탬프
  - 프로듀서에서 해당 레코드가 생성된 시점의 유닉스 타임이 설정
  - 프로듀서가 레코드를 생성할 때 임의의 타임 스탬프 값을 설정할 수 있음
  - 토픽 설정에 따라 브로커에 적재된 시간으로 설정될 수 있음
- 메시지 키
  - 메시지 값을 순서대로 처리하거나 메시지 값의 종료를 나타내기 위해 사용
  - 파티션 개수가 변경되면 메시지 키와 파티션 매칭이 달리질 수 있음
  - 메시지 키를 선언하지 않으면(null) 프로듀서 기본 설정 파티셔너에 따라서 파티션에 분배되어 적재
- 메시지 값
  - 실질적으로 처리할 데이터
  - 메시지 키와 값은 직렬화되어 브로커로 전송되므로 컨슈머가 이용할 때는 동일한 형태로 역직렬화
- 오프셋
  - 0 이상의 숫자
  - 직접 지정할 수 없고 브로커에 저장될 때 이전에 전송된 레코드의 오프셋 + 1 값으로 생성
- 헤더
  - 레코드의 추가적인 정보를 담는 메타데이터 저장소 용도
  - 키 값 형탤로 데이터를 추가
  - 레코드의 속성(스키마 버전 등)을 저장하여 컨슈머에서 참조할 수 있음

프로듀서는 압축 옵션을 통해 브로커로 전송 시 압축 방식을 정할 수 있다. 
압축을 하면 데이터 전송 시 네트워크 처리량에 이득을 볼 수 있지만 압출을 하는 데에 CPU 또는 메모리 리소스를 사용하므로 사용환경에 따라 적절한 압축 옵션을 사용하는 것이 중요하다. 
컨슈머 애플리케이션에서 압축한 메시지를 풀 때도 컨슈머 애플리케이션의 리소스가 사용된다.

프로듀서 옵션

- 필수
  - bootstrap.servers
  - key.serializer
  - value.serializer
- 선택
  - acks
    - 프로듀서가 전송한 데이터가 브로커들에 정상적으로 저장되었는지 전송 성공 여부를 확인하는 데에 사용하는 옵션이다. 설정 값에 따라 데이터의 유실 가능성이 달라진다.
    - 값
      - 1
        - 기본값
        - 리더 파티션에 데이터가 저장되면 전송 성공으로 판단
      - 0
        - 프로듀서가 전송한 즉시 브로커에 데이터 저장 여부와 상관없이 성공으로 판단
      - -1(all)
        - 토픽의 min.insync.replicas 개수에 해당하는 리더 파티션과 팔로워 파티션에 데이터가 저장되면 성공하는 것으로 판단
  - buffer.memory
  - retries
    - 프로듀서가 브로커로부터 에러를 받고 난 뒤 재전송을 시도하는 횟수.
  - batch.size
    - 배치로 전송할 레코드 최대 용량
  - linger.ms
    - 배치를 전송하기 전까지 기다리는 최소 시간
    - 기본값 0
  - partitioner.class
  - enable.idempotence
  - transactional.id

컨슈머를 운영하는 방법은 크게 2가지 있다.

1. 1개 이상의 컨슈머로 이루어진 컨슈머 그룹을 운영하는 것
   - 1개의 파티션은 최대 1개의 컨슈머에 할당 가능, 1개의 컨슈머는 여러 개의 파티션에 할당 가능
   - 이러한 특징으로 컨슈머 그룹의 컨슈머 개수는 가져가고자 하는 토픽의 파티션 개수보다 같거나 작아야 함
2. 토픽의 특정 파티션만 구독하는 컨슈머를 운영하는 것

컨슈머 그룹은 다른 컨슈머 그룹과 격리되는 특징을 가지고 있다. 따라서 각기 다른 역할을 하는 컨슈머 그룹끼리 영향을 받지 않게 처리할 수 있다는 장점이 있다.

컨슈머 그룹의 컨슈머에 장애가 발생하면? 장애가 발생한 컨슈머에 할당된 파티션은 장애가 발생하지 않은 컨슈머에 소유권이 넘어가는데, 이러한 과정을 리밸런싱이라고 부른다.

리밸런싱은 크게 두 가지 상황에 일어난다.

1. 컨슈머가 추가되는 상황
2. 컨슈머가 제외되는 상황

리밸런싱은 컨슈머가 데이터를 처리하는 도중에 언제든지 발생할 수 있으므로 데이터 처리 중 발생한 리밸런싱에 대응하는 코드를 작성해야 한다.

가용성을 높이면서도 안정적인 운영을 도와주는 리밸런싱은 유용하지만 자주 일어나서는 안 된다.
리밸런싱이 발생할 때 파티션의 소유권을 컨슈머로 재할당하는 과정에서 해당 컨슈머 그룹의 컨슈머들이 토픽의 데이터를 읽을 수 없기 때문이다.
코디네이터는 리밸런싱을 발동시키는 역할을 하는데 컨슈머 그룹의 컨슈머가 추가되고 삭제될 때를 감지한다.

데이터 처리의 중복이 발생하지 않게 하기 위해서는 컨슈머 애플리케이션이 오프셋 커밋을 정상적으로 처리했는지 검증해야만 한다.

오프셋 커밋은 컨슈머 애플리케이션에서 명시적, 비명시적으로 수행할 수 있다.

- 기본 옵션은 `poll()` 수행될 때 일정 간격마다 오프셋을 커밋하도록 enable.auto.commit=true로 설정되어 있다.
  - 이렇게 일정 간격마다 자동으로 커밋되는 것은 비명시 '오프셋 커밋'이라고 부른다.
  - 이 옵션은 auto.commit.interval.ms 에 설정된 값과 함께 사용되는데 해당 값 이상 지났을 때 그 시점까지 읽은 레코드의 오프셋을 커밋한다.
  - 비명시 오프셋 커밋은 편리하지만 `poll()` 이후 리밸런싱 또는 컨슈머 강제 종료 발생 시 컨슈머가 처리하는 데이터가 중복 또는 유실될 수 있는 가능성이 있는 취약한 구조를 가지고 있다.
- 명시적으로 오프셋을 커밋하려면 `poll()` 호출 이후에 반환받은 데이터의 처리가 완료되고 `commitSync()` 를 호출하면 된다.
  - `commitSync()` 은 `poll()` 통해 반환된 레코드의 가장 마지막 오프셋을 기준으로 커밋을 수행한다.
  - `commitSync()`은 브로커에 커밋 요청을 하고 커밋이 정상적으로 처리되었는지 응답하기까지 기다리는데 이는 컨슈머의 처리량에 영향을 끼친다.
  - 이를 해결하기 위해 `commitAsync()` 를 사용할 수 있다.
  - 하지만 비동기 커밋은 커밋 요청이 실패했을 경우 현재 처리 중인 데이터의 순서를 보장하지 않으며 데이터의 중복 처리가 발생할 수 있다.

컨슈머는 `poll()` 을 호출하는 시점에 클러스터에서 데이터를 가져오는 것은 아니다.
컨슈머 애플리케이션을 실행하게 되면 컨슈머 내부에서 Fetcher 인스턴스가 생성되어 `poll()`을 호출하기 전에 미리 레코드들을 내부 큐로 가져온다.
`poll()` 를 호출하면 컨슈머는 내부 큐에 있는 레코드들을 반환받아 처리를 수행한다.

컨슈머 주요 옵션

- 필수
  - bootstrap.servers
  - key.deserializer
  - value.deserializer
- 선택
  - group.id
  - auto.offset.reset
    - 컨슈머 그룹이 특정 파티션을 읽을 때 저장된 컨슈머 오프셋이 없는 경우 어느 오프셋부터 읽을지 선택하는 옵션이다.
    - 이미 컨슈머 오프셋이 있다면 이 옵션값은 무시된다.
    - 값
      - latest(기본값): 가장 최근 오프셋부터
      - earliest: 가장 오래전 오프셋부터
      - none: 컨슈머 그룹이 커밋한 기록이 있는지 찾아봄. 없으면 오류 반환. 있다면 기존 커밋 기록 이후 오프셋부터 읽기 시작.
  - enable.auto.commit
  - auto.commit.interval.ms
  - max.poll.records
    - `poll()` 메서드로 가져올 레코드의 최대 개수
    - 기본값 500
  - session.timeout.ms
    - 컨슈머가 브로커와 연결이 끊기는 최대 시간
    - 이 시간 내에 하트비트를 전송하지 않으면 브로커는 컨슈머에 이슈가 발생했다고 가정하고 리밸런싱
    - 보통 하트비트 시간 간격의 3배로 설정
    - 기본값 10000(10초)
  - heartbeat.interval.ms
    - 하트비트를 전송하는 시간 간격
    - 기본값 3000(3초)
  - max.poll.interval.ms
    - `poll()` 을 호출하는 간격의 최대 시간
    - `poll()` 을 호출한 이후에 데이터를 처리하는 데에 시간이 너무 많이 걸리는 경우 비정상으로 판단하고 리밸런싱을 시작
    - 기본값 300000(5분)
  - isolation.level

`commitSync()` 는 파라미터 없이 호출하면 `poll()` 로 반환된 가장 마지막 레코드의 오프셋을 기준으로 커밋되고, 개별 레코드 단위로 커밋할 수도 있다.

`commitAsync()` 도 마찬가지로 파라미터 없이 호출하면 `poll()` 로 반환된 가장 마지막 레코드의 오프셋을 기준으로 커밋된다.
비동기로 커밋 응답을 받기 때문에 callback 함수를 파라미터로 받아서 결과를 얻을 수 있다.

`poll()` 을 통해 반환받은 데이터를 모두 처리하기 전에 리밸런스가 발생하면 데이터를 중복 처리할 수 있다.
`poll()` 을 통해 받은 데이터 중 일부를 처리했으나 커밋하지 않았기 때문이다.

리밸런스 발생 시 데이터를 중복 처리하지 않게 하기 위해서는 리밸런스 발생 시 처리한 데이터를 기준으로 커밋을 시도해야 한다.

리밸런스 발생을 감지하기 위해 카프카 라이브러리는 `ConsumerRebalanceListener` 인터페이스를 제공한다.

- `onPartitionsAssigned()` : 리밸런스가 끝난 뒤에 파티션이 할당 완료되면 호출되는 메서드
- `onPartitionsRevoked()` : 리밸런스가 시작되기 직전에 호출. 여기에 커밋을 구현하여 처리할 수 있음.

파티션을 컨슈머에 명시적으로 할당하여 운영할 수도 있다(`assign()` 메서드 사용).
직접 컨슈머가 특정 토픽, 특정 파티션에 할당되므로 리밸런싱하는 과정이 없다.

정상적으로 종료되지 않은 컨슈머는 세션 타임아웃이 발생할 때까지 컨슈머 그룹에 남게 된다. 이로 인해 파티션 데이터는 소모되지 못하고 컨슈머 랙이 늘어나게 된다.

컨슈머를 안전하게 종료하기 위해 `KafkaConsumer.wakeup()` 메서드를 지원한다. `wakeup()` 가 실행된 후 `poll()` 가 호출되면 `WakeupException` 이 발생한다.
`WakeupException` 이 발샌한 뒤에는 데이터 처리를 위해 사용한 자원들을 해제하면 된다. 그리고 마지막에는 `close()` 메서드를 호출하여 컨슈머를 안전하게 종료한다.
`close()` 를 호출하면 해당 컨슈머는 더는 동작하지 않는다는 것을 명시적으로 알려주므로 컨슈머 그룹에서 이탈되고 나머지 컨슈머들이 파티션을 할당받게 된다.
`wakeup()` 은 셧다운 훅에서 실행하면 된다.

`AdminClient` 를 활용하는 예시

- 카프카 컨슈머를 멀티 스레드로 생성할 때, 구독하는 토픽의 파티션 개수만큼 스레드를 생성
- 웹 대시보드 구현
- 특정 토픽의 데이터양이 늘어남을 감지하고 해당 토픽의 파티션을 늘림
