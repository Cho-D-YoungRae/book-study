# 주니어 백엔드 개발자가 반드시 알아야 할 실무 지식 - 1회

## Chapter 02. 느려진 서비스, 어디부터 봐야 할까

성능과 관련된 지표: 네트워크 속도, 디스크 속도, 메모리 크기, 디바이스의 CPU 속도 등

> 이 중 서버 성능과 가장 관련 있는 것: 응답시간과 처리량

서버 처리 시간은 다음과 같은 요소를 포함

- 로직 수행(if, for 등)
- DB 연동(SQL 실행)
- 외부 API 연동
- 응답 데이터 생성(전송)

> 이 중 DB 연동과 외부 API 연동이 큰 비중을 차지 -> 응답 시간을 줄일 때 여기에 집중

TPS 를 높이는 방법

- 서버가 동시에 처리할 수 있는 요청 수를 늘려 대기 시간 줄이기
- 처리 시간 자체를 줄여 대기 시간 줄이기

TPS 를 높이려면 먼저 성능 문제가 발생하는 지점을 찾아야 한다. 문제 지점을 찾는 간단한 방법은 처리 시간이 오래 걸리는 작업을 식별하는 것이다. 성능 문제는 응답 시간이 길어지면서 발생하는 경우가 많기 때문이다. 이때 모니터링 도구가 유용하다. 성능 문제는 주로 DB나 외부 API를 연동하는 과정에서 발생했다.

일단 급한 불을 끄고 나서 근본적인 해결책을 모색해야 한다.

- 수직 확장(scale-up)
- 수평 확장(scale-out)

TPS 를 높이기 위해 무턱대고 서버를 추가해서는 안된다. 실제 병목 지점이 어디인지 파악하는 게 중요하다. DB나 외부 API 성능이 문제인 경우 서버를 추가한다고 해서 TPS는 향상되지 않는다.

트래픽이 순간적으로 급증하는 패턴을 보인다면 커넥션 풀의 최소 크기를 최대 크기에 맞추는 것이 좋다. 트래픽이 점직적으로 증가할 때는 DB 연결 시간이 성능에 큰 영향을 주지 않지만 트래픽이 급증할 경우 DB 연결 시간도 성능 저하의 주요 원인이 될 수 있기 때문이다.

커넥션 풀 크기를 늘리면 처리량을 높일 수 있으나, DB 상태(CPU 사용률 등)을 보고 늘려야 한다. 수평 확장도 마찬가지다.

MySQL과 같은 DB는 클라이언트와 일정 시간 동안 상호작용이 ㅇ벗으면 자동으로 연결을 끊는 기능을 제공한다. 연결 끊김으로 인해 발생하는 에러를 방지하기 위해 커넥션 풀은 다음 2가지 기능을 제공한다.

- 최대 유휴 시간 지정
- 유효성 검사 지원
- 최대 유지 시간

DB 서버를 확장하지 않고도 응답 시간과 처리량을 개선하고 싶다면 캐시 사용을 고려할 수 있다. (로컬 캐시, 리모트 캐시)

트래픽이 순간적으로 급증하는 패턴을 보인다면 캐시에 데이터를 미리 저장하는 것도 고려할 필요가 있다.

가비지 컬렉터는 정해진 규칙(e.g. 힙 메모리 사용량이 일정 비율 초과, 일정 주기)에 따라 사용하지 않는 메모리를 찾아서 반환한다.

가비지 컬렉터는 응답 시간에 영향을 줄 수 있다. 가비지 컬렉터가 실행되는 동안 애플리케이션의 실행이 일시 중단된다.

GC 알고리즘과 메모리 사용 패턴에 따라 차이가 있지만 사용하는 메모리양과 객체 수가 많을수록 GC 실행 시간은 길어진다.

파일 다운로드와 같은 기능을 구현할 때는 스트림을 활용하여 메모리 사용량을 줄인다.

응답 시간에는 데이터 전송 시간이 포함되고 이는 2가지 요인에 영향을 받는다.

- 네트워크 속도
- 전송 데이터 크기

> 네트워크 속도를 제어할 수는 없지만, 데이터의 크기는 압축을 통해 제어할 수 있다.

응답 데이터를 압출할 때 고려 사항

- html, css, js, json과 같은 텍스트 형식의 응답은 압축률이 높아 효과적이다. 하지만 jpeg 이미지나 zip 파일 처럼 이미 압축한 데이터에는 다시 압축해도 효과가 없다.
- 웹 서버에서 압축을 적용했더라도 방화벽이 이를 해체해 응답할 수 있다. 즉, 웹 서버에 압축 설정을 적용했음에도 실제 응답 데이터가 압축되지 않는다면 방화벽 설정도 확인해야 한다.

> 응답 데이터의 크기는 곧 비용으로 연결 된다.

HTTP 프로토콜(Cache-Control, Expires)를 사용해 클라이언트 캐시를 활용하여 정적 데이터를 캐싱하여 트래픽을 줄일 수 있다.

CDN

- 여러 CDN 을 통해서 오리진 서버에 대한 부담을 줄일 수 있다.
- CDN은 지역적으로 가까운 곳에 위치하여 콘텐츠를 더 빠르게 받을 수 있고 트래픽 비용도 줄일 수 있다.

정적 파일을 관리할 때는 파일 크기를 주의해야 한다. 너무 큰 용량의 파일은 비용 청구 혹은 네트워크 트래픽 문제가 발생할 수 있으므로 제한 설정 등이 필요하다.

사용자가 순간적으로 폭증할 때

- 서버 미리 증설
  - API 서버 증설, DB 증설(쉽게 할 수 없기에 예상되는 트래픽에 맞춰 미리 증설)
  - 비용 문제 고려: API 서버는 다시 줄일 수 있지만, DB는 그렇지 않다. 짧은 시간을 위해 고정 비용(DB 비용)이 커지는 격이다.
- 수용할 수 있는 수준의 트래픽만 받아들이고 나머지는 대기 처리
  - 서버를 증설하지 않고도 서비스를 안정적으로 제공할 수 있다.
  - 사용자의 지속적인 새로 고침으로 인한 트래픽 폭증도 방지할 수 있다. 사용자는 새로 고침할 경우 순번이 뒤로 밀리기 때문에 불필요한 새로 고침을 자제하게 된다.

## Chapter 03. 성능을 좌우하는 DB 설계와 쿼리

데이터가 많지 않은 상황에서는 테이블 풀 스캔을 하더라도 성능 문제가 발생하지 않기 때문에 꼭 인덱스를 생성할 필요는 없다. 하지만 데이터가 많아지는 경우 조회 성능을 위해 인덱스를 생성해야 한다.

엘라스틱서치 같은 검색 엔진을 사용하면 DB를 사용하지 않고 검색 기능을 구현할 수 있지만, 별도의 검색 엔진을 구성하기 힘든 상황이라면 DB가 제공하는 전문 검색 기능 사용을 고려해볼 수 있다.

인덱스 생성시 조회 조건은 2개 칼럼을 이용하지만 데이터 수가 1개 칼럼으로 충분한 경우 꼭 복합 인덱스를 생성하지 않아도 될 수 있다.

인덱스를 생성할 때는 선택도(selectivity)가 높은 칼럼을 골라야 한다. 선택도는 인덱스에서 특정 칼럼의 고유한 값 비율을 나타낸다. 선택도가 높을수록 인덱스를 이용한 조회 효율이 높아진다.

> 특정 상태의 데이터를 조회해야 하는 등의 상황에서는 선택도가 높지 않아도 엔덱스 칼럼으로 적합하다. (e.g. 작업 중 상태의 데이터 조회)

효과가 적은 인덱스를 추가하면 오히려 성능이 나빠질 수 있다. 인덱스는 조회 속도를 빠르게 해주지만 데이터 추가, 변경, 삭제 시에는 인덱스 관리에 따른 비용이 추가되기 때문이다. 또한 인덱스 자체도 데이터이기 때문에 인덱스가 많아질수록 메모리와 디스크 사용량도 함께 증가한다.

> 꼭 조회 조건에 필요한 모든 칼럼을 추가할 필요 X

새로 추가할 쿼리가 기존에 존재하는 인덱스를 사용하지 않을 때는 요구사항을 일부 변경할 수 있는지 검토해보자.

> 예약 테이블에 예약 날짜에만 인덱스가 있는 경우: 예약자 이름으로 조회 -> 특정 일자에 예약한 예약자 이름으로 조회

인덱스가 아니어도 조회 성능을 개선할 방법

- 미리 집계하기
- 페이지 기준 목록 조회 대신 ID 기준 목록 조회 방식 사용하기
- 조회 범위를 시간 기준으로 제한하기
  - 특정 일자, 시간의 데이터는 비교적 적기때문에
- 전체 개수 세지 않기
- 오래된 데이터 삭제 및 분리 보관하기
  - 데이터 개수가 늘어날수록 쿼리 실행 시간은 증가
- DB 장비 확장하기
  - scale-up, scale-out
- 별도 캐시 서버 구성하기

> DELETE 쿼리를 사용한다고 실제 디스크 용량이 줄어들지는 않는다. 데이터가 삭제되었다는 표시만 남기고, 삭제된 공간은 향후 재사용한다. 이것이 반복되면 데이터가 흩어져 저장되고 빈 공간이 생기게 되는 단편화 현상이 발생할 수 있다. 단편화가 심해지면 디스크 I/O가 증가하면서 쿼리 성능이 저하될 수 있고 디스크 낭비도 발생한다. 이를 해결하는 방법 중 하나는 최적화 작업이다. 최적화는 데이터를 재배치해 단편화를 줄이고, 물리적인 디스크 사용량까지 줄여주는 효과가 있다.

알아두면 좋을 몇 가지 주의 사항

- 쿼리 타임아웃
- 상태 변경 기능은 복제 DB 에서 조회하지 않기
- 배치 쿼리 실행 시간 증가
  - 커버링 인덱스 활용
  - 데이터를 일정 크기로 나눠 처리
- 타입이 다른 칼럼 조인 주의 -> 인덱스 사용 불가능
  - 두 칼럼의 타입을 맞춰서 비교해야 한다
- 테이블 변경은 신중하게
  - MySQL의 겨웅 테이블을 변경할 때 새 테이블을 생성하고 원본 테이블의 데이터를 복사한 뒤, 복사가 완료되면 새 테이블로 대체하는데, 이 과정에서 dml 작업을 허용하지 않기 때문에 복사 시간만큼 서비스가 멈춘다.
  - dml 을 허용하면서 테이블을 변경하는 기능도 있지만 항상 가능한 것은 아니다. 그래서 데이터가 많은 테이블은 점검 시간을 잡고 변경하는 경우가 많다.
- DB 최대 연결 개수

## Chapter 04. 외부 연동이 문제일 때 살펴봐야 할 것들

외부 연동에서 가장 중요한 설정 중 하나는 타임아웃(연결 타임아웃, 읽기 타임아웃)

외부 연동에 실패했을 때 처리 방법 중 하나는 재시도

재시도를 해도 되는 조건

- 단순 조회 기능
- 연결 타임아웃
- 멱등성을 가진 변경 기능

같은 API 라도 실패 원인에 따라 재시도 여부를 결정해야 한다.

> 검증 오류는 재시도를 해도 실패

연동 서비스에 임계치 이상의 요청을 보내면서 발생하는 성능 저하 문제를 완화하는 방법은, 연동 서비스에 요청을 일정 수준 이상으로 보내지 않는 것이다.

> 벌크헤드 패턴: 각 구성 요소를 격리함으로써 한 구성 요소의 장애가 다른 구성 요소에 영향을 주지 않도록 설계하는 패턴

서킷브레이커를 통해서 연동 서비스가 장애 상활일 때는 연동 대신 바로 에러를 응답하고, 정상화되었을 때 연동을 재개하여 연동 서비스의 장애가 주는 영향을 줄일 수 있다.

외부 연동에 실패했을 때 트랜잭션 롤백

- 읽기 타임아웃이 발생해 트랜잭션을 롤백할 때는, 외부 서비스가 실제로는 성공적으로 처리했을 가능성을 염두에 두어야 한다.
- 트랜잭션을 롤백했는데 외부 서비스가 실제로는 성공했을 경우
  - 일정 주기로 두 시스템의 데이터가 일치하는지 확인하고 보정
  - 성공 확인 API 호출
    - 읽기 타임아우이 발생한 경우, 일정 시간 후에 이전 호출이 실제로 성공했는지 확인하는 API 호출
    - 성공 응답: 트랜잭션 지속
    - 실패 응답: 트랜잭션 롤백
  - 취소 API 호출
    - '성공 확인 API 호출'의 변형
    - 읽기 타임아웃이 발생한 뒤 일정 시간 후에 취소 API 호출

> 성공 확인 API나 취소 API를 호출하는 방식은 연동 서비스가 지원할 때만 사용할 수 있고, 이 또한 호출하는 과정에서 타임아웃이 발생할 수 있다. 따라서 두 시스템 간 데이터 일관성이 중요한 기능이라면 정기적으로 데이터 일치를 확인하는 프로세스를 갖추는 것이 바람직하다.

외부 연동은 성공했는데 DB 연동에 실패해서 트랜잭션 롤백

- 취소 API 호출
- 일정 주기로 데이터가 맞는지 비교

DB 트랜잭션 범위 안에서 외부 연동을 수행할 때, 트랜잭션 처리 외에도 **외부 연동이 느려지면서 발생하는 커넥션 풀 부족 현상**도 주의해야 한다.

HTTP 연결도 커넥션 풀을 사용하면 연결 시간을 줄일 수 있어 응답 속도 향상에 도움이 된다.

HTTP 커넥션 풀을 사용할 때 고려사항

- HTTP 커넥션 풀의 크기
- 풀에서 HTTP 커넥션을 가져올 때까지 대기하는 시간
- HTTP 커넥션을 유지할 시간(keep alive)

## Chapter 05. 비동기 연동, 언제 어떻게 써야 할까

많은 연동에서 비동기 방식을 사용해도 된다.

- 쇼핑몰에서 주문이 들어오면 판매자에게 푸시 보내기(푸시 서비스 연동)
- 학습을 완료하면 학생에게 포인트 지급(포인트 서비스 연동)
- 컨텐츠를 등록할 때 검색 서비스에도 등록(검색 서비스 연동)
- 인증 번호를 요청하면 SMS로 인증 메시지 발송(SMS 발송 서비스 연동)

> 1. 시차가 생겨도 문제 되지 않는다.
> 2. 일부 기능은 실패했을 떄 재시도가 가능하다.
> 3. 연동에 실패했을 떄 나중에 수동으로 처리할 수 있는 기능도 있다.
> 4. 연동에 실패했을 때 무시해도 되는 기능도 있다.

외부 연동이 4가지 특징 중 일부에 해당하면 비동기로 처리할 수 있는지 검토해볼 수 있다.

비동기 연동의 다양한 구현

1. 별도 스레드로 실행하기
2. 메시징 시스템 이용하기
3. 트랜잭션 아웃박스 패턴 사용하기
4. 배치로 연동하기
5. CDC 이용하기

별도 스레드로 실행되는 코드는 내부 연동 과정에서 발생한 오류를 직접 처리해야 한다.

메시지 시스템 이점

1. 시스템 간에 영향을 주지 않는다.
   - 메시징 시스템은 중간에서 메시지를 보관하는 버펴 역할을 한다.
2. 확장에 용이하다
   - 다른 시스템이 추가되더라도 추가에 대한 코드를 작성할 필요 없다.

카프카 특징

- 높은 처리량을 자랑한다. 초당 백 만 개 이상의 메시지를 처리할 수 있다.
- 수평 확장이 용이하다. 서버(브로커), 파티션, 소비자를 늘리면 된다.
- 카프카는 메시지를 파일에 보관해서 메시지가 유실되지 않는다.
- 1개의 토픽이 여러 파티션을 가질 수 있는데, 파티션 단위로 순서를 보장한다. 하지만 토픽 수준에서는 순서를 보장할 수 없다.
- 소비자는 메시지를 언제든지 재처리할 수 있다.
- 풀(pull) 모델을 사용한다. 소비자가 카프카 브로커에서 메시지를 읽어가는 방식이다.

래빗MQ 특징

- 클러스터를 통해 처리량을 높일 수 있다. 단, 카프카보다 더 많은 자원을 필요로 한다.
- 메모리에만 메시지를 보관하는 큐 설정을 사용하면 장애 상황 시 메시지가 유실될 수 있다.
- 메시지는 큐에 등록된 순서대로 소비자에 전송된다.
- 메시지가 소비자에 전달됐는지 확인하는 기능을 제공한다.
- 푸시(push) 모델을 사용한다. 래빗MQ 브로커가 소비자에 메시지를 전송한다. 소비자의 성능이 느려지면 큐에 과부하가 걸려 전반적으로 성능 저하가 발생할 수 있다.
- 다재다능하다. AMQP, STOMP 등 여러 프로토콜을 지원하고, 게시/구독 패너뿌ㄴ만 아니라 요청/응답, 점대점 패턴을 지원한다. 또한 우선순위를 지정해서 처리 순서를 변경할 수도 있다.

레디스 pub/sub 특징

- 메모리를 사용하므로 지연 시간이 짧고, 래빗MQ 대치 처리량이 높다.
- 구독자가 없으면 메시지가 유실된다.
- 기본적으로 영구 메시지를 지원하지 않는다.
- 모델이 단순해서 사용하기 쉽다.

메시지 전송 과정에서 오류 처리

- 무시
  - 메시지 유실된다
- 재시도
  - 중복된 메시지 전송될 수 있다
  - 메시지마다 고유 식별자를 사용하면 메시지 소비자가 중복 메시지 여부를 판단하는 데 도움이 된다
- 실패 로그
  - 나중에 후처리를 하는 데 사용된다

잘못된 메시지가 전송되는 문제를 방지하려면 트랜잭션이 끝난 뒤에 메시지를 전송해야 한다.

메시지 소비자는 다음 2가지 이유로 동일 메시지를 중복해서 처리할 수 있다.

- 메시지 생산자가 같은 데이터를 가진 메시지를 메시징 시스템에 두 번 전송
- 소비자가 메시지를 처리하는 과정에서 오류가 발생해서 메시지 재수신

메시지에 고유한 ID를 부여해서 이미 처리했는지 여부를 추적하여 이미 처리한 메시지는 다시 처리하지 않고 무시할 수 있다. 메시지를 처리했는지 여부는 DB 테이블에 기록하거나 메모리에 집합으로 관리하면 된다. 메모리로 관리할 때는 메모리 부족 에러가 발생하는 것을 막기 위해 일정 개수의 메시지 ID만 유지한다.

멱등성을 갖도록 API를 구현하여 메시지 재수신에 따른 중복 처리 대응 가능

소비자가 메시지를 잘 소비하고 있는지 모니터링 해야 한다.

메시지의 종류

- 이벤트
  - 어떤 일이 발생했음을 알려주는 메시지
  - 상태 변경과 관련
  - 정해진 수신자가 없다
  - 소비자 확장에 적합
- 커맨드
  - 무언가를 요청
  - 메시지를 수신할 측의 기능 실행에 초점

메시지 데이터가 유실되지 않도록 보장하는 방법: 데이터를 DB 저장, 저장된 메시지를 읽어 메시징 시스템에 전송. -> 트랜잭션 아웃박스 패턴

트랜잭션 아웃박스 패턴은 하나의 DB 트랜잭션 내에서 다음 2가지 작업 수행

- 실제 업무 로직에 필요한 DB 변경 작업을 수행
- 메시지 데이터를 아웃박스 테이블에 추가

아웃 박스 테이블에 쌓인 메시지 데이터는 별도의 메시지 중계 프로세스가 주기적으로 읽어서 메시징 시스템에 전송

발송 와뇰를 표시하는 방법

- 아웃박스 테이블에 발송 상태 칼럼(발송 대기, 발송 완료, 발송 실패)
- 메시지 중계 서비스가 성공적으로 전송한 마지막 메시지 ID를 기록하는 방식

> 발송 상태 칼럼 방식이 선호됨. 2개 이상의 메시지 중계 서비스가 하나의 아웃박스 테이블을 함께 사용하는 환경이라면 각 중계 서비스가 고유하게 마지막 ID를 관리해야 하므로, 이 경우에는 마지막 메시지 ID를 기록하는 방식이 더 적합할 수 있다.

아웃박스 테이블 구조

|칼럼|타입|설명|
|---|---|---|
|id|bigint|단순 증가 값(PK). 저장된 순서대로 증가하는 값을 사용한다.|
|message_id|varchar|메시지 고유 ID(고유키)|
|message_type|varchar|메시지 타입. 메시지 종류 구분(LoginFailed, OrderPlaced, ...)|
|payload|clob|메시지 데이터. json, xml, ...|
|status|varchar|이벤트 처리상태(WAITING, DONE, FAILED). 대기 상태인 메시지 데이터만 조회하기 때문에, 어떤 조건에서 실패 상태로 바꿀지 결정해야 한다. 실패 횟수를 기준으로 자동으로 상태를 변경할 수도 있고, 상태를 모니터링하다가 수동으로 변경할 수도 있다. 예를 들어 메시지 발송에 5회 실패하면 실패함 상태로 바꾸고 다음 메시지를 처리할 수 있다. 또는 실패 횟수가 10회를 넘어가면, 모니터링 시스템을 통해서 메시지 발송이 지연되고 있다는 사실을 운영팀에 알리고, 운영팀이 수동으로 실패함 상태로 바꾸도록 할 수도 있다. 실패 상태로 바뀐 메시지는 알맞은 후속조치를 해야 한다. memo나 remark와 같은 칼럼을 추가해서 실패 메시지를 아웃박스 테이블에 기록하면, 실패 이유를 파악하는 데 도움이 된다. 실패가 아니라 수동으로 특정 메시지를 전송하고 싶지 않을 때 제외함(EXCLUDED)를 추가하여 사용할 수 있다. |
|fail_count|int|실패 횟수|
|occured_at|timestamp|메시지 발생 시간|
|processed_at|timestamp|메시지 처리 시간|
|failed_at|timestamp|마지막 실패 시간|

CDC 처리기는 전달받은 변경 데이터를 확인하고 가공한 뒤에 대상 시스템에 전파한다.

목적에 따라 CDC 처리기는 DB, 메시징 시스템, API 등 다양한 대상에 데이터를 전파할 수 있다.

> CDC 는 데이터의 변경 분을 전달한다. 이는 어떤 일이 발생했음을 알려주는 이벤트 메시지에 가깝다. 하지만 이벤트처럼 정확하게 의미를 전달하지는 못한다.

시스템이 복잡해서 연동 코드를 넣기 부담스러울 때 CDC를 활용할 수 있다.

## Chapter 06. 동시성, 데이터가 꼬이기 전에 잡아야 한다

서버가 동시에 여러 클라이언트의 요청을 처리하는 방식

- 클라이언트 요청마다 스레드를 할당해서 처리
- 비동기 IO(또는 논블로킹 IO)를 사용해서 처리

세마포어는 동시에 실행할 수 있는 스레드 수를 제한한다. 이진 세마포어는 동시에 접근할 수 있는 스레드 수가 1개인 반면 계수 세마포어는 지정한 수만큼 동시 접근이 가능하다.

자바 23 이하 버전 기준으로 가상 스레드를 사용하나면 `Collections.synchronized...()`와 같은 동기화 컬렉션 객체로 변환해주는 메서드를 사용하면 안 된다. 내부적으로 synchronized 를 사용하는데 자바 23 이하 버전 기준으로 가상 스레드는 아직 synchronized 를 지원하지 않기 때문이다.

분산 잠금은 여러 프로세스가 동시에 동일한 자원에 접근하지 못하도록 막는 방법이다. 간단한 분산 잠금이 필요할 때는 DB에서 제공하는 선점 잠금을 사용해 구현하는 편이다. 하지만 트래픽이 많다면 레디스를 이용해 분산 잠금을 구현하는 것을 고려한다.

트랜잭션 범위 내에서 외부 시스템과 연동해야 한다면, 비선점 잠금보다는 선점 잠금을 고려하는 것이 좋다. 비선점 잠금을 사용하면 외부 연동은 성공했는데, 데이터 변경에 실패해서(냑관락 업데이트 실패 등) 트랜잭션이 롤백되는 문제가 발생할 수 있다.

> 비선점 잠금을 사용하고 싶다면 트랜잭션 아웃박스 패턴을 적용해서 외부 연동을 처리할 수도 있다.

증분 쿼리를 사용할 수도 있다.

```sql
update subject set join_count = join_count + 1 where id = ?
```

> 증분 쿼리는 DB에 따라 원자적 연산이 아닐 수도 있기 때문에 반드시 검증이 필요하다.

잠금을 획득한 뒤에는 반드시 해제해야 한다. 그렇지 않으면 잠금을 시도하는 스레드가 무한 대기하게 될 수 있다. 이런 이유로 try-finally 코드를 사용한다.

잠금 대기 시간이 길어지는 문제를 막기 위해 대기 시간을 지정할 수 있다.

2개 이상의 자원의 잠금을 획득하는 코드 구조는 교착 상태에 빠지기 쉬운 전형적인 패턴이다.

교착 상태가 발생하지 않도록 신경 써야 하지만, 복잡한 코드 구족에서 잠금을 사용하면 개발자 자신도 모르게 교착 상태가 발생할 수 있다. 이를 해소하기 위해서..

- 잠금 대기 시간을 제한한다.
- 지정한 순서대로 잠금을 획득한다.

단일 스레드로 처리하면 동시성 문제에서 자유로울 수 있다. 하지만 반대로 구조는 복잡해지는 단점이 있다. 이 점을 고려해서 단일 스레드 방식을 검토해야 한다. 참고로 논블로킹이나 비동기 IO를 사용하는 경우에는 블로킹 연산을 최소화해야 하므로 단일 스레드 처리 방식이 적합하다.

> 성능은 동시에 실행할 작업 개수와 임계 영역의 실행 시간에 따라 달라진다. 임계 영역의 실행 시간이 짧고 동시에 접근하는 스레드 수가 적을수록 잠금을 사용하는 구현의 성능이 좋을 가능성이 높다. 이 경우에는 큐나 채널을 처리하는 데 드는 시간보다 잠금 획득과 해제에 드는 시간이 더 짧기 때문이다. 반면에 동시에 실행되는 작업이 많고 임계 영역의 실행 시간이 길어진다면 큐나 채널을 이용한 방식이 비슷하거나 더 나을 성능을 낼 가능성도 있다.

## Chapter 06. IO 병목, 어떻게 해결하지

스레드가 대기하는 데 시간을 소요한다는 것은, 그 스레드를 실행하는 CPU도 아무것도 하지 않는 시간이 생긴다는 의미이다. CPU 사용률을 높이려면 CPU가 실행할 스레드를 많이 만들면 왼다. 요청당 스레드 방식으로 구현한 서버가 이에 해당한다.

하지만 스레드를 생성하는 데는 한계가 있다.

- 메모리 사용: 스레드 당 수백 KB 에서 수 MB의 메모리 사용
- 컨텍스트 스위칭: 스레드가 증가하면 컨텍스트 스위칭에 사용되는 시간도 증가

트래픽이 증가하면 다음 2가지 이유로 자원 효율 떨어짐

- IO 대기와 컨텍스트 스위칭에 따른 CPU 낭비
- 요청마다 스레드를 할당함으로써 메모리 사용량이 높음

다수의 서비스는 서버의 자원 낭비를 걱정할 필요가 없다. CPU와 메모리 사용에 영향을 줄 만큼 트래픽이 발생하지 않기 때문이다. 수백만 또는 수천만 이상의 고객이 사용할 정도로 인기 있는 서비스가 아니면 CPU와 메모리 자원 부족보다는 다른 이유로 성능 문제가 발생할 때가 많다.

서비스가 인기를 끌기 시작하면 트래픽이 증가하고 이때부터 처리량을 더 높이기 위한 방법을 고민하면 된다. 가장 쉬운 방법은 서버를 수평 확장하거나 수직 확장하여 자원을 더 확보하는 것이다. 하지만 서버를 확장하는 것은 비용과 직결된다.

서버 성능을 높이는 또 다른 방법은 자원 효율을 높이는 것이다. IO 대기로 인한 CPU 낭비를 줄이고 요청을 처리하는 데 필요한 메모리를 줄이는 것이다.

- 가상 스레드나 고루틴 같은 경량 스레드 사용
- 논블로킹 또는 비동기 IO 사용

가상 스레드와 고루틴은 경량 스레드라는 공통점을 갖는다. 경량 스레드는 OS가 관리하는 스레드가 아니라 JVM 같은 언어 런타임이 관리하는 스레드다. 마치 OS가 CPU로 실행할 스레드를 스케줄링하듯, 언어 런타임이 OS 스레드로 실행할 경량 스레드를 스케줄링 한다.

가상 스레드를 경량 스레드라고 부르는 이유는 플랫폼 스레드보다 더 적은 자원을 사용하기 때문이다.

> 가상 스레드는 수백 바이트에서 수 KB ~ 수십 KB의 힙메모리를 사용한다. 호출 스택의 깊이에 따라 사용하는 메모리를 동적으로 늘렸다가 줄인다.

스레드를 생성하는 시간도 차이가 많이 난다.

> 가상 스레드를 실행하는 플랫폼 스레드를 캐리어 스레드라고 표현한다. CPU가 여러 스레드를 실행하는 것처럼, 한 개의 캐리어 스레드도 여러 가상 스레드를 실행하게 된다. 특정 가상 스레드가 특정 캐리어 스레드에 연결되는 것을 마운트 되었다고 표현한다. 가상 스레드가 캐리어 스레드에 마운트되면 가상 스레드가 실행된다. 반대로 가상 스레드가 캐리어 스레드로부터 언마운트되면 가상 스레드는 실행을 멈춘다.

가상 스레드는 실행하는 과정에서 블로킹되면 플랫폼 스레드와 언마운트되고 실행이 멈춘다. 이때 언마운트된 플랫폼 스레드는 실행 대기 중인 다른 가상 스레드와 연결된 뒤 실행을 재개한다.

블로킹 연산에는 IO 기능, ReentrantLock, Thread.sleep() 등이 포함된다. 이들 연산을 사용해서 가상 스레드가 블로킹되면, 플랫폼 스레드는 대기 중인 다른 가상 스레드를 실핸하다. 반면에 자바 23 이하 버전에서 synchronized로 인해 블로킹되면, 가상 스레드를 플랫폼 스레드로부터 언마운트되지 않는다. 즉, 플랫폼 스레드도 같이 블로킹된다. 이렇게 가상 스레드가 플랫폼 스레드까지 블로킹할 때 이를 가상 스레드가 플랫폼 스레드에 고정됐다고 한다.  
자바 21 기준으로 sychronized 외에도 JNI 호출 등 가상 스레드가 플랫폼 스레드에 고정되는 경우가 있는데, 가상 스레드가 고정되면 CPU 효율을 높일 수 없다.

가상 스레드는 IO 중심 작업일 때 효과가 있다.

IO 중심 작업이라고 해서 무조건 가상 스레드의 이점을 얻는 것은 아니다. 스케줄링에 사용되는 플랫폼 스레드 개수보다 가상 스레드의 개수가 많아야 효과를 기대할 수 있다.

> 동시에 처리해야 하는 요청만큼 가상 스레드가 사용될 것이므로 동시에 처리해야 하는 요청이 플랫폼 스레드 개수보다 많아야 한다.

가상 스레드를 사용해서 높일 수 있는 것은 처리량이다. 실행 속도가 플랫폼 스레드보다 빨라지지는 않는다.

> 요청별 스레드 방식을 사용하는 서버는 스레드 풀을 사용할 때가 많다. 미리 스레드를 생성해서 요청이 들어왔을 때 스레드 생성 부하를 줄이기 위합이다. 또한 스레드 풀 크기에 최대치를 설정해서 요청이 급격히 늘어나도 스레드가 무한정 생성되는 것을 막는다. CPU와 메모리 같은 자원을 일정 수준으로 제한해서 서버 자원이 포화되는 것을 방지하려는 목적이다.  
> 가상 스레드는 플랛폼 스레드보다 생성 비용이 적기 때문에 스레드 풀을 미리 구성할 필요가 없다. 필요한 시점에 가상스레드를 생성하고 필요 없으면 제거하면 된다.

가상 스레드의 중요한 장점은 기존 코드를 크게 수정할 필요가 없다는 것이다.

가상 스레드와 고루틴 같은 경량 스레드를 사용하면 IO 중심 작업을 하는 서버의 처리량을 높일 수 있지만 경량 스레드 자체도 메모리를 사용하고 스케줄링이 필요하므로 경량 스레드가 많아질수록 더 많은 메모리를 사용하고 스케줄링에 더 많은 시간을 사용하게 된다. 사용자가 폭발적으로 증가하면 어느 순간 경량 스레드로도 한계가 오는데 이때 서버의 IO 구현 방식을 구조적으로 변경해야 한다. 논블로킹 IO를 사용해야 하는 것이다.

논블로킹 IO를 사용할 때는 데이터 읽기를 바로 시도하기 보다는 어떤 연산을 수행할 수 있는지 확인하고 해당 연산을 실행하는 방식으로 구현한다.

1. 실행 가능한 IO 연산 목록을 구한다(실행 가능한 연산을 구할 때까지 대기).
2. 1에서 구현 IO 연산 목록을 차례대로 순회하며 각 IO 연산을 처리한다.
3. 이 과정을 반복한다.

블로킹 IO로 구현한 서버는 커넥션 별로(또는 요청별로) 스레드를 할당한다. 반면에 논블로킹 IO는 클라이언트 수에 상관없이 소수의 스레드를 사용한다. 논블로킹 IO는 동시 접속하는 클라이언트가 증가해도 스레드 개수는 일정하게 유지되므로 같은 메모리로 더 많은 클라이언트 연결을 처리할 수 있다.

논블로킹 IO나 가상 스레드를 적용할 때는 먼저 다음을 검토

- 문제가 있는가?
- 문제가 있다면 네트워크 IO 관련 성능 문제인가?
- 구현 변경이 가능한가?

## Chapter 08. 실무에서 꼭 필요한 보안 지식

토큰을 이용해서 사용자를 식별하려면 토큰과 사용자 간의 매핑 정보를 어딘가에 저장해야 한다.

- 서버의 별도 저장소: 별도 저장소에 토큰과 사용자 식별 정보를 저장한다.
  - DB 혹은 레디스
  - 로그인에 성공할 경우 서버는 임의의 토큰 문자열을 만든 뒤 외부 저장소에 매핑 정보를 보관. 토큰 중복 주의.
  - 외부 저장소에 보관되는 정보: 토큰, 사용자 식별자, 생성 시간, 최근 사용 시간, 유효 시간, 클라이언트 버전 등 추가 데이터
  - 서버 메모리에 토큰 데이터를 저장할 수도 있다: 서블릿 세션
    - 고정 세션 필요
    - 서버를 재시작 하면 토큰 데이터 사라짐
    - 생성할 수 있는 세션 개수가 메모리 크기에 제한을 받음
- 토큰: 토큰 자체에 사용자 식별자 정보를 저장한다.
  - 대표적으로 JWT
  - 토큰만 있으면 사용자가 누구인지 확인 가능
  - 별도의 외부 DB에 토큰 데이터를 저장할 필요가 없으므로 서버 구조 간단
  - 메모리에 토큰 데이터를 저장하지 않기 때문에 서버를 수평 확장하기 쉬움
  - 네트워크 트래픽 증가: 토큰 안에 데이터가 추가되므로
  - 토큰 데이터를 서버에서 제어할 수 없음

유효 시간과 함께 클라이언트 IP를 비교하면 토큰 보안이 향상된다. 토큰을 생성할 때 접근한 클라이언트 IP와 실제 토큰을 전송한 클라이언트 IP가 같은지 비교한다.

역할 권한 부여 방식과 사용자별 권한 부여 방식은 각각 장단점이 있기 때문에 단독으로 사용하기보다는 함께 사용하는 경우가 많다.

같은 해시 알고리즘을 사용하면 동일한 원본 데이터에 대해 항상 동일한 해시 값이 생성된다. 이 특성은 해시 값이 유츌됐을 때 원본을 유추하기 쉽게 만든다. 해시 알고리즘은 이 취약점을 보완하기 위해 솔트(Salt)를 사용한다. 솔트는 임의의 값이며, 암호화할 때 솔트를 함께 사용하면 솔트 값에 따라 결과 해시 값이 달라진다.

대표적인 감사 로그 기록 대상

- 사용자의 로그인/로그아웃 내역
- 암호 초기화 등 설정 변경 내역
- 환자 기록을 조회한 의료진 정보
- 계약서의 수정 이력

> 감사 로그는 데이터 조회 및 변경 이력, 작업자, 시점 등의 정보를 기록해 활동을 입증하는 증거로 사용된다.

서버 프로그램을 개발할 때 신경쓸 것

- 입력 값 검증: 클라이언트가 전송한 값이 올바르다고 가정하지 말고 모든 값을 검증해야 한다. 검사 항목으로는 필수 여부, 길이 제한, 미허용 값 등이 있다.
- 개인 정보/민감 정보 암호화: 로그인 암호와 바이오 정보처럼 인증에 사용되는 정보뿐만 아니라 주민 번호, 운전 면허 번호 같은 고유 식별 정보도 암호화해야 한다.
- 에러 메시지에 시스템 정보 미노출: 에러 메시지에 내부 IP나 DB IP와 같은 시스템 정보가 노출되지 않도록 한다.
- 보안 통신: HTTPS 처럼 데이터를 암호화해서 데이터 유출을 방지한다.
- CORS 설정: 허용된 도메인만 서버 자원에 접근할 수 있도록 제한한다.
- CSRF 대응: 주요 기능은 타 사이트에서 위조 공격이 들어오는 것을 방지하기 위해 CSRF 토큰, SameSite 쿠키, 캡차 등을 사용한다.

## Chapter 09.최소한 알고 있어야 할 서버 지식

일반적으로 로그 파일은 일정 단위로 잘라서 보관한다. 그렇게 하면 로그 파일이 계속 커지는 것을 방지할 수 있다.

## Chapter 10. 모르면 답답해지는 네트워크 기초

QUIC은 URP를 기반으로 한다. TCP의 연결 관리 기능을 QUIC 프로토콜 수준에서 제공한다.

## Chapter 11. 자주 쓰는 서버 구조와 설계 패턴

## 부록 A. 처음 해보는 성틍 테스트를 위한 기본 정리

|테스트 종류|설명|
|---|---|
|부하(load) 테스트|특정한 예상 부하에서 시스템이 어떻게 동작하는지 확인한다. 이 테스트를 통해 주요 기능의 응답 시간과 처리량 등의 성능 지표를 확인할 수 있고, 병목을 파악하는 데 도움이 된다.|
|스트레스(stress) 테스트|시스템의 최대 성능을 확인하기 위한 테스트이다. 예상을 뛰어넘는 부하가 발생했을 때, 시스템이 어디까지 성능을 낼 수 있는지를 확인한다.|
|지속 부하(soak) 테스트|시스템이 지속적인 부하를 견딜 수 있는지를 검증한다. 장시간 동안 일정 수준의 부하를 주어 성능 저하가 발생하는지 확인하며 메모리 누수도 탐지할 수 있다.|
|스파이크(spike) 테스트|급격하게 트래픽이 변화할 때 시스템의 반응성과 안정성을 검증하는 테스트이다. 순간적으로 트래픽이 급증했을 때, 성능 저하나 실패가 발생하는지를 확인한다.|

성능 테스트를 진행하는 일반적인 방식은 낮은 부하에서 시작해서 점진적으로 부하를 높이는 것이다. 이렇게 부하를 증가시키면 초기에는 처리량도 함께 증가한다. 그러다 일정 부하 구간에 도달하면 처리량의 증가 폭이 줄어들기 시작하고, 어느 시점부터는 처리량과 응답 시간이 급격히 저하되는데, 이때 성능이 저하되기 전의 최대 처리량을 포화점이라고 하고 포화점을 지나 성능이 꺾이기 시작하는 구간을 버클존이라고 한다.

포화점이 목표로 한 성능보다 높다면 만족하면서 성능 테스트를 마칠 수 있지만 목표치보다 낮다면 병목 지점을 찾아 제거해야 한다. 일반적으로 웹 서버의 병목 지점은 호출 비중이 높으면서도 응답 시간이 긴 기능과 관련되어 있다. 다음 요인들이 응답 시간에 영향을 준다.

- DB 연동(쿼리 실행 시간)
- 외부 연동 시간
- 트래픽 대비 부족한 커넥션 풀 크기

> 어떤 지점에서 병목이 발생하는지 확인한 뒤, 서버 확장, 캐시 적용, 비동기 연동과 같은 수단을 강구해서 응답 시간을 줄일 수 있다. 응답 시간을 줄인 만큼 포화점을 높일 수 있을 것이다.

성능 테스트에서 중요한 지표 중 하나는 응답 시간이다. 응답 시간은 다음과 같이 여러 값을 측정 한다.

- 평균
- 최대
- 최소
- 중앙
- 99% 나 95% 백분위

> 응답 시간의 평균과 최대 값의 차이가 크다면 99%나 95% 백분위 값을 함께 확인해야 한다. 이 백분위 값이 최대 응답 시간보다 평균 값에 가깝다면 최대 값은 이상치일 수 있다.  
> 중앙 값과 평균 값으 ㅣ차이도 중요하다. 응답 시간이 중앙 값보다 평균 값이 더 큰 좌편향 분포를 보인다면 이는 응답 시간이 전반적으로 평균보다 느리다는 것을 의미 한다.

처리량, 에러율, CPU 사용률도 함께 확인한다.

성능 테스트를 설계할 때는 다음 사항들을 고려해야 한다.

- 시스템의 트래픽 패턴
- 동시 요청 사용자 수 / 트래픽 규모
- 기능별 요청 비율
- 데이터 크기
- 워밍업
- 적절한 목표치 설정

성능 테스트 실행 시 주의 사항

- 테스트 대상 시스템과 부하기를 한 장비에서 실행하지 말자
  - 부하를 발생할 장비의 성능도 중요하다. 대량의 부하를 발생시켜야 하는데 장비의 성능이 나쁘면 대초에 부하 자체를 제대로 발생시킬 수 없다.
- 서버의 설정에 제한을 걸고 부하 테스트를 실행하지 말자
  - NginX 는 DDOS 공격을 막기 위해 limit_req_zone 설정을 사용해서 IP 당 초당 요청 개수를 제한하고 있다.
  - 서버의 스레드 풀 개수나 DB 커넥션 풀 크기도 테스트할 부하 규모에 맞게 풀의 크기를 미리 설정한다.
- 운영 시스템과 동일한 네트워크 환경에서 부하 테스트를 진행하는 것을 조심하자
  - 실 운영 시스템과 테스트 대상 시스템을 동일 네트워크에 넣고 테스트를 실행하면 테스트가 발생시키는 트래픽이 실 운영 환경에 영향을 줄 수 있다.
  - 동일 네트워크에 있다면 심야에 스트레스 테스트를 돌릴 수 있다.
- 외부 서비스를 연동하는 기능을 테스트할 때는 실제 외부 서비스를 사용하지 않게 주의해야 한다
- 테스트 대상 시스템은 최대한 실제 운영 환경과 동일하게 구성해야 한다

## 부록 B. NoSQL 이해하기

데이터 시스템에서 NoSQL을 사용하는 주된 이유

- 대용량 데이터나 분산 처리
- 고속의 읽기와 쓰기 성능
- 특정한 요구사항에 맞는 데이터 설계
- 비정형 데이터 처리 또는 유연한 스키마

NoSQL 종류

- 키-값 DB
  - 아마존의 DynamoDB, 레디스
  - 주된 용도: 세션 관리, 캐시, 설정 관리
- 문서 DB
  - MongoDB
  - 스키마가 고정되어 있지 않음
  - 어플리케이션에서 사용하는 데이터 모델과 DB에서 사용하는 데이터 모델이 거의 일치
  - 주된 용도: 컨텐츠 관리(유연한 스키마를 이용해서 다양한 종류의 컨텐츠를 관리), 제품 카탈로그(다양한 메타데이터를 가진 카탈로그를 제공)
- 칼럼 패밀리 DB
  - 키-값 DB의 확장 버전으로 볼 수 있음
  - Cassandra, HBase
  - 각 행은 여러 칼럼을 가질 수 있는데 여러 칼럼들을 그룹으로 묶어 관리
  - 대량의 데이터를 저장할 수 있는 수평 확장이 용이한 구조
  - 주된 용도: 대규모 데이터 관리(채팅 플랫폼의 채팅 메시지나 IoT 데이터 등 대규모 데이터에 대한 저장과 조회가 필요한 서비스에 사용)
- 그래프 DB
  - 데이터를 그래프 형태로 관리
  - 노드 데이터가 있고 노드와 노드를 연결하는 엣지 데이터가 있음
  - 노드와 엣지로 데이터의 관계를 표현하며 노드와 엣지는 필요한 프로퍼티를 갖는다
  - Neo4j
  - 주된 용도: 소셜, 추천, 부정 탐지

NoSQL 도입 시 고려 사항

- 트랜잭션 지원 여부
- 데이터 모델이 요구사항에 적합한지
- 확장성과 성능 요구
- 운영과 개발 역량 확보

## 부록 C. DB로 분산 잠금 구현하기

[코드](./distlock/)
