# 주니어 백엔드 개발자가 반드시 알아야 할 실무 지식 - 1회

## Chapter 02. 느려진 서비스, 어디부터 봐야 할까

성능과 관련된 지표: 네트워크 속도, 디스크 속도, 메모리 크기, 디바이스의 CPU 속도 등

> 이 중 서버 성능과 가장 관련 있는 것: 응답시간과 처리량

서버 처리 시간은 다음과 같은 요소를 포함

- 로직 수행(if, for 등)
- DB 연동(SQL 실행)
- 외부 API 연동
- 응답 데이터 생성(전송)

> 이 중 DB 연동과 외부 API 연동이 큰 비중을 차지 -> 응답 시간을 줄일 때 여기에 집중

TPS 를 높이는 방법

- 서버가 동시에 처리할 수 있는 요청 수를 늘려 대기 시간 줄이기
- 처리 시간 자체를 줄여 대기 시간 줄이기

TPS 를 높이려면 먼저 성능 문제가 발생하는 지점을 찾아야 한다. 문제 지점을 찾는 간단한 방법은 처리 시간이 오래 걸리는 작업을 식별하는 것이다. 성능 문제는 응답 시간이 길어지면서 발생하는 경우가 많기 때문이다. 이때 모니터링 도구가 유용하다. 성능 문제는 주로 DB나 외부 API를 연동하는 과정에서 발생했다.

일단 급한 불을 끄고 나서 근본적인 해결책을 모색해야 한다.

- 수직 확장(scale-up)
- 수평 확장(scale-out)

TPS 를 높이기 위해 무턱대고 서버를 추가해서는 안된다. 실제 병목 지점이 어디인지 파악하는 게 중요하다. DB나 외부 API 성능이 문제인 경우 서버를 추가한다고 해서 TPS는 향상되지 않는다.

트래픽이 순간적으로 급증하는 패턴을 보인다면 커넥션 풀의 최소 크기를 최대 크기에 맞추는 것이 좋다. 트래픽이 점직적으로 증가할 때는 DB 연결 시간이 성능에 큰 영향을 주지 않지만 트래픽이 급증할 경우 DB 연결 시간도 성능 저하의 주요 원인이 될 수 있기 때문이다.

커넥션 풀 크기를 늘리면 처리량을 높일 수 있으나, DB 상태(CPU 사용률 등)을 보고 늘려야 한다. 수평 확장도 마찬가지다.

MySQL과 같은 DB는 클라이언트와 일정 시간 동안 상호작용이 ㅇ벗으면 자동으로 연결을 끊는 기능을 제공한다. 연결 끊김으로 인해 발생하는 에러를 방지하기 위해 커넥션 풀은 다음 2가지 기능을 제공한다.

- 최대 유휴 시간 지정
- 유효성 검사 지원
- 최대 유지 시간

DB 서버를 확장하지 않고도 응답 시간과 처리량을 개선하고 싶다면 캐시 사용을 고려할 수 있다. (로컬 캐시, 리모트 캐시)

트래픽이 순간적으로 급증하는 패턴을 보인다면 캐시에 데이터를 미리 저장하는 것도 고려할 필요가 있다.

가비지 컬렉터는 정해진 규칙(e.g. 힙 메모리 사용량이 일정 비율 초과, 일정 주기)에 따라 사용하지 않는 메모리를 찾아서 반환한다.

가비지 컬렉터는 응답 시간에 영향을 줄 수 있다. 가비지 컬렉터가 실행되는 동안 애플리케이션의 실행이 일시 중단된다.

GC 알고리즘과 메모리 사용 패턴에 따라 차이가 있지만 사용하는 메모리양과 객체 수가 많을수록 GC 실행 시간은 길어진다.

파일 다운로드와 같은 기능을 구현할 때는 스트림을 활용하여 메모리 사용량을 줄인다.

응답 시간에는 데이터 전송 시간이 포함되고 이는 2가지 요인에 영향을 받는다.

- 네트워크 속도
- 전송 데이터 크기

> 네트워크 속도를 제어할 수는 없지만, 데이터의 크기는 압축을 통해 제어할 수 있다.

응답 데이터를 압출할 때 고려 사항

- html, css, js, json과 같은 텍스트 형식의 응답은 압축률이 높아 효과적이다. 하지만 jpeg 이미지나 zip 파일 처럼 이미 압축한 데이터에는 다시 압축해도 효과가 없다.
- 웹 서버에서 압축을 적용했더라도 방화벽이 이를 해체해 응답할 수 있다. 즉, 웹 서버에 압축 설정을 적용했음에도 실제 응답 데이터가 압축되지 않는다면 방화벽 설정도 확인해야 한다.

> 응답 데이터의 크기는 곧 비용으로 연결 된다.

HTTP 프로토콜(Cache-Control, Expires)를 사용해 클라이언트 캐시를 활용하여 정적 데이터를 캐싱하여 트래픽을 줄일 수 있다.

CDN

- 여러 CDN 을 통해서 오리진 서버에 대한 부담을 줄일 수 있다.
- CDN은 지역적으로 가까운 곳에 위치하여 콘텐츠를 더 빠르게 받을 수 있고 트래픽 비용도 줄일 수 있다.

정적 파일을 관리할 때는 파일 크기를 주의해야 한다. 너무 큰 용량의 파일은 비용 청구 혹은 네트워크 트래픽 문제가 발생할 수 있으므로 제한 설정 등이 필요하다.

사용자가 순간적으로 폭증할 때

- 서버 미리 증설
  - API 서버 증설, DB 증설(쉽게 할 수 없기에 예상되는 트래픽에 맞춰 미리 증설)
  - 비용 문제 고려: API 서버는 다시 줄일 수 있지만, DB는 그렇지 않다. 짧은 시간을 위해 고정 비용(DB 비용)이 커지는 격이다.
- 수용할 수 있는 수준의 트래픽만 받아들이고 나머지는 대기 처리
  - 서버를 증설하지 않고도 서비스를 안정적으로 제공할 수 있다.
  - 사용자의 지속적인 새로 고침으로 인한 트래픽 폭증도 방지할 수 있다. 사용자는 새로 고침할 경우 순번이 뒤로 밀리기 때문에 불필요한 새로 고침을 자제하게 된다.

## Chapter 03. 성능을 좌우하는 DB 설계와 쿼리

데이터가 많지 않은 상황에서는 테이블 풀 스캔을 하더라도 성능 문제가 발생하지 않기 때문에 꼭 인덱스를 생성할 필요는 없다. 하지만 데이터가 많아지는 경우 조회 성능을 위해 인덱스를 생성해야 한다.

엘라스틱서치 같은 검색 엔진을 사용하면 DB를 사용하지 않고 검색 기능을 구현할 수 있지만, 별도의 검색 엔진을 구성하기 힘든 상황이라면 DB가 제공하는 전문 검색 기능 사용을 고려해볼 수 있다.

인덱스 생성시 조회 조건은 2개 칼럼을 이용하지만 데이터 수가 1개 칼럼으로 충분한 경우 꼭 복합 인덱스를 생성하지 않아도 될 수 있다.

인덱스를 생성할 때는 선택도(selectivity)가 높은 칼럼을 골라야 한다. 선택도는 인덱스에서 특정 칼럼의 고유한 값 비율을 나타낸다. 선택도가 높을수록 인덱스를 이용한 조회 효율이 높아진다.

> 특정 상태의 데이터를 조회해야 하는 등의 상황에서는 선택도가 높지 않아도 엔덱스 칼럼으로 적합하다. (e.g. 작업 중 상태의 데이터 조회)

효과가 적은 인덱스를 추가하면 오히려 성능이 나빠질 수 있다. 인덱스는 조회 속도를 빠르게 해주지만 데이터 추가, 변경, 삭제 시에는 인덱스 관리에 따른 비용이 추가되기 때문이다. 또한 인덱스 자체도 데이터이기 때문에 인덱스가 많아질수록 메모리와 디스크 사용량도 함께 증가한다.

> 꼭 조회 조건에 필요한 모든 칼럼을 추가할 필요 X

새로 추가할 쿼리가 기존에 존재하는 인덱스를 사용하지 않을 때는 요구사항을 일부 변경할 수 있는지 검토해보자.

> 예약 테이블에 예약 날짜에만 인덱스가 있는 경우: 예약자 이름으로 조회 -> 특정 일자에 예약한 예약자 이름으로 조회

인덱스가 아니어도 조회 성능을 개선할 방법

- 미리 집계하기
- 페이지 기준 목록 조회 대신 ID 기준 목록 조회 방식 사용하기
- 조회 범위를 시간 기준으로 제한하기
  - 특정 일자, 시간의 데이터는 비교적 적기때문에
- 전체 개수 세지 않기
- 오래된 데이터 삭제 및 분리 보관하기
  - 데이터 개수가 늘어날수록 쿼리 실행 시간은 증가
- DB 장비 확장하기
  - scale-up, scale-out
- 별도 캐시 서버 구성하기

> DELETE 쿼리를 사용한다고 실제 디스크 용량이 줄어들지는 않는다. 데이터가 삭제되었다는 표시만 남기고, 삭제된 공간은 향후 재사용한다. 이것이 반복되면 데이터가 흩어져 저장되고 빈 공간이 생기게 되는 단편화 현상이 발생할 수 있다. 단편화가 심해지면 디스크 I/O가 증가하면서 쿼리 성능이 저하될 수 있고 디스크 낭비도 발생한다. 이를 해결하는 방법 중 하나는 최적화 작업이다. 최적화는 데이터를 재배치해 단편화를 줄이고, 물리적인 디스크 사용량까지 줄여주는 효과가 있다.

알아두면 좋을 몇 가지 주의 사항

- 쿼리 타임아웃
- 상태 변경 기능은 복제 DB 에서 조회하지 않기
- 배치 쿼리 실행 시간 증가
  - 커버링 인덱스 활용
  - 데이터를 일정 크기로 나눠 처리
- 타입이 다른 칼럼 조인 주의 -> 인덱스 사용 불가능
  - 두 칼럼의 타입을 맞춰서 비교해야 한다
- 테이블 변경은 신중하게
  - MySQL의 겨웅 테이블을 변경할 때 새 테이블을 생성하고 원본 테이블의 데이터를 복사한 뒤, 복사가 완료되면 새 테이블로 대체하는데, 이 과정에서 dml 작업을 허용하지 않기 때문에 복사 시간만큼 서비스가 멈춘다.
  - dml 을 허용하면서 테이블을 변경하는 기능도 있지만 항상 가능한 것은 아니다. 그래서 데이터가 많은 테이블은 점검 시간을 잡고 변경하는 경우가 많다.
- DB 최대 연결 개수

## Chapter 04. 외부 연동이 문제일 때 살펴봐야 할 것들

외부 연동에서 가장 중요한 설정 중 하나는 타임아웃(연결 타임아웃, 읽기 타임아웃)

외부 연동에 실패했을 때 처리 방법 중 하나는 재시도

재시도를 해도 되는 조건

- 단순 조회 기능
- 연결 타임아웃
- 멱등성을 가진 변경 기능

같은 API 라도 실패 원인에 따라 재시도 여부를 결정해야 한다.

> 검증 오류는 재시도를 해도 실패

연동 서비스에 임계치 이상의 요청을 보내면서 발생하는 성능 저하 문제를 완화하는 방법은, 연동 서비스에 요청을 일정 수준 이상으로 보내지 않는 것이다.

> 벌크헤드 패턴: 각 구성 요소를 격리함으로써 한 구성 요소의 장애가 다른 구성 요소에 영향을 주지 않도록 설계하는 패턴

서킷브레이커를 통해서 연동 서비스가 장애 상활일 때는 연동 대신 바로 에러를 응답하고, 정상화되었을 때 연동을 재개하여 연동 서비스의 장애가 주는 영향을 줄일 수 있다.

외부 연동에 실패했을 때 트랜잭션 롤백

- 읽기 타임아웃이 발생해 트랜잭션을 롤백할 때는, 외부 서비스가 실제로는 성공적으로 처리했을 가능성을 염두에 두어야 한다.
- 트랜잭션을 롤백했는데 외부 서비스가 실제로는 성공했을 경우
  - 일정 주기로 두 시스템의 데이터가 일치하는지 확인하고 보정
  - 성공 확인 API 호출
    - 읽기 타임아우이 발생한 경우, 일정 시간 후에 이전 호출이 실제로 성공했는지 확인하는 API 호출
    - 성공 응답: 트랜잭션 지속
    - 실패 응답: 트랜잭션 롤백
  - 취소 API 호출
    - '성공 확인 API 호출'의 변형
    - 읽기 타임아웃이 발생한 뒤 일정 시간 후에 취소 API 호출

> 성공 확인 API나 취소 API를 호출하는 방식은 연동 서비스가 지원할 때만 사용할 수 있고, 이 또한 호출하는 과정에서 타임아웃이 발생할 수 있다. 따라서 두 시스템 간 데이터 일관성이 중요한 기능이라면 정기적으로 데이터 일치를 확인하는 프로세스를 갖추는 것이 바람직하다.

외부 연동은 성공했는데 DB 연동에 실패해서 트랜잭션 롤백

- 취소 API 호출
- 일정 주기로 데이터가 맞는지 비교

DB 트랜잭션 범위 안에서 외부 연동을 수행할 때, 트랜잭션 처리 외에도 **외부 연동이 느려지면서 발생하는 커넥션 풀 부족 현상**도 주의해야 한다.

HTTP 연결도 커넥션 풀을 사용하면 연결 시간을 줄일 수 있어 응답 속도 향상에 도움이 된다.

HTTP 커넥션 풀을 사용할 때 고려사항

- HTTP 커넥션 풀의 크기
- 풀에서 HTTP 커넥션을 가져올 때까지 대기하는 시간
- HTTP 커넥션을 유지할 시간(keep alive)

## Chapter 05. 비동기 연동, 언제 어떻게 써야 할까

많은 연동에서 비동기 방식을 사용해도 된다.

- 쇼핑몰에서 주문이 들어오면 판매자에게 푸시 보내기(푸시 서비스 연동)
- 학습을 완료하면 학생에게 포인트 지급(포인트 서비스 연동)
- 컨텐츠를 등록할 때 검색 서비스에도 등록(검색 서비스 연동)
- 인증 번호를 요청하면 SMS로 인증 메시지 발송(SMS 발송 서비스 연동)

> 1. 시차가 생겨도 문제 되지 않는다.
> 2. 일부 기능은 실패했을 떄 재시도가 가능하다.
> 3. 연동에 실패했을 떄 나중에 수동으로 처리할 수 있는 기능도 있다.
> 4. 연동에 실패했을 때 무시해도 되는 기능도 있다.

외부 연동이 4가지 특징 중 일부에 해당하면 비동기로 처리할 수 있는지 검토해볼 수 있다.

비동기 연동의 다양한 구현

1. 별도 스레드로 실행하기
2. 메시징 시스템 이용하기
3. 트랜잭션 아웃박스 패턴 사용하기
4. 배치로 연동하기
5. CDC 이용하기

별도 스레드로 실행되는 코드는 내부 연동 과정에서 발생한 오류를 직접 처리해야 한다.

메시지 시스템 이점

1. 시스템 간에 영향을 주지 않는다.
   - 메시징 시스템은 중간에서 메시지를 보관하는 버펴 역할을 한다.
2. 확장에 용이하다
   - 다른 시스템이 추가되더라도 추가에 대한 코드를 작성할 필요 없다.

카프카 특징

- 높은 처리량을 자랑한다. 초당 백 만 개 이상의 메시지를 처리할 수 있다.
- 수평 확장이 용이하다. 서버(브로커), 파티션, 소비자를 늘리면 된다.
- 카프카는 메시지를 파일에 보관해서 메시지가 유실되지 않는다.
- 1개의 토픽이 여러 파티션을 가질 수 있는데, 파티션 단위로 순서를 보장한다. 하지만 토픽 수준에서는 순서를 보장할 수 없다.
- 소비자는 메시지를 언제든지 재처리할 수 있다.
- 풀(pull) 모델을 사용한다. 소비자가 카프카 브로커에서 메시지를 읽어가는 방식이다.

래빗MQ 특징

- 클러스터를 통해 처리량을 높일 수 있다. 단, 카프카보다 더 많은 자원을 필요로 한다.
- 메모리에만 메시지를 보관하는 큐 설정을 사용하면 장애 상황 시 메시지가 유실될 수 있다.
- 메시지는 큐에 등록된 순서대로 소비자에 전송된다.
- 메시지가 소비자에 전달됐는지 확인하는 기능을 제공한다.
- 푸시(push) 모델을 사용한다. 래빗MQ 브로커가 소비자에 메시지를 전송한다. 소비자의 성능이 느려지면 큐에 과부하가 걸려 전반적으로 성능 저하가 발생할 수 있다.
- 다재다능하다. AMQP, STOMP 등 여러 프로토콜을 지원하고, 게시/구독 패너뿌ㄴ만 아니라 요청/응답, 점대점 패턴을 지원한다. 또한 우선순위를 지정해서 처리 순서를 변경할 수도 있다.

레디스 pub/sub 특징

- 메모리를 사용하므로 지연 시간이 짧고, 래빗MQ 대치 처리량이 높다.
- 구독자가 없으면 메시지가 유실된다.
- 기본적으로 영구 메시지를 지원하지 않는다.
- 모델이 단순해서 사용하기 쉽다.

메시지 전송 과정에서 오류 처리

- 무시
  - 메시지 유실된다
- 재시도
  - 중복된 메시지 전송될 수 있다
  - 메시지마다 고유 식별자를 사용하면 메시지 소비자가 중복 메시지 여부를 판단하는 데 도움이 된다
- 실패 로그
  - 나중에 후처리를 하는 데 사용된다

잘못된 메시지가 전송되는 문제를 방지하려면 트랜잭션이 끝난 뒤에 메시지를 전송해야 한다.

메시지 소비자는 다음 2가지 이유로 동일 메시지를 중복해서 처리할 수 있다.

- 메시지 생산자가 같은 데이터를 가진 메시지를 메시징 시스템에 두 번 전송
- 소비자가 메시지를 처리하는 과정에서 오류가 발생해서 메시지 재수신

메시지에 고유한 ID를 부여해서 이미 처리했는지 여부를 추적하여 이미 처리한 메시지는 다시 처리하지 않고 무시할 수 있다. 메시지를 처리했는지 여부는 DB 테이블에 기록하거나 메모리에 집합으로 관리하면 된다. 메모리로 관리할 때는 메모리 부족 에러가 발생하는 것을 막기 위해 일정 개수의 메시지 ID만 유지한다.

멱등성을 갖도록 API를 구현하여 메시지 재수신에 따른 중복 처리 대응 가능

소비자가 메시지를 잘 소비하고 있는지 모니터링 해야 한다.

메시지의 종류

- 이벤트
  - 어떤 일이 발생했음을 알려주는 메시지
  - 상태 변경과 관련
  - 정해진 수신자가 없다
  - 소비자 확장에 적합
- 커맨드
  - 무언가를 요청
  - 메시지를 수신할 측의 기능 실행에 초점

메시지 데이터가 유실되지 않도록 보장하는 방법: 데이터를 DB 저장, 저장된 메시지를 읽어 메시징 시스템에 전송. -> 트랜잭션 아웃박스 패턴

트랜잭션 아웃박스 패턴은 하나의 DB 트랜잭션 내에서 다음 2가지 작업 수행

- 실제 업무 로직에 필요한 DB 변경 작업을 수행
- 메시지 데이터를 아웃박스 테이블에 추가

아웃 박스 테이블에 쌓인 메시지 데이터는 별도의 메시지 중계 프로세스가 주기적으로 읽어서 메시징 시스템에 전송

발송 와뇰를 표시하는 방법

- 아웃박스 테이블에 발송 상태 칼럼(발송 대기, 발송 완료, 발송 실패)
- 메시지 중계 서비스가 성공적으로 전송한 마지막 메시지 ID를 기록하는 방식

> 발송 상태 칼럼 방식이 선호됨. 2개 이상의 메시지 중계 서비스가 하나의 아웃박스 테이블을 함께 사용하는 환경이라면 각 중계 서비스가 고유하게 마지막 ID를 관리해야 하므로, 이 경우에는 마지막 메시지 ID를 기록하는 방식이 더 적합할 수 있다.

아웃박스 테이블 구조

|칼럼|타입|설명|
|---|---|---|
|id|bigint|단순 증가 값(PK). 저장된 순서대로 증가하는 값을 사용한다.|
|message_id|varchar|메시지 고유 ID(고유키)|
|message_type|varchar|메시지 타입. 메시지 종류 구분(LoginFailed, OrderPlaced, ...)|
|payload|clob|메시지 데이터. json, xml, ...|
|status|varchar|이벤트 처리상태(WAITING, DONE, FAILED). 대기 상태인 메시지 데이터만 조회하기 때문에, 어떤 조건에서 실패 상태로 바꿀지 결정해야 한다. 실패 횟수를 기준으로 자동으로 상태를 변경할 수도 있고, 상태를 모니터링하다가 수동으로 변경할 수도 있다. 예를 들어 메시지 발송에 5회 실패하면 실패함 상태로 바꾸고 다음 메시지를 처리할 수 있다. 또는 실패 횟수가 10회를 넘어가면, 모니터링 시스템을 통해서 메시지 발송이 지연되고 있다는 사실을 운영팀에 알리고, 운영팀이 수동으로 실패함 상태로 바꾸도록 할 수도 있다. 실패 상태로 바뀐 메시지는 알맞은 후속조치를 해야 한다. memo나 remark와 같은 칼럼을 추가해서 실패 메시지를 아웃박스 테이블에 기록하면, 실패 이유를 파악하는 데 도움이 된다. 실패가 아니라 수동으로 특정 메시지를 전송하고 싶지 않을 때 제외함(EXCLUDED)를 추가하여 사용할 수 있다. |
|fail_count|int|실패 횟수|
|occured_at|timestamp|메시지 발생 시간|
|processed_at|timestamp|메시지 처리 시간|
|failed_at|timestamp|마지막 실패 시간|

CDC 처리기는 전달받은 변경 데이터를 확인하고 가공한 뒤에 대상 시스템에 전파한다.

목적에 따라 CDC 처리기는 DB, 메시징 시스템, API 등 다양한 대상에 데이터를 전파할 수 있다.

> CDC 는 데이터의 변경 분을 전달한다. 이는 어떤 일이 발생했음을 알려주는 이벤트 메시지에 가깝다. 하지만 이벤트처럼 정확하게 의미를 전달하지는 못한다.

시스템이 복잡해서 연동 코드를 넣기 부담스러울 때 CDC를 활용할 수 있다.
