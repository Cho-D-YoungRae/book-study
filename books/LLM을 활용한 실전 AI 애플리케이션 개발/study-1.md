# LLM을 활용한 실전 AI 애플리케이션 개발 - 1회독

## Chapter 01. LLM 지도

LLM은 다음에 올 단어가 무엇일지 예측하면서 문장을 하나씩 만들어 가는 방식으로 텍스트를 생성하는데, 이렇게 다음에 올 단어를 예측하는 모델을 `언어 모델`이라고 한다.

임베딩은 거리를 계산할 수 있기 때문에 다음과 같은 작업에 활용할 수 있다.

- 검색 및 추천: 검색어와 관련이 있는 상품을 추천한다.
- 클러스터링 및 분류: 유사하고 관련이 있는 데이터를 하나로 묶는다.
- 이상치 탐지: 나머지 데이터와 거리가 먼 데이터는 이상치로 볼 수 있다.

딥러닝 모델이 텍스트 데이터를 학습하는 가장 대표적인 방법인 `언어 모델링`

`언어 모델링`이란, 모델이 입력받은 텍스트의 다음 단어를 예측해 텍스트를 생성하는 방식

`언어 모델링`은 텍스트를 생성하는 모델을 학습스키는 방법으로도 사용되지만, 대량의 데이터에서 언어의 특성을 학습하는 사전 학습 과제로도 많이 사용됨

자연어 처리 분야에서도 이미지 인식에서와 같이 전이 학습 개념을 활용하고 싶었지만 마땅한 사전 학습 방식을 찾지 못하고 있었다. 그러던 중 2018년 다음 단어를 예측하는 `언어 모델링` 방식으로 사전 학습을 수행했을 때 훨씬 적은 레이블 데이터로도 기존 지도학습 모델의 성능을 뛰어넘는다는 사실을 발견했다.

당시 많이 활용되던 RNN에서 언어 모델링이 사전 학습 과제로 적합하다는 사실이 확인됐는데, 트랜스포머 모델에서도 `언어 모델링`으로 사전 학습을 수행했을 때가 그렇지 않았을 때에 비해 다운스트림 과제에서 모델의 성능이 높았다고 발표되었다. 이를 통해 `언어 모델링`은 자연어 처리 분야에서 가장 대표적인 사전 학습 방법으로 자리 잡았다.

트랜스포머 아키텍처는 RNN의 순차적인 처리 방식을 버리고, 맥락을 모두 참조하는 어텐션 연산을 사용해 RNN의 문제를 대부분 해결

> RNN이 하나의 잠재 상태로 맥락을 압축하던 것과는 달리 맥락 데이터를 그대로 모두 활용해 다음 단어를 예측

트랜스포머 아키텍처는 맥락을 압축하지 않고 그대로 활용하기 때문에 성능을 높일 수 있지만

- 입력 텍스트가 길어지면 맥락 데이터를 모두 저장하고 있어야 하기 때문에 메모리 사용량이 증가
- 매번 다음 단어를 예측할 때마다 맥락 데이터를 모두 확인해야 하기 때문에 입력이 길어지면 예측에 걸리는 시간 증가
- 즉, 성능이 높아지는 대신, 무겁고 비효율적인 연산 -> 많은 연산량이 필요하다는 단점
- 성능이 좋고 순차적으로 처리하는 RNN과 달리 병렬 처리를 통해 학습 속도를 높일 수 있어 현재는 대부분의 LLM이 트랜스포머 아키텍처를 기반으로 함
- 최근 뛰어난 성능과 효율성을 갖춘 새로운 아키텍처인 맘바(Mamba)가 기대를 받고 있다

왜 모델의 크기가 커지고 학습 데이터가 많을수록 모델의 성능이 높아질까?

- 언어 모델이 학습 데이터를 아북한다는 관점으로 볼 수 있음
  - zip과 같은 무손실 압축이 아니라 공통되고 중요한 패턴을 남기는 손실 압축
- 압축의 관점에서 모델이 커지면 학습 데이터가 갖고 있는 언어 생성 패턴을 더 많이 학습할 수 있기 때문에 모델 성능이 높아진다고 이해할 수 있음
- 모델이 계속 커진다고 성능이 높아지지는 않고 학습 데이터의 크기가 최대 모델의 크기의 상한

GPT-3를 챗GPT로 바꾼 것은 `지도 미세 조정(supervised fine-tuning)`과 `RLHF(Reinforcement Learning from Human Feedback)`이라는 기술

- 이 기술을 통해 챗GPT는 그저 사용자가 한 말 다음에 이어질 말을 생성하는 것이 아니라 사용자의 요청을 해결할 수 있는 텍스트 생성

LLM이 생성하는 답변을 사용자의 요청 의도에 맞추는 것을 `정렬(alignment)`라고 함

지도 미세 조정은 정렬을 위한 가장 핵심적인 학습 과정으로서, 언어 모델링으로 사전 학습한 언어 모델을 지시 데이터셋으로 추가 학습하는 것을 뜻함

OpenAI는 수많은 데이터 작업자를 고용해 LLM이 받을 법한 질문과 그에 대한 답변을 작성하게 했고 이 데이터를 활용해 지도 미세조정을 수행하여 챗GPT와 같이 사용자의 요청에 맞춰 응답하는 모델을 만들 수 있었음

하지만 사용자의 요청에 맞춰 응답하는 것이 항상 옳은 것은 아님(폭탄이나 약물 제조 방법 등). 같은 내용의 답변이라도 사용자가 더 이해하기 쉽게 생성하거나 인종, 성별 등에 차별적인 표현을 사용하지 않는 등 다양한 관점에서 사용자에게 도움이 되도록 노력해야 함

OpenAI 에서는 두 가지 답변 중 사용자가 더 선호하는 답변을 선택한 데이터셋을 구축 -> 선호 데이터셋(preference dataset)

선호 데이터셋으로 LLM의 답변을 평가하는 리워드 모델(reward model)을 만들고 LLM이 점점 더 높은 점수를 받을 수 있도록 추가 학습하는데, 이때 강화 학습을 사용하기 때문에 이 기술을 일컬어 `RLHF`라고 부름

OpenAI 등의 상업용 API의 모델은 오픈소스 LLM에 비해 모델이 크고 범용 텍스트 생성 능력이 뛰어나지만 오픈소스 LLM은 원하는 도메인의 데이터, 작업을 위한 데이터로 자유롭게 추가학습 할 수 있고 이렇게 추가 학습을 하는 경우 모델 크기가 작으면서도 특정 도메인 데이터나 작업에서 높은 성능을 보이는 모델을 만들 수 있는데, 이를 sLLM 이라고 함

LLM을 학습하고 추론할 때 GPU를 효율적으로 사용해 적은 GPU 자원으로도 LLM을 활용할 수 있도록 돕는 연구

- 모델 파라미터를 더 적은 비트로 표현하는 양자화(quantization)
- 모델 전체를 학습하는 것이 아니라 모델의 일부만 학습하는 LoRA(Low Rank Adaptation)
- 무거운 어텐션 연산을 개선해 효율적인 학습과 추론을 가능하게 하는 연구

LLM의 환각 현상을 대처하는 검색 증강 생성(RAG) 기술

> 프롬프트에 LLM이 답변할 때 필요한 정보를 미리 추가함으로써 잘못된 정보를 생성하는 문제를 줄임

## Chapter 02. LLM의 중추, 트랜스포머 아키텍처 살펴보기

RNN

- 이전 토큰의 출력을 다시 모델에 입력으로 사용하기 때문에 입력을 병렬적으로 처리하지 못함
- 순차적으로 처리해야 하기 때문에 학습 속도 느림
- 입력이 길어지면 먼저 입력한 토큰의 정보가 희석되면서 성능 떨어짐
- 성능을 높이기 위해 층을 깊이 쌓으면 그레디언트 소실(gradient vanishing)이나 그레디언트 증폭(gradient exploding)이 발생하면서 학습 불안정

트랜스포머

- RNN의 문제를 해결하기 위해 입력을 하나씩 순차적으로 처리하는 방식을 버리고 셀프 어텐션(self-attention)이라는 개념 도입
- 셀프 어텐션은 입력된 문장 내의 각 단어가 서로 어떤 관련이 있는지 계산해서 각 단어의 표현을 조정하는 역할
- RNN에 비해 다음과 같은 장점
  - 확장성: 더 깊은 모델을 만들어도 학습이 잘된다. 동일한 블록을 반복해 사용하기 때문에 확장이 용이하다.
  - 효율성: 학습할 때 병렬 연산이 가능하기 때문에 학습 시간이 단축된다.
  - 더 긴 입력 처리: 입력이 길어져도 성능이 거의 떨어지지 않는다.
- 현재 대부분의 LLM은 트랜스포머 아키텍처 활용
- 인코더: 언어를 이해하는 역할
- 디코더: 언어를 생성하는 역할

임베딩

1. 텍스트를 적절한 단위로 잘라 숫자형 ID를 부여하는 `토큰화`
2. 토큰 아이디를 토큰 임베딩 층을 통해 여러 숫자의 집합인 토큰 임베딩으로 변환
3. 위치 인코딩 층을 통해 토큰의 위치 정보를 담고있는 위치 임베딩을 추가해 최종적으로 모델에 입력할 임베딩 생성

토큰화

- 텍스트를 적절한 단위로 나누고 숫자 아이디를 부여
- 한글은 작게는 자모 단위부터 음절, 단어 단위로 나눌 수 있음
- 토큰화를 할 때는 어떤 토큰이 어떤 숫자 아이디로 연결됐는지 기록해 둔 사전(vocabulary)을 만들어야 함
- 큰 단위를 기준으로 토큰화할수록 텍스트의 의미가 잘 유지된다는 장점이 있지만, 사전의 크기가 커진다는 단점
  - 또한 OOV(Out Of Vocabulary)문제 자주 발생
- 작은 단위로 토큰화하는 경우 사전의 크기가 작고 OOV 문제를 줄일 수 있지만 텍스트의 의미가 유지되지 않는다는 단점
- 작은 단위와 큰 단위 모두 각각의 장단점이 뚜렷하기 때문에 최근에는 데이터에 등장하는 비녿에 따라 토큰화를 결정하는 `서브워드(subword)` 토큰화 방식 사용

서브워드 토큰화

> 자주 나오는 단어는 단어 단위 그대로 유지하고 가끔 나오는 단어는 더 작은 단위로 나눠 텍스트의 의미를 최대한 유지하면서 사전의 크기는 작고 효율적으로 유지

위치 인코딩

- RNN과 달리 트랜스포머는 입력을 순차적으로 처리하지 않고 모든 입력을 동시에 처리하기 때문에 텍스트의 순서 정보를 주기 위해 위치 인코딩 사용
- 'Attention is All you need' 논문에서는 사인과 코사인을 활용한 수식을 통해 위치에 대한 정보를 입력 했지만 그 이후에는 위치 인코딩도 위치에 따른 임베딩 층을 추가해 학습 데이터를 통해 학습하는 방식을 많이 활용
  - 수식을 통해 위치정보를 추가하는 방식이나 임베딩으로 위치 정보를 학습하는 방식 모두 결국 모델로 추론을 수행하는 시점에서는 입력 토큰의 위치에 따라 고정된 임베딩을 더해주기 때문에 `절대적 위치 인코딩(absolute position encoding)`이라 부름
- `절대적 위치 인코딩 방식`은 간단하게 구현할 수 있다는 장점이 있지만 토큰과 토큰 사이의 상대적인 위치 정보는 활용하지 못하고, 학습 데이터에서 보기어려웠던 긴 텍스트를 추론하는 경우에는 성능이 떨어진다는 문제
  - 최근에는 `상대적 위치 인코딩(relative position encoding)` 방식도 많이 활용
- 절대적 위치 인코딩 중 위치 정보를 학습하는 방식은 새로운 임베딩 층을 하나 추가하고 위치 인덱스에 따라 임베딩을 더하도록 구현할 수 있음

사람이 글을 이해하는 것처럼 딥러닝 모델이 작동하도록 하려면 단어 사이의 관계를 계산해 관련이 있는지 찾고, 관련이 있는 단어의 맥락을 포함시켜 단어를 재해석 해야함

- 트랜스포머 아키텍처는 이 과정을 처리하기 위해 쿼리, 키 값이라는 개념 도입
- 정보 검색 분야에서 가져온 용어
  - 쿼리: 검색창에서 검색을 할 때, 우리가 입력하는 검색어
  - 키: 쿼리와 관련이 있는지 계산하기 위해 문석가 가진 특징
  - 값: 검색 엔진이 쿼리와 관련이 깊은 키를 가진 문서를 찾아 관련도순으로 정렬해서 문서를 제공할 때 문서

임베딩을 직접 활용해 관련도를 계산하는 방식은 두 가지 문제가 발생할 수 있음

- 같은 단어끼리는 임베딩이 동일하므로 관련도가 크게 계산되면서 주변 맥락을 충분히 반영하지 못하는 경우 발생
- 토큰의 의미가 유사하거나 반대되는 경우처럼 직접적인 관련성을 띨 떄는 잘 작동하지만 문법에 의거해 토큰이 이어지는 경우처럼 간접적인 관련성은 반영되기 어려울 수 있음

트랜스포머 아키텍처에서는 위 문제를 피하기 위해 토큰 임베딩을 변환하는 가중치 W_Q, W_K 를 도입

- 가중치를 통해 토큰과 토큰 사이의 관계를 계산하는 능력을 학습시킨 것
- 값도 토큰 임베딩을 가중치(W_V)를 통해 변환
- 세 가지 가중치를 통해 내부적으로 토큰과 토큰 사이의 관계를 계산해서 적절히 주변 맥락을 반영하는 방법을 학습

멀티 헤드 어텐션

- 한 번에 하나의 어텐션만 수행하는 게 아니라 여러 어텐션 연산을 동시에 적용하면 성능을 더 높일 수 있음
- 직관적으로 이해하자면, 토큰 사이의 관계를 한 가지 측면에서 이해하는 것보다 여러 측면을 동시에 고려할 때 언어나 문장에 대한 이해도가 높아질 것

정규화

> 딥러닝 모델에서 입력이 일정한 분포를 갖도록 만들어 학습이 안정적이고 빨라질 수 있도록 하는 기법

평균과 표준편차를 구할 데이터를 어떻게 묶는지에 따라 크게 배치 정규화와 층 정규화로 구분

- 일반적으로 이미지 처리에서는 배치 정규화를 사용하고, 자연어 처리에서는 층 정규화 사용
- 배치 정규화는 모델에 입력으로 들어가는 미치 배치 사이 정규화
- 자연어 처리에서 배치 정규화를 사용하지 않는 이유를 직관적으로 이해해 보자면, 자연어 처리에서는 입력으로 들어가는 문장의 길이가 다양해서 정규화에 포함되는 데이터 수가 제각각이라 정규화 효과를 보장하기 어려움
- 층 정규화는 각 토큰 임베딩의 평균과 표준편차를 구해 정규화 수행

트랜스포머 아키텍처에서 층 정규화를 적용하는 순서에는 크게 두 가지 방식

- 사후 정규화: 어텐션과 피드 포워드 층 이후에 층 정규화 적용
  - 이전 방식(원 트랜스포머 논문)
- 사전 정규화: 먼저 층 정규화를 적용하고 어텐션과 피드 포워드 층을 통과
  - 학습이 더 안정적
  - 현재 주로 활용

피드 포워드 층

- 어텐션 연산이 입력 단어 사이의 관계를 계산해 토큰 임베딩을 조정하는 역할을 한다면 전체 입력 문장을 이해하는 연산이 필요한데, 트랜스포머 아키텍처에서는 이를 위해 완전 연결층(fully connected layer)인 피드 포워드 층 사용
- 선형 층, 드롭아웃 층, 층 정규화, 활성 함수로 구성

인코더

- 안정적인 학습이 가능하도록 도와주는 잔차 연결(residual connection) 사용
- 트랜스포머 인코더는 인코더 블록을 반복해서 쌓아서 만든다

디코더

- 인코더와 두 가지 부분에서 차이
  - 인코더는 기본적인 멀티 헤드 어텐션을 사용하지만 디코더 블록에서는 `마스크 멀티 헤드 어텐션`을 사용
    - 디코더는 생성을 담당하는 부분으로, 사람이 글을 쓸 때 앞 단어부터 수나적으로 작성하는 것처럼 트랜스포머 모델도 앞에서 생성한 토큰을 기반으로 다음 토큰을 생성
    - 이렇게 순차적으로 생성해야 하는 특징을 인과적(causal)또는 자기 회귀적(auto-regressive)라고 함
    - 텍스트를 생성할 때는 이전까지 생성한 텍스트만 확인할 수 있지만 학습할 때는 인코더와 디코더 모두 완성된 텍스트를 입력으로 받고 어텐션을 그대로 활용할 경우 미래 시점에 작성해야 하는 텍스트를 미리 확인하게 되는 문제가 생기기 때문에 이를 막기 위해 특정 시점에는 그 이전까지 생성된 토큰까지만 확인할 수 있도록 마스크를 추가
    - `is_causal=True`: 마스크 연산
  - `크로스 어텐션`
    - 인코더와 디코더가 연결되는 부분
    - 영어에서 한국어로 변역한다고 했을 때 인코더가 영어 문장을 입력으로 받아 처리한 결과를 번역한 한국어를 생성하는 디코더가 받아 활용
    - 이때 쿼리는 디코더의 잠재 상태를 사용하고 키와 값은 인코더의 결과를 사용
- 인코더와 마찬가지로 디코더 층을 여러 번쌓아 만듬

트랜스포머 아키텍처를 활용한 모델 그룹

- 인코더만 활용해 자연어 이해(Natural Language Understanding, NLU) 작업에 집중한 그룹
- 디코더만 활용해 자연어 생성(Natural Language Generation, NLG) 작업에 집중한 그룹
- 인코더와 디코더를 모두 활용해 더 넓은 범위의 작을 수행할 수 있도록 한 그룹

주요 사전 학습 메커니즘

- `인과적 언어 모델링`
  - 문장의 시작부터 끝까지 순차적으로 단어를 예측하는 방식 -> 이전에 등장한 단어들을 바탕으로 다음에 등장할 단어를 예측
  - GPT 같은 생성 트랜스포머 모델에서 인과적 언어 모델링을 핵심적인 학습 방법으로 사용
- `마스크 언어 모델링`
  - 입력 단어의 일부를 마스크 처리하고 그 단어를 맞추는 작업으로 모델 학습
  - 지금까지 생성한 문맥만 활용할 수 있다는 한계
  - 인과적 언어 모델링의 경우 단방향 예측이기 때문에 다음 단어 예측이라는 목표가 자연스럽게 정해지지만, 양방향 방식의 경우 새로운 작업 목표가 필요

## Chapter 03. 트랜스포머 모델을 다루기 위한 허깅페이스 트랜스포머 라이브러리

허깅페이스에서는 모델을 바디(body)와 헤드(head)로 구분

- 같은 바디를 사용하면서 다른 작업에 사용할 수 있도록 만들기 위해
- 예를 들어 바디는 BERT 모델을 사용하면서 작업에 따라 서로 다른 헤드 사용

허깅페이스 모델을 저장할 때 config.json 파일이 함께 저장되는데 해당 설정 파일에는 모델의 종류(model_type), 여러 설정 파라미터(num_attention_heads, num_hidden_layers 등), 어휘 사전 크기(vocab_size), 토크나이저 클래스(tokenizer_class) 등이 저장된다.

> AutoModel, AutoTokenizer 클래스는 config.json 파일을 참고해 적절한 모델과 토크나이저를 불러온다.

토크나이저도 학습 데이터를 통해 어휘 사전을 구축하기때문에 일반적으로 모델과 함께 저장한다.

허깅페이스 허브에서 모델과 토크나이저를 불러오는 경우 동일한 모델 아이디로 맞춰야 한다.

모델에 대한 정보가 config.json 파일에 저장돼 있던 것처럼 tokenizer_config.json 은 토크나이저의 종류나 설정에 대한 정보를 갖고 있고 tokenizer.json 파일은 실제 어휘 사전 정보를 갖고 있다.

토크나이저에 텍스트를 입력하면 아래와 같이 반환

- 토큰 아이디의 리스트인 input_ids
- 토큰이 실제 텍스트인지 아니면 길이를 맞추기 위해 추가한 패딩인지 알려주는 attention_mask
- 토큰이 속한 문장의 아이디를 알려주는 token_type_ids

토큰 아이디를 다시 텍스트로 돌리고 싶다면 토크나이저의 decode 메서드 사용

> \[CLS], \[SEP] 같은 특수 토큰이 추가되는데 제외하고 싶다면 skip_special_tokens=True

토큰화 결과 중 token_type_ids 는 문장을 구분하는 역할

- BERT 는 학습할 때 2개의 문장이 서로 이어지는지 맞추는 NSP(Next Sentence Prediction) 작업을 활용하는데, 이를 위해 문장을 구분하는 토큰 타입 아이디를 만듬
- 그래서 BERT ㅁ델의 토크나이저를 불러오면 문장에 따라 토큰 타입 아이디를 구분
- RoBERTa 계열 모델의 경우 NSP 작업을 학습 과정에서 제거했기 때문에 문장 토큰 구분 필요 없음 -> 그래서 토큰화 해도 없음

attention_mask 는 해당 토큰이 패딩 토큰인지 실제 데이터인지에 대한 정보

- 토크나이저의 padding 인자에 'longest'를 입력하면 입력한 문장 중 가장 긴 문장에 맞춰 패딩 토큰 추가

## Chapter 04. 말 잘듣는 모델 만들기

GPT-3 는 단순히 다음 단어를 예측하는 방식이어서 사용자의 요청에 적절히 응답하기보다는 사용자의 말에 이어질 법한 텍스트를 생성한다는 한계 -> 챗GPT가 되려면?

- 요청(또는 질문)과 답변 형식으로 된 지시 데이터셋(instruction dataset)을 통해 GPT-3가 사용자의 요청에 응답할 수 있도록 학습
- 사용자가 더 좋아하고 사용자에게 더 도움이 되는 답변을 생성할 수 있도록 추가 학습 -> 사용자의 선호(preference)를 학습
  - 선호를 학습한 LLM은 예를 들어 차별적인 표현을 사용하지 않고, 사용자가 위험해질 수 있는 정보(예: 무기 또는 약물의 제조 방법)에 대한 답변을 피하는 등 더 정제된 답변 생성

사람들이 더 선호하는 답변을 생성할 수 있도록 모델을 조정하는 방법

> LLM이 사용자의 요청에 맞춰 응답하도록 학습시키는 지도 미세 조정(supervised fine-tuning)

- 강화 학습(reinforcement learning)을 사용하는 방법
  - 근접 정책 최적화(Proximal Policy Optimization, PPO)
    - 하이퍼파라미터에 민감
    - 학습이 불안정
  - RELF(Reinforment Learning from Human Feedback)
- 사용하지 않는 방법
  - 기각 샘플링(rejective sampling)
  - 직접 선호 최적화(Direct Preference Optimization, DPO)
