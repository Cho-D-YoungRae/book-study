# LLM을 활용한 실전 AI 애플리케이션 개발 - 1회독

## Chapter 01. LLM 지도

LLM은 다음에 올 단어가 무엇일지 예측하면서 문장을 하나씩 만들어 가는 방식으로 텍스트를 생성하는데, 이렇게 다음에 올 단어를 예측하는 모델을 `언어 모델`이라고 한다.

임베딩은 거리를 계산할 수 있기 때문에 다음과 같은 작업에 활용할 수 있다.

- 검색 및 추천: 검색어와 관련이 있는 상품을 추천한다.
- 클러스터링 및 분류: 유사하고 관련이 있는 데이터를 하나로 묶는다.
- 이상치 탐지: 나머지 데이터와 거리가 먼 데이터는 이상치로 볼 수 있다.

딥러닝 모델이 텍스트 데이터를 학습하는 가장 대표적인 방법인 `언어 모델링`

`언어 모델링`이란, 모델이 입력받은 텍스트의 다음 단어를 예측해 텍스트를 생성하는 방식

`언어 모델링`은 텍스트를 생성하는 모델을 학습스키는 방법으로도 사용되지만, 대량의 데이터에서 언어의 특성을 학습하는 사전 학습 과제로도 많이 사용됨

자연어 처리 분야에서도 이미지 인식에서와 같이 전이 학습 개념을 활용하고 싶었지만 마땅한 사전 학습 방식을 찾지 못하고 있었다. 그러던 중 2018년 다음 단어를 예측하는 `언어 모델링` 방식으로 사전 학습을 수행했을 때 훨씬 적은 레이블 데이터로도 기존 지도학습 모델의 성능을 뛰어넘는다는 사실을 발견했다.

당시 많이 활용되던 RNN에서 언어 모델링이 사전 학습 과제로 적합하다는 사실이 확인됐는데, 트랜스포머 모델에서도 `언어 모델링`으로 사전 학습을 수행했을 때가 그렇지 않았을 때에 비해 다운스트림 과제에서 모델의 성능이 높았다고 발표되었다. 이를 통해 `언어 모델링`은 자연어 처리 분야에서 가장 대표적인 사전 학습 방법으로 자리 잡았다.

트랜스포머 아키텍처는 RNN의 순차적인 처리 방식을 버리고, 맥락을 모두 참조하는 어텐션 연산을 사용해 RNN의 문제를 대부분 해결

> RNN이 하나의 잠재 상태로 맥락을 압축하던 것과는 달리 맥락 데이터를 그대로 모두 활용해 다음 단어를 예측

트랜스포머 아키텍처는 맥락을 압축하지 않고 그대로 활용하기 때문에 성능을 높일 수 있지만

- 입력 텍스트가 길어지면 맥락 데이터를 모두 저장하고 있어야 하기 때문에 메모리 사용량이 증가
- 매번 다음 단어를 예측할 때마다 맥락 데이터를 모두 확인해야 하기 때문에 입력이 길어지면 예측에 걸리는 시간 증가
- 즉, 성능이 높아지는 대신, 무겁고 비효율적인 연산 -> 많은 연산량이 필요하다는 단점
- 성능이 좋고 순차적으로 처리하는 RNN과 달리 병렬 처리를 통해 학습 속도를 높일 수 있어 현재는 대부분의 LLM이 트랜스포머 아키텍처를 기반으로 함
- 최근 뛰어난 성능과 효율성을 갖춘 새로운 아키텍처인 맘바(Mamba)가 기대를 받고 있다

왜 모델의 크기가 커지고 학습 데이터가 많을수록 모델의 성능이 높아질까?

- 언어 모델이 학습 데이터를 아북한다는 관점으로 볼 수 있음
  - zip과 같은 무손실 압축이 아니라 공통되고 중요한 패턴을 남기는 손실 압축
- 압축의 관점에서 모델이 커지면 학습 데이터가 갖고 있는 언어 생성 패턴을 더 많이 학습할 수 있기 때문에 모델 성능이 높아진다고 이해할 수 있음
- 모델이 계속 커진다고 성능이 높아지지는 않고 학습 데이터의 크기가 최대 모델의 크기의 상한

GPT-3를 챗GPT로 바꾼 것은 `지도 미세 조정(supervised fine-tuning)`과 `RLHF(Reinforcement Learning from Human Feedback)`이라는 기술

- 이 기술을 통해 챗GPT는 그저 사용자가 한 말 다음에 이어질 말을 생성하는 것이 아니라 사용자의 요청을 해결할 수 있는 텍스트 생성

LLM이 생성하는 답변을 사용자의 요청 의도에 맞추는 것을 `정렬(alignment)`라고 함

지도 미세 조정은 정렬을 위한 가장 핵심적인 학습 과정으로서, 언어 모델링으로 사전 학습한 언어 모델을 지시 데이터셋으로 추가 학습하는 것을 뜻함

OpenAI는 수많은 데이터 작업자를 고용해 LLM이 받을 법한 질문과 그에 대한 답변을 작성하게 했고 이 데이터를 활용해 지도 미세조정을 수행하여 챗GPT와 같이 사용자의 요청에 맞춰 응답하는 모델을 만들 수 있었음

하지만 사용자의 요청에 맞춰 응답하는 것이 항상 옳은 것은 아님(폭탄이나 약물 제조 방법 등). 같은 내용의 답변이라도 사용자가 더 이해하기 쉽게 생성하거나 인종, 성별 등에 차별적인 표현을 사용하지 않는 등 다양한 관점에서 사용자에게 도움이 되도록 노력해야 함

OpenAI 에서는 두 가지 답변 중 사용자가 더 선호하는 답변을 선택한 데이터셋을 구축 -> 선호 데이터셋(preference dataset)

선호 데이터셋으로 LLM의 답변을 평가하는 리워드 모델(reward model)을 만들고 LLM이 점점 더 높은 점수를 받을 수 있도록 추가 학습하는데, 이때 강화 학습을 사용하기 때문에 이 기술을 일컬어 `RLHF`라고 부름

OpenAI 등의 상업용 API의 모델은 오픈소스 LLM에 비해 모델이 크고 범용 텍스트 생성 능력이 뛰어나지만 오픈소스 LLM은 원하는 도메인의 데이터, 작업을 위한 데이터로 자유롭게 추가학습 할 수 있고 이렇게 추가 학습을 하는 경우 모델 크기가 작으면서도 특정 도메인 데이터나 작업에서 높은 성능을 보이는 모델을 만들 수 있는데, 이를 sLLM 이라고 함

LLM을 학습하고 추론할 때 GPU를 효율적으로 사용해 적은 GPU 자원으로도 LLM을 활용할 수 있도록 돕는 연구

- 모델 파라미터를 더 적은 비트로 표현하는 양자화(quantization)
- 모델 전체를 학습하는 것이 아니라 모델의 일부만 학습하는 LoRA(Low Rank Adaptation)
- 무거운 어텐션 연산을 개선해 효율적인 학습과 추론을 가능하게 하는 연구

LLM의 환각 현상을 대처하는 검색 증강 생성(RAG) 기술

> 프롬프트에 LLM이 답변할 때 필요한 정보를 미리 추가함으로써 잘못된 정보를 생성하는 문제를 줄임
