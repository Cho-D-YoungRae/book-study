# Chapter 1. 사용자 수에 따른 규모 확장성

## 단일 서버

- 모든 컴포넌트가 단 한 대의 서버에서 실행
  - 웹 앱, 데이터베이스, 캐시 등이 전부 서버 한 대에서 실행

### 사용자 요청 처리 흐름

1. 사용자는 도메인 이름(api.mysite.com)을 이용하여 웹사이트에 접속.
2. 이 접속을 위해서는 도메인 이름을 도메인 이름 서비스(Domain Name Service, DNS)에 질의하여 IP 주소로 변환하는 과정이 필요
   - DNS는 보통 제3 사업자(third party)가 제공하는 유료 서비스를 이용하게 되므로, 우리 시스템의 일부 X
3. DNS 조회 결과로 IP 주소 반환
4. 해당 IP 주소로 HTTP 요청 전달
5. 요청을 받은 웹 서버는 HTML 페이지나 JSON 형태의 응답을 반환

## 데이터베이스

- 사용자가 늘면 서버 하나로는 충분하지 않아서 여러 서버를 두어야 함
- 웹/모바일 트래픽 처리 서버(웹 계층)와 데이터베이스 서버(데이터 계층)를 분리하면 그 각각을 독립적으로 확장해 나갈 수 있음

### 어떤 데이터베이스를 사용할 것인가?

#### 관계형 데이터베이스(RDB)

- 데이터를 테이블과 열, 칼럼으로 표현
- SQL을 사용하면 여러 테이블에 있는 데이터를 그 관계에 따라 조인하여 합칠 수 있음

#### 비 관계형 데이터베이스(NoSQL)

- 키-값 저장소(key-value store), 그래프 저장소(graph store), 칼럼 저장소(column store), 문서 저장소(document store)
- 일반적으로 조인 연산은 지원하지 않음
- 비관계형 DB가 바람직한 경우
    1. 아주 낮은 응답 지연시간(latency)이 요구됨
    2. 다루는 데이터가 비정형이라 관계형 데이터가 아님
    3. 데이터를(JSON, YAML, XML, ...)를 직렬화하거나 역직렬화할 수 있기만 하면 됨
    4. 아주 많은 양의 데이터를 저장할 필요가 있음

## 수직적 규모 확장 VS 수평적 규모 확장

- `수직적 규모 확장(vertical scaling)`, `스케일 업(scale up)`: 서버에 고사양 자원(더 좋은 CPU, 더 많은 RAM 등)을 추가하는 행위
- `수평적 규모 확장`, `스케일 아웃(scale out)`: 더 많은 서버를 추가하여 성능을 개선
- 서버로 유입되는 트래픽의 양이 적을 때는 수직적 확장이 좋은 선택
  - 가장 큰 장점은 단순함
  - 몇 가지 심각한 단점 존재

### 수직적 규모 확장의 단점

- 한계 존재
  - 한 대의 서버에 CPU나 메모리를 무한대로 증설할 수 없음
- 장애에 대한 복구 방안이나 다중화 방안을 제시하지 않음
  - 서버에 장애가 발생하면 웹사이트/앱 완전히 중단

### 로드밸런서

> 부하 분산 집합(load balancing set)에 속한 웹 서버들에게 트래픽을 고르게 분산하는 역할

- 사용자는 로드밸런서의 공개 IP 주소(public IP address)로 접속
  - 웹 서버는 클라이언트의 접속을 직접 처리 X
- 보안을 위해, 서버 간 통신에는 사설 IP 주소(private IP address)가 이용
  - 사설 IP 주소: 같은 네트워크에 속한 서버 사이의 통신에만 사용 가능
  - 로드밸런서는 웹 서버와 통신하기 위해 사설 주소를 이용

#### 로드밸런서 장점

- 서버 1이 다운되면 모든 트래픽은 서버 2로 전송 -> 웹사이트 전체가 다운되는 일 방지
  - 부하를 나누기 위해 새로운 서버 추가 가능
- 웹 서버 계층에 서버를 추가하면 로드밸런서가 자동적으로 트래픽 분산

### 데이터베이스 다중화

- 대부분의 애플리케이션은 읽기 연산의 비중이 쓰기 연산보다 훨씬 높기 때문에 통상 부 데이터베이스의 수가 주 데이터베이스의 수보다 많음
- `더 나은 성능`: 주-부 다중화 모델에서 모든 데이터 변경 연산은 주 데이터베이스 서버로만 전달되고, 읽기 연산은 부 데이터베이스 서버들로 분산
- `안정성(reliability)`: 자연 재해 등의 이유로 데이터베이스 서버 가운데 일부가 파괴되어도 **데이터는 보존**
- `가용성(availability)`: 하나의 데이터베이스 서버에 **장애가 발생하더라도** 다른 서버에 있는 데이터를 가져와 계속 서비스 가능

#### 데이터베이스 서버 가운데 하나가 다운되면

- 부 서버 다운, 부 서버 한 대 뿐
  - 읽기 연산은 한시적으로 모두 주 데이터베이스로 전달
  - 즉시 새로운 부 데이터베이스 서버가 장애 서버를 대체
- 부 서버 다운, 부 서버 여러 대
  - 읽기 연산은 나머지 부 데이터베이스 서버들로 분산
  - 새로운 부 데이터베이스 서버가 장애 서버를 대체
- 주 데이터베이스 서버 다운, 한 대의 부 데이터베이스
  - 해당 부 데이터베이스 서버가 새로운 주 서버
  - 모든 데이터베이스 연산은 일시적으로 새로운 주 서버상에서 수행
  - 새로운 부 서버 추가
  - 프로덕션(production) 환경에서 벌어지는 일은 이것보다 복잡 -> 부 서버에 보관된 데이터가 최신 상태가 아닐 수 있음
  - 없는 데이터는 복구 스크립트(recovery script)를 돌려서 추가
  - 다중 마스터, 원형 다중화 방식은 이런 상황 대처에 도움이 될 수도 있지만 해당 구성은 훨씬 복잡

## 캐시

> 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리 안에 두고, 뒤 이은 요청이 보다 빨리 처리될 수 있도록 함

애플리케이션의 성능은 데이터베이스를 얼마나 자주 호출하느냐에 크게좌우되는데, 캐시는 그런 문제를 완화할 수 있음

### 캐시 계층

- 성능 개선
- 데이터베이스 부하를 줄일 수 있음
- 캐시 계층의 규모를 독립적으로 확장 가능
- 캐시 서버를 두는 방법 중 하나
  1. 웹 서버는 캐시에 응답이 저장되어 있는지 확인
  2. 저장되어 있다면 해당 데이터를 반환
  3. 없는 경우 데이터베이스 질의를 통해 데이터를 찾아 캐시에 저장한 뒤 클라이언트에 반환
- 이러한 캐시 전략을 `읽기 주도형 캐시 전략`이라고 부르는데, 이외에도 캐시할 데이터 종류, 크기, 엑세스 패턴에 맞는 캐시 전략을 선택하면 됨

### 캐시 사용시 유의할 점

- 캐시는 **어떤 상황**에 바람직한가?
  - 데이터 갱신은 자주 일어나지 않지만 참조는 빈번
- **어떤 데이터**를 캐시에 두어야 하는가?
  - 캐시는 데이터를 휘발성 메모리에 두므로, 영속적으로 보관할 데이터를 캐시에 두는 것은 바람직하지 않음
- 캐시에 보관된 데이터는 어떻게 만료(expire)되는가?
  - 적절한 정책을 마련하고 만료된 데이터는 캐시에서 삭제되어야 함
  - 만료 기한이 너무 짧으면 데이터베이스를 너무 자주 읽고, 너무 길면 원본과 차이가 날 가능성이 높아짐
- **일관성(consistency)**  은 어떻게 유지되는가?
  - 일관성은 데이터 저장소의 원본과 캐시 내의 사본이 같은지 여부
  - 저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우 이 일관성은 꺠질 수 있음
- **장애**에는 어떻게 대처할 것인가?
  - 캐시 서버를 한 대만 두는 경우 해당 서버는 단일 장애 지점(Single Point of Failure, SPOF)이 되어버릴 가능성이 있고, SPOF를 피하려면 여러 지역에 걸쳐 캐시 서버를 분산시켜야 함
  - `단일 장애 지점(Single Point of Failure)`: 어떤 특정 지점에서의 장애가 전체 시스템의 동작을 중단시켜버릴 수 있는 경우, 우리는 해당 지점을 단일 장애 지점이라고 부름
- 캐시메모리는 **얼마나 크게** 잡을 것인가?
  - 캐시 메모리가 너무 작으면 액세스 패턴에 따라 데이터가 너무 자주 캐시에서 밀려나버려서(eviction) 캐시의 성능 저하
  - 이를 막을 방법 중 한가지는 캐시 메모리를 과할당해서 캐시에 보관될 데이터가 갑자기 늘어났을 때 생길 문제도 방지할 수 있게 됨
- **데이터 방출(eviction)** 정책은 무엇인가?
  - 캐시가 꽉 차버리면 추가로 캐시에 데이터를 넣어야 할 경우 기존 데이터를 내보내야 하는데 이것을 캐시 데이터 방출 정책이라 함
  - LRU(Least Recently Used), LFU(Least Frequently Used), FIFO(First In First Out)

## 콘텐츠 전송 네트워크(CDN)

> CDN은 정적 콘텐츠를 전송하는 데 쓰이는, 지리적으로 분산된 서버의 네트워크이다. 이미지, 비디오, CSS, Javascript 파일 등을 캐시할 수 있다.

어떤 사용자가 웹사이트를 방문하면, 그 사용자에게 가장 가까운 CDN 서버가 정적 콘텐츠를 전달하게 된다. 사용자가 CDN 서버로부터 멀면 멀수록 웹사이트는 천천히 로드될 것이다.

### CDN이 어떻게 동작한는지

1. 사용자 A가 정적 콘텐츠를 URL을 통해 접근
2. CDN 서버의 캐시에 해당 정적 콘텐츠가 없는 경우, 서버는 원본(origin) 서버에 요청하여 파일을 가져옴
3. 원본 서버가 응답의 HTTP 헤더에 TTL 값을 포함하여 파일을 CDN 서버에 반환
4. CDN 서버는 파일을 캐시하고 사용자 A에게 반환
5. 사용자 B가 같은 정적 콘텐츠에 대한 요청을 CDN 서버에 전송
6. 만료되지 않은 파일에 대한 요청은 캐시를 통해 처리

### CDN 사용 시 고려해야 할 사항

- `비용`
  - 보통 제3 사업자(third-party providers)에 의해 운영
  - CDN으로 들어가고 나가는 데이터 전송 양에 따라 요금 지불
  - 자주 사용되지 않는 콘텐츠를 캐싱하는 것은 이득이 크지 않으므로, CDN에서 빼는 것 고려
- `적절한 만료 시한 설정`
  - 시의성이 중요한(time-sensitive) 콘텐츠의 경우 만료 시점을 잘 정해야 함
  - 너무 길지도 않고 짧지도 않아야 하는데, 너무 길면 콘텐츠의 신선도는 떨어질 것이고, 너무 짧으면 원본 서버에 빈번히 접속하게 되어 좋지 않음
- `CDN 장애에 대한 대처 방안`
  - 일시적으로 CDN이 응답하지 않을 경우, 해당 문제를 감지하여 원본 서버로부터 직접 콘텐츠를 가져오도록 클라이언트를 구성하는 것이 필요할 수 있음
- `콘텐츠 무효화(invalidation) 방법`
  - 아직 만료되지 않은 콘텐츠라 하더라도 아래 방법 가운데 하나를 쓰면 CDN에서 제거 가능
  - CDN 서비스 사업자가 제공하는 API를 이용하여 콘텐츠 무효화
  - 콘텐츠의 다른 버전을 서비스하도록 오브젝트 버저닝(object versioning) 이용. ex) image.png?v=2

## 무상태(stateless) 웹 계층

웹 계층을 수평적으로 황장하려면 웹 게층에서 상태 정보(사용자 세션 데이터와 같은)를 제거해야 한다.

### 상태 정보 의존적인 아키텍처

- 상태 정보를 보관하는 서버는 클라이언트 정보, 즉 상태를 유지하여 요청들 사이에 공유되도록 함
- 클라이언트로부터의 요청은 항상 같은 서버로 전송되어야 함
  - 로드 밸런서 이를 지원하기 위해 고정 세선(sticky session)이라는 기능을 제공하고 있는데, 이는 로드밸런서에 부담을 주고 로드밸런서 뒷단에 서버를 추가하거나 제거하기도 까다로워 짐

### 무상태 아키텍처

- 웹 서버는 상태 정보가 필요할 경우 공유 저장소(shared stroage)로부터 데이터를 가져옴

## 데이터 센터

> 가용성을 높이고 전 세계 어디서도 쾌적하게 사용할 수 있도록

- 장애가 없는 상황에서 사용자는 가장 가까운 데이터 센터로 안내되는데, 통상 이 절차를 지리적 라우팅(geoDNS-routing 또는 geo-routing)이라고 부름
- geoDNS는 사용자의 위치에 따라 도메인 이름을 어떤 IP주소로 변환할지 결정해주는 DNS 서비스
- 데이터 센터 중 하나에 심각한 장애가 발생하면 모든 트래픽은 장애가 없는 데이터 센터로 전송

### 다중 데이터센터 아키텍처의 기술적 난제

- `트래픽 우회`
  - 올바른 데이터 센터로 트래픽을 보내는 효과적인 방법을 찾아야 함
  - GeoDNS는 사용자에게서 가장 가까운 데이터 센터로 트래픽을 보낼 수 있도록 해줌
- `데이터 동기화(synchronization)`
  - 데이터 센터마다 별도의 데이터베이스를 사용하고 있는 상황이라면, 장애가 자동으로 복구되어 트래픽이 다른 데이터베이스로 우회된다 해도, 해당 데이터센터에는 찾는 데이터가 없을 수 있음
- `테스트와 배포(deployment)`
  - 여러 데이터 센터를 사용하도록 시스템이 구성된 상황이라면 웹 사이트 또는 애플리케이션을 여러 위치에서 테스트해보는 것이 중요
  - 자동화된 배포 도구는 모든 데이터 센터에 동일한 서비스가 설치되도록 하는데 중요한 역할

## 메시지큐

> 시스템을 더 큰 규모로 확장하기 위해서는 시스템의 컴포넌트를 분리하여, 각기 독립적으로 확장될 수 있도록 하여야 하는데, 메시지 큐(message queeu)는 많은 실제 분산 시스템이 이 문제를 풀기 위해 채용하고 있는 핵심적 전략 가운데 하나

- `메시지의 무손실(durability)`: 메시지 큐에 일단 보관된 메시지는 소비자가 꺼낼 때까지 안전히 보관
- `비동기 통신` 지원
- 메시지의 버퍼 역할
- 메시지 큐를 이용하면 서비스 또는 서버 간의 결합이 느슨해져서 규모 확장성이 보장되어야 하는 안정적 애플리케이션을 구성하기 좋음

## 로그, 메트릭 그리고 자동화

> 몇 개의 서버에서 실행되는 소규모 웹 사이트를 만들 때는 로그나 케드릭, 자동화 같은 것은 하면 좋지만 꼭 할 필요는 없다. 하지만 일단 웹 사이트와 함께 사업 규모가 커지고 나면, 그런 도구에 필수적으로 투자해야 한다.

## 데이터베이스의 규모 확장

### 수직적 확장의 단점

- 데이터베이스 서버 하드웨어에는 한계가 있으므로 CPU, RAM 등을 무한 증설할 수는 없음
- SPOF(Single Point of Failure)로 인한 위험성 큼
- 비용이 많이 듬. 고성능 서버로 갈수록 가격이 올라감.

### 수평적 확장

- `샤딩(sharding)`이라고도 부름
- `샤드(shard)`라고 부르는 작은 단위로 분할
- 모든 샤드는 **같은 스키마**를 쓰지만 샤드에 보관되는 데이터 사이에는 **중복이 없음**
- 샤딩 전략을 구혈할 때 가장 고려해야 할 중요한 것은 **샤딩 키**를 어떻게 정하느냐 하는 것
  - 파티션 키라고도 부름

#### 샤딩의 문제

- `데이터 재 샤딩(resharding)`
  - 재 샤딩이 필요한 경우
    1. 데이터가 너무 많아져서 하나의 샤드로 더 이상 감당하기 어려울 때
    2. 샤드 간 데이터 분포가 균등하지 못하여 어떤 샤드에 할당된 공간 소모가 다른 샤드에 비해 빨리 진행될 떄
  - 이런 경우 샤드 키를 계산하는 함수를 변경하고 데이터를 재배치 하여야 함
- 유명인사 문제
  - 핫스팟 키 문제라고도 부름
  - 특정 샤드에 질의가 집중되어 서버에 과부하가 걸리는 문제
  - 이 문제를 풀려면 유명인사 각각에 샤드 하나씩을 할당해야 할 수도 있고, 심지어는 더 잘게 쪼개야 할 수도 있음
- 조인과 비정규화
  - 일단 하나의 데이터베이스를 여러 샤드 서버로 쪼개고 나면, 여러 샤드에 걸친 데이터를 조인하기 힘듦
  - 이를 해결하는 한 가지 방법은 데이터베이스를 비정규화하여 하나의 테이블에서 질의가 수행될 수 있도록 하는 것

## 정리

- 웹 계층은 무상태 계층으로
- 모든 계층에 다중화 도입
- 가능한 한 많은 데이터를 캐시할 것
- 여러 데이터 센터를 지원할 것
- 정적 콘텐츠는 CDN을 통해 서비스할 것
- 데이터 계층은 샤딩을 통해 그 규모를 확장할 것
- 각 계층은 독립적 서비스로 분할할 것
- 시스템을 지속적으로 모니터링하고, 자동화 도구들을 활용할 것

# Chapter 3. 시스템 설계 면접 공략법

- 설계 기술을 시연
- 설계 과정에서 내린 결정들에 대한 방어 능력
- 피드백을 건설적인 방식으로 처리할 자질
- 시스템 설계 면접이 잘 진행되면
  - 협력에 적합한 사람인지
  - 압박이 심한 상황도 잘 헤쳐 나갈 자질이 있는지
  - 모호한 문제를 건설적으로 해결할 능력이 있는지
  - 좋은 질문을 던질 능력이 있는지
- 부정적 신호
  - 설계의 순수성에 집착한 나머지 타협적 결정을 도외시하고 과도한 엔지니어링을 하는 것 -> 시스템 전반의 비용이 올라감
  - 완고함, 편협함, ... 등

## 효과적 면접을 위한 4단계 접근법

### 1단계 문제 이해 및 설계 범위 확정

- 요구사항을 완전히 이해하지 않고 답을 내놓는 행위는 아주 엄청난 부정적 신호
- 올바른 질문을 하는 것, 적절한 가정을 하는 것, 시스템 구축에 필요한 정보를 모으는 것

### 2단계 개략적인 설계안 제시 및 동의 구하기

- 설계안에 대한 최초 청사진을 제시하고 의견을 구하라
  - 면접관을 마치 팀원인 것처럼 대하라
- 화이트보드나 종이에 핵심 컴포넌트를 포함하는 다이어그램을 그려라
  - 클라이언트(모바일/웹), API, 웹 서버, 데이터 저장소, 캐시, CDN, 메시지 큐, ...
- 이 최초 설계안이 시스템 규모에 관계된 제약사항들을 만족하는지를 개략적으로 계산해보라
  - 계산 과정은 소리내어 설명하라
  - 이런 개략적 추정이 필요한지는 면접관에게 미리 물어보도록 하자

### 3단계 상세 설계

- 설계 대상 컴포넌트 사이의 우선순위를 정하기
  - 면접관이 집중 했으면 하는 영역을 알려 주기도 함
  - 성능 특성에 대한 질문, 시스템의 병목 구간이나 자원 요구량 추정치
- 시간 관리에도 주의
  - 사소한 세부사항을 설명하느라 정작 여러분의 능력을 보일 기회를 놓칠 수 있음

### 4단계 마무리

- 개선 가능한 지점을  찾아내라 주문할 수 있음
  - 개선할 점은 언제나 있음
- 설계를 한번 다시 요약
  - 여러 해결책을 제시한 경우 특히 중요
- 오류가 발생하면 무슨 일이 생기는지
- 운영 이슈
  - 메트릭, 모니터링, 로그, 배포, ...
- 미래의 규모 확장 요구에 어떻게 대처할 것인지
- 필요하지만 다루지 못했던 세부적 개선사항들 제안

## 해야할 것

- 질문을 통해 확인하라. 스스로 내린 가정이 옳다 믿고 진행하지 말라.
- 문제의 요구사항을 이해하라.
- 정답이나 최선의 답안 같은 것은 없다는 점을 명심하라. 스타트업을 위한 설계안과 수백만 사용자를 지원해야 하는 중견 기업을 위한 설계안이 같을 리 없다. 요구사항을 정확하게 이해했는지 다시 확인하라.
- 면접관이 여러분의 사고 흐름을 이해할 수 있도록 하라. 면접관과 소통하라.
- 가능하다면 여러 해법을 함께 제시하라.
- 개략적 설계에 면접관이 동의하면, 각 컴포넌트의 세부사항을 설명하기 시작하라. 가장 중요한 컴포넌트부터 진행하라.
- 면접관의 아이디어를 이끌어 내라. 좋은 면접관은 여러분과 같은 팀원처럼 협력한다.
- 포기하지 말라.

## 해지 말아야 할 것

- 전형적인 면접 문제들에도 대비하지 않은 상태에서 면접장에 가지 말라.
- 요구사항이나 가정들을 분명히 하지 않은 상태에서 설계를 제시하지 말라.
- 처음부터 특정 컴포넌트의 세부사항을 너무 깊이 설명하지 말라. 개략적 설계를 마친 뒤에 세부사항으로 나아가라.
- 진행 중에 막혔다면, 힌트를 청하기를 주저하지 말라.
- 다시 말하지만, 소통을 주저하지 말라. 침묵 속에 설계를 진행하지 말라.
- 설계안을 내놓는 순간 면접이 끝난다고 생각하지 말라. 면접관이 끝났다고 말하기 전까지는 끝난 것이 아니다. 의견을 일찍, 그리고 자주 구하라.

# 처리율 제한 장치의 설계

## API 게이트웨이가 할 수 있는 역할

- 처리율 제한
- SSL 종단
- 사용자 인증
- IP 허용 목록 관리

## 레디스 Race condition 해결

> Read -> Write 과정이 분리되서 진행될 경우 Race Condition 발생 가능

1. 락
   - 시스템의 성능을 떨어트림
2. 루아 스크립트
3. 정렬 집합

# Chapter 5. 안정 해시 설계

수평적 규모 확장성을 달성하기 위해서는 요청 또는 데이터를 서버에 균등하게 나누는 것이 중요한데, 안정 해시는 이 목표를 달성하기 위해 보편적으로 사용하는 기술이다.

## 안정 해시

- 해시 테이블 크기가 조정될 때 오직 k/n 개의 키만 재배치
  - k = 키의 개수, n = 슬롯

### 기본 구현법

- 서버와 키를 균등 분포 해시 함수를 사용해 해시 링에 배치
- 키의 위치에서 링을 시계방향으로 탐색하다 만나는 최초의 서버가 키가 저장될 서버

### 기본 구현법의 두 가지 문제

1. 서버가 추가되거나 삭제되는 상황을 감안하면 파티션의 크기를 균등하게 유지하는 게 불가능
2. 키의 균등 분포를 달성하기가 어려움

#### 가상 노드(복제)

> 위 문제를 해결하기 위해 제안된 기법

- 실제 노드 또는 서버를 가리키는 노드로서, 하나의 서버는 링 위에 여러 개의 가상 노드를 가질 수 있음
- 가상 노드의 개수를 늘리면 키의 분포는 점점 더 균등 해짐
  - 표준 편차가 작아져서 데이터가 고르게 분포
